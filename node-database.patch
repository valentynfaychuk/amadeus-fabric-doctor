diff --git a/README.md b/README.md
index 95d288e..544e827 100644
--- a/README.md
+++ b/README.md
@@ -15,10 +15,22 @@ podman build --tag erlang_builder -f build.Dockerfile
 ```
 #run local testnet with RPC api
 
-TESTNET=true WORKFOLDER=/tmp/testnet HTTP_IPV4=127.0.0.1 HTTP_PORT=8080  ./amadeusd
+#point RPC endpoint to localhost
+vim /etc/hosts
+127.0.0.1 nodes.amadeus.bot
 
-# inside REPL submit a transfer to self
+#run google chrome with cert verification disabled and CORS disabled
+mkdir -p /tmp/chrome_debug
+google-chrome  --user-data-dir="/tmp/chrome_debug" --no-first-run --no-default-browser-check \
+--ignore-certificate-errors --disable-web-security --unsafely-treat-insecure-origin-as-secure=https://nodes.amadeus.bot
+
+#allow listening on port 80 and 443
+sudo sysctl -w net.ipv4.ip_unprivileged_port_start=80
 
+#run the local testnet
+TESTNET=true WORKFOLDER=/tmp/testnet HTTP_IPV4=127.0.0.1 HTTP_PORT=80  ./amadeusd
+
+# inside REPL submit a transfer to self
 pk = Application.fetch_env!(:ama, :trainer_pk)
 sk = Application.fetch_env!(:ama, :trainer_sk)
 Testnet.call(sk, "Coin", "transfer", [pk,"1","AMA"])
diff --git a/ex/build.sh b/ex/build.sh
index cfc2b45..e8873cd 100755
--- a/ex/build.sh
+++ b/ex/build.sh
@@ -1,5 +1,7 @@
 #!/bin/bash
 
+#&& export ERL_COMPILER_OPTIONS=bin_opt_info \
+
 podman run -it --rm -v ../.:/root/node --entrypoint bash erlang_builder -c "echo 'building amadeus..' \
     && cd /root/node/ex \
     && export MIX_ENV=prod \
diff --git a/ex/config/config.exs b/ex/config/config.exs
index cb2d9a8..dec9398 100644
--- a/ex/config/config.exs
+++ b/ex/config/config.exs
@@ -1,15 +1,18 @@
 import Config
 
+
 config :logger, truncate: :infinity
+config :logger, :console, truncate: :infinity
+config :logger, :default_formatter, truncate: :infinity
 
-config :iex,
-  inspect: [width: 120, limit: 480, pretty: true, custom_options: [sort_maps: true]]
+inspect_opts = [width: 120, limit: 320, pretty: true, custom_options: [sort_maps: true]]
+config :iex, inspect: inspect_opts
+config :logger, translator_inspect_opts: inspect_opts
 
 config :ama, :version, Mix.Project.config[:version]
 
 config :ama, :entry_size, 524288
 config :ama, :tx_size, 393216
-config :ama, :attestation_size, 512
 config :ama, :quorum, 3
 #config :ama, :quorum, 1
 
diff --git a/ex/config/runtime.exs b/ex/config/runtime.exs
index 2bf4d15..8e20951 100644
--- a/ex/config/runtime.exs
+++ b/ex/config/runtime.exs
@@ -15,7 +15,15 @@ config :ama, :work_folder, work_folder
 
 #load env
 #Envvar.load(Path.join([work_folder, ".env"]))
-config :ama, :snapshot_height, (System.get_env("SNAPSHOT_HEIGHT") || "34076355") |> :erlang.binary_to_integer()
+config :ama, :snapshot_height, (System.get_env("SNAPSHOT_HEIGHT") || "39434469") |> :erlang.binary_to_integer()
+
+# zip -0 -r 000037454455.zip db/
+# aws s3 cp --checksum-algorithm=CRC32 --endpoint-url https://20bf2f5d11d26a322e389687896a6601.r2.cloudflarestorage.com 000039434469.zip s3://ama-snapshot
+# aria2c -x 2 https://snapshots.amadeus.bot/000039434469.zip
+
+# tar -C /tmp/000037454455 --xform 's@^\./@@' -cf - . | zstd -T0 -1 -o /tmp/000037454455.tar.zst
+# zstd -T0 -d --stdout /tmp/000037454455.tar.zst | tar -C /tmp/restore -xf -
+
 
 #Bind Interaces
 config :ama, :offline, (!!System.get_env("OFFLINE") || nil)
@@ -54,6 +62,7 @@ keys_by_pk = Enum.into(keys, %{}, fn(key)->
 end)
 config :ama, :keys, keys
 config :ama, :keys_by_pk, keys_by_pk
+config :ama, :keys_all_pks, Enum.map(keys, & &1.pk)
 
 first_key = hd(keys)
 config :ama, :trainer_pk, first_key.pk
diff --git a/ex/lib/api/api_chain.ex b/ex/lib/api/api_chain.ex
index c0bc197..08b9aee 100644
--- a/ex/lib/api/api_chain.ex
+++ b/ex/lib/api/api_chain.ex
@@ -1,13 +1,13 @@
 defmodule API.Chain do
     def entry_tip() do
-        entry = Consensus.chain_tip_entry()
+        entry = DB.Chain.tip_entry()
         entry = format_entry_for_client(entry)
         %{error: :ok, entry: entry}
     end
 
     def entry(entry_hash, filter_on_function \\ nil) do
         entry_hash = if byte_size(entry_hash) != 32, do: Base58.decode(entry_hash), else: entry_hash
-        entry = Fabric.entry_by_hash(entry_hash)
+        entry = DB.Entry.by_hash(entry_hash)
         if !entry do
             %{error: :not_found}
         else
@@ -27,13 +27,13 @@ defmodule API.Chain do
     end
 
     def by_height(height) do
-        entries = Fabric.entries_by_height(height)
+        entries = DB.Entry.by_height(height)
         |> Enum.map(& format_entry_for_client(&1))
         %{error: :ok, entries: entries}
     end
 
     def by_height_with_txs(height) do
-        entries = Fabric.entries_by_height(height)
+        entries = DB.Entry.by_height(height)
         |> Enum.map(fn(entry)->
             txs = API.TX.get_by_entry(entry.hash)
             entry = format_entry_for_client(entry)
@@ -42,26 +42,18 @@ defmodule API.Chain do
         %{error: :ok, entries: entries}
     end
 
-    def consensus_score_by_entryhash(hash, height) do
-        consensuses = Fabric.consensuses_by_entryhash(hash)
-        if !consensuses do
-            {nil, nil}
-        else
-            trainers = Consensus.trainers_for_height(height)
-            {mut_hash, score, consensus} = Consensus.best_by_weight(trainers, consensuses)
-            {score, mut_hash}
-        end
-    end
-
     def consensuses_by_height(height) do
-        Fabric.consensuses_by_height(height)
+        DB.Attestation.consensuses_by_height(height)
         |> Enum.map(fn(c)->
+            aggsig = %{
+              aggsig: Base58.encode(c.aggsig.aggsig),
+              mask: Base58.encode(c.aggsig.mask),
+              mask_size: c.aggsig.mask_size,
+              mask_set_size: c.aggsig.mask_set_size,
+            }
             c = put_in(c, [:mutations_hash], Base58.encode(c.mutations_hash))
             c = put_in(c, [:entry_hash], Base58.encode(c.entry_hash))
-            c = put_in(c, [:aggsig], Base58.encode(c.aggsig))
-            signers = BLS12AggSig.unmask_trainers(Consensus.trainers_for_height(height), c.mask)
-            |> Enum.map(& Base58.encode(&1))
-            c = put_in(c, [:signers], signers)
+            c = put_in(c, [:aggsig], aggsig)
             c = put_in(c, [:score], length(c.signers) / bit_size(c.mask))
             Map.drop(c, [:mask])
         end)
@@ -69,7 +61,7 @@ defmodule API.Chain do
 
     def pflops() do
       #A*B=C M=16 K=50240 N=16 u8xi8=i32
-      height_in_epoch = rem(Consensus.chain_height(), 100_000)
+      height_in_epoch = rem(DB.Chain.height(), 100_000)
       total_score = API.Epoch.score() |> Enum.map(& Enum.at(&1,1))|> Enum.sum()
       diff_multiplier = Bitwise.bsl(1, API.Epoch.get_diff_bits())
       total_calcs = total_score * diff_multiplier
@@ -82,26 +74,28 @@ defmodule API.Chain do
 
     def stats() do
       %{
-        height: Consensus.chain_height(),
-        tip_hash: Consensus.chain_tip() |> Base58.encode(),
-        tip: format_entry_for_client(Consensus.chain_tip_entry()),
+        height: DB.Chain.height(),
+        tip_hash: DB.Chain.tip() |> Base58.encode(),
+        tip: format_entry_for_client(DB.Chain.tip_entry()),
         tx_pool_size: TXPool.size(),
-        cur_validator: Consensus.trainer_for_slot_current() |> Base58.encode(),
-        next_validator: Consensus.trainer_for_slot_next() |> Base58.encode(),
-        emission_for_epoch: BIC.Coin.from_flat(BIC.Epoch.epoch_emission(Consensus.chain_epoch())),
-        circulating: BIC.Coin.from_flat(BIC.Epoch.circulating_without_burn(Consensus.chain_epoch())),
+        cur_validator: DB.Chain.validator_for_height_current() |> Base58.encode(),
+        next_validator: DB.Chain.validator_for_height_next() |> Base58.encode(),
+        emission_for_epoch: BIC.Coin.from_flat(BIC.Epoch.epoch_emission(DB.Chain.epoch())),
+        circulating: BIC.Coin.from_flat(BIC.Epoch.circulating_without_burn(DB.Chain.epoch())),
         total_supply_y3: BIC.Coin.from_flat(BIC.Epoch.circulating_without_burn(500*3)),
         total_supply_y30: BIC.Coin.from_flat(BIC.Epoch.circulating_without_burn(500*30)),
         pflops: pflops(),
         burned: API.Contract.total_burned().float,
-        txs_per_sec: stat_txs_sec()
+        txs_per_sec: stat_txs_sec(),
+        diff_bits: API.Epoch.get_diff_bits()
       }
     end
 
     def stat_txs_sec() do
-      height = Fabric.rooted_tip_height()
-      last_100 = Enum.sum_by((height-100)..height, fn(height)->
-        length(Fabric.entries_by_height(height) |> List.first() |> Map.get(:txs))
+      height = DB.Chain.rooted_height()
+      height_start = max(height-100, 0)
+      last_100 = Enum.sum_by(height_start..height, fn(height)->
+        length(DB.Entry.by_height(height) |> List.first() |> Map.get(:txs))
       end)
       last_100/50
     end
@@ -114,20 +108,20 @@ defmodule API.Chain do
         {_, entry} = pop_in(entry, [:header_unpacked, :txs_hash])
         entry = put_in(entry, [:hash], Base58.encode(entry.hash))
         entry = if !entry[:mask] do entry else
-          rem     = rem(bit_size(entry.mask), 8)
-          pad_bits = if rem == 0, do: 0, else: 8 - rem
-          put_in(entry, [:mask], Base58.encode(<<entry.mask::bitstring, 0::size(pad_bits)>>))
+          put_in(entry, [:mask], Base58.encode(entry.mask))
+          put_in(entry, [:mask_size], entry.mask_size)
         end
         entry = put_in(entry, [:header_unpacked, :dr], Base58.encode(entry.header_unpacked.dr))
         entry = put_in(entry, [:header_unpacked, :vr], Base58.encode(entry.header_unpacked.vr))
         entry = put_in(entry, [:header_unpacked, :prev_hash], Base58.encode(entry.header_unpacked.prev_hash))
         entry = put_in(entry, [:header_unpacked, :signer], Base58.encode(entry.header_unpacked.signer))
-        {score, mut_hash} = consensus_score_by_entryhash(hash, entry.header_unpacked.height)
-        if !score do entry else
+        {mut_hash, score} = DB.Attestation.best_consensus_by_entryhash(hash)
+        if !mut_hash do entry else
             entry = put_in(entry, [:consensus], %{})
             entry = put_in(entry, [:consensus, :score], Float.round(score, 3))
             entry = put_in(entry, [:consensus, :finality_reached], Float.round(score, 3) >= 0.67)
             entry = put_in(entry, [:consensus, :mut_hash], Base58.encode(mut_hash))
+            entry
         end
     end
 end
diff --git a/ex/lib/api/api_epoch.ex b/ex/lib/api/api_epoch.ex
index 055f605..3cc5d99 100644
--- a/ex/lib/api/api_epoch.ex
+++ b/ex/lib/api/api_epoch.ex
@@ -26,18 +26,18 @@ defmodule API.Epoch do
     end
 
     def get_diff_bits(epoch \\ nil) do
-      epoch = if epoch do epoch else Consensus.chain_epoch() end
+      epoch = if epoch do epoch else DB.Chain.epoch() end
       API.Contract.get("bic:epoch:diff_bits:#{epoch}", :to_integer) || 24
     end
 
     def get_total_sols(epoch \\ nil) do
-      epoch = if epoch do epoch else Consensus.chain_epoch() end
+      epoch = if epoch do epoch else DB.Chain.epoch() end
       API.Contract.get("bic:epoch:total_sols:#{epoch}", :to_integer) || 0
     end
 
     def get_pop(pk) do
       pk = if byte_size(pk) != 48, do: Base58.decode(pk), else: pk
-      Consensus.chain_pop(pk)
+      DB.Chain.pop(pk)
       |> case do
         nil -> nil
         addr -> Base58.encode(addr)
diff --git a/ex/lib/api/api_peer.ex b/ex/lib/api/api_peer.ex
index 7e6eff4..a5e471f 100644
--- a/ex/lib/api/api_peer.ex
+++ b/ex/lib/api/api_peer.ex
@@ -1,9 +1,9 @@
 defmodule API.Peer do
     def trainers(height \\ nil) do
-        height = height || Consensus.chain_height()+1
-        trainerForSlot = Consensus.trainer_for_slot(height, height)
+        height = height || DB.Chain.height()+1
+        trainerForSlot = DB.Chain.validator_for_height(height)
 
-        Consensus.trainers_for_height(height)
+        DB.Chain.validators_for_height(height)
         |> Enum.map(fn(pk)->
             p = NodeANR.get_peer_hotdata(pk)
             inSlot = trainerForSlot == pk
@@ -90,9 +90,9 @@ defmodule API.Peer do
     end
 
     def removed_trainers(epoch \\ nil) do
-        epoch = if !epoch do Consensus.chain_epoch() else epoch end
-        trainers_for_epoch = Consensus.trainers_for_height(epoch*100_000)
-        trainers = Consensus.trainers_for_height(Consensus.chain_height()+1)
+        epoch = if !epoch do DB.Chain.epoch() else epoch end
+        trainers_for_epoch = DB.Chain.validators_for_height(epoch*100_000)
+        trainers = DB.Chain.validators_for_height(DB.Chain.height()+1)
         (trainers_for_epoch -- trainers)
         |> Enum.map(& Base58.encode(&1))
     end
diff --git a/ex/lib/api/api_tx.ex b/ex/lib/api/api_tx.ex
index 588cfda..935c276 100644
--- a/ex/lib/api/api_tx.ex
+++ b/ex/lib/api/api_tx.ex
@@ -1,13 +1,13 @@
 defmodule API.TX do
     def get(tx_id) do
         tx_id = if byte_size(tx_id) != 32, do: Base58.decode(tx_id), else: tx_id
-        Consensus.chain_tx(tx_id)
+        DB.Chain.tx(tx_id)
         |> format_tx_for_client()
     end
 
     def get_by_entry(entry_hash) do
         entry_hash = if byte_size(entry_hash) != 32, do: Base58.decode(entry_hash), else: entry_hash
-        case Fabric.entry_by_hash(entry_hash) do
+        case DB.Entry.by_hash(entry_hash) do
             nil -> nil
             %{hash: entry_hash, header_unpacked: %{slot: slot}, txs: txs} ->
                 Enum.map(txs, fn(tx_packed)->
@@ -161,8 +161,9 @@ defmodule API.TX do
       end
     end
 
-    def submit_and_wait_1(hash, 30) do nil end
-    def submit_and_wait_1(hash, tries \\ 0) do
+    def submit_and_wait_1(_hash, tries \\ 0)
+    def submit_and_wait_1(_hash, 30) do nil end
+    def submit_and_wait_1(hash, tries) do
       tx = get(hash)
       if tx do tx else
         Process.sleep(100)
@@ -186,7 +187,7 @@ defmodule API.TX do
             Map.put(a, :args, args)
         end)
         tx = put_in(tx, [:tx, :actions], actions)
-        tx = if !Map.has_key?(tx, :metadata) do tx else
+        if !Map.has_key?(tx, :metadata) do tx else
             put_in(tx, [:metadata, :entry_hash], Base58.encode(tx.metadata.entry_hash))
         end
     end
diff --git a/ex/lib/api/api_wallet.ex b/ex/lib/api/api_wallet.ex
index 4d37d90..dbd99f4 100644
--- a/ex/lib/api/api_wallet.ex
+++ b/ex/lib/api/api_wallet.ex
@@ -7,7 +7,7 @@ defmodule API.Wallet do
     #def balance(pk, symbol \\ "AMA") do
     def balance(pk, symbol \\ "AMA") do
         pk = if byte_size(pk) != 48, do: Base58.decode(pk), else: pk
-        coins = Consensus.chain_balance(pk, symbol)
+        coins = DB.Chain.balance(pk, symbol)
         %{symbol: symbol, flat: coins, float: BIC.Coin.from_flat(coins)}
     end
 
@@ -30,7 +30,7 @@ defmodule API.Wallet do
     def transfer(from_sk, to, amount, symbol, broadcast \\ true) do
         from_sk = if byte_size(from_sk) != 64, do: Base58.decode(from_sk), else: from_sk
         to = if byte_size(to) != 48, do: Base58.decode(to), else: to
-        if !BlsEx.validate_public_key(to) and to != @burn_address, do: throw(%{error: :invalid_receiver_pk})
+        if !BlsEx.validate_public_key(to) and to != BIC.Coin.burn_address(), do: throw(%{error: :invalid_receiver_pk})
         amount = if is_float(amount) do trunc(amount * 1_000_000_000) else amount end
         amount = if is_integer(amount) do :erlang.integer_to_binary(amount) else amount end
         tx_packed = TX.build(from_sk, "Coin", "transfer", [to, amount, symbol])
diff --git a/ex/lib/api/db_api.ex b/ex/lib/api/db_api.ex
new file mode 100644
index 0000000..2ff8341
--- /dev/null
+++ b/ex/lib/api/db_api.ex
@@ -0,0 +1,70 @@
+defmodule DB.API do
+  def pad_integer(key) do
+    String.pad_leading("#{key}", 12, "0")
+  end
+
+  def pad_integer_20(key) do
+    String.pad_leading("#{key}", 20, "0")
+  end
+
+  def db_handle(db_opts, default_cf, merge_opts \\ %{}) do
+    %{db: db_static, cf: cf_static} = :persistent_term.get({:rocksdb, Fabric})
+    db = db_opts[:db]
+    cf = db_opts[:cf]
+    rtx = db_opts[:rtx]
+    cond do
+      !!rtx and !!cf -> Map.merge(%{rtx: rtx, cf: cf}, merge_opts)
+      !!rtx -> Map.merge(%{rtx: rtx, cf: Map.fetch!(cf_static, default_cf)}, merge_opts)
+      !!db and !!cf -> Map.merge(%{db: db, cf: cf}, merge_opts)
+      !!db -> Map.merge(%{db: db, cf: Map.fetch!(cf_static, default_cf)}, merge_opts)
+      true ->
+        Map.merge(%{db: db_static, cf: Map.fetch!(cf_static, default_cf)}, merge_opts)
+    end
+  end
+
+  def init() do
+    workdir = Application.fetch_env!(:ama, :work_folder)
+
+    path = Path.join([workdir, "db/fabric/"])
+    File.mkdir_p!(path)
+
+    cfs = [
+      "default",
+      "sysconf",
+      "entry", "entry_meta",
+      "attestation",
+      "tx", "tx_account_nonce", "tx_receiver_nonce",
+      "contractstate"
+    ]
+    try do
+      {:ok, db_ref, cf_ref_list} = RDB.open_transaction_db(path, cfs)
+      [
+        default_cf,
+        sysconf_cf,
+        entry_cf, entry_meta_cf,
+        attestation_cf,
+        tx_cf, tx_account_nonce_cf, tx_receiver_nonce_cf,
+        contractstate_cf
+      ] = cf_ref_list
+      cf = %{
+        default: default_cf,
+        sysconf: sysconf_cf,
+        entry: entry_cf, entry_meta: entry_meta_cf,
+        attestation: attestation_cf,
+        tx: tx_cf, tx_account_nonce: tx_account_nonce_cf, tx_receiver_nonce: tx_receiver_nonce_cf,
+        contractstate: contractstate_cf
+      }
+      :persistent_term.put({:rocksdb, Fabric}, %{db: db_ref, cf_list: cf_ref_list, cf: cf, path: path})
+    catch
+      e,r ->
+        IO.inspect {e, r}
+        IO.inspect {:using_old_db, "migrate"}
+        :erlang.halt()
+    end
+  end
+
+  def close() do
+      %{db: db} = :persistent_term.get({:rocksdb, Fabric})
+      RDB.close_db(db)
+  end
+end
diff --git a/ex/lib/api/db_attestation.ex b/ex/lib/api/db_attestation.ex
new file mode 100644
index 0000000..75b7cee
--- /dev/null
+++ b/ex/lib/api/db_attestation.ex
@@ -0,0 +1,102 @@
+defmodule DB.Attestation do
+  import DB.API
+
+  def consensuses(hash, db_opts \\ %{}) do
+    RocksDB.get_prefix("consensus:#{hash}:", db_handle(db_opts, :attestation, %{}))
+    |> Enum.map(& RDB.vecpak_decode( elem(&1,1) ))
+  end
+
+  def consensus(hash, muts_hash, db_opts \\ %{}) do
+    RocksDB.get("consensus:#{hash}:#{muts_hash}", db_handle(db_opts, :attestation, %{}))
+    |> case do
+      nil -> nil
+      value -> RDB.vecpak_decode(value)
+    end
+  end
+
+  def set_consensus(consensus, db_opts \\ %{}) do
+    score = consensus.aggsig.mask_set_size / consensus.aggsig.mask_size
+
+    old_consensus = consensus(consensus.entry_hash, consensus.mutations_hash, db_opts)
+    old_score = if old_consensus do old_consensus.aggsig.mask_set_size / old_consensus.aggsig.mask_size else 0.0 end
+
+    if score > old_score do
+      RocksDB.put("consensus:#{consensus.entry_hash}:#{consensus.mutations_hash}", RDB.vecpak_encode(consensus), db_handle(db_opts, :attestation, %{}))
+    end
+  end
+
+  def consensuses_by_height(height, db_opts \\ %{}) do
+    DB.Entry.by_height_return_hashes(height, db_opts)
+    |> Enum.map(fn(hash)->
+        DB.Attestation.consensuses(hash, db_opts)
+        |> Enum.map(fn %{aggsig: aggsig, mutations_hash: mutations_hash} ->
+            %{entry_hash: hash, mutations_hash: mutations_hash, aggsig: aggsig}
+        end)
+    end)
+    |> List.flatten()
+  end
+
+  def best_consensus_by_entryhash(hash) do
+    consensuses(hash)
+    |> Enum.reduce({nil,nil}, fn(consensus, {best_mutshash, best_score}) ->
+      score = consensus.aggsig.mask_set_size/consensus.aggsig.mask_size
+      cond do
+          !best_mutshash -> {consensus.mutations_hash, score}
+          score > best_score -> {consensus.mutations_hash, score}
+          true -> {best_mutshash, best_score}
+      end
+    end)
+  end
+
+  #Attestations
+  def by_height(height, db_opts \\ %{}) do
+    RocksDB.get_prefix("attestation:#{pad_integer(height)}:", db_handle(db_opts, :attestation, %{}))
+    |> Enum.map(& RDB.vecpak_decode( elem(&1,1) ))
+  end
+
+  def by_height_my(height, db_opts \\ %{}) do
+    my_validators = DB.Chain.validators_for_height_my(height, db_opts)
+    by_height(height, db_opts)
+    |> Enum.filter(& &1.signer in my_validators)
+  end
+
+  def by_height_by_signer(height, signer, db_opts \\ %{}) do
+    height = pad_integer(height)
+    RocksDB.get("attestation:#{height}:#{signer}", db_handle(db_opts, :attestation, %{}))
+    |> Attestation.unpack()
+  end
+
+
+  def missing_attestations(height, mask, mask_size, db_opts \\ %{}) do
+
+  end
+
+  def put(attestation, height, db_opts \\ %{}) do
+    a = attestation
+    a_packed = Attestation.pack_for_db(attestation)
+    RocksDB.put("attestation:#{pad_integer(height)}:#{a.entry_hash}:#{a.signer}:#{a.mutations_hash}", a_packed, db_handle(db_opts, :attestation, %{}))
+  end
+
+  #def put_or_error(attestation, db_opts \\ %{}) do
+  #  a = attestation
+  #  height = 0
+  #  round = 0
+
+  #  existing = attestations_for_height_by_signer(a.height, a.signer, db_opts)
+  #  cond do
+  #    length(existing) >= 1 and a not in existing ->
+  #      #DB.Slash.record()
+  #      %{error: :multiple_vote_cast}
+  #    a in existing ->
+  #      %{error: :ok}
+  #    true ->
+  #      RocksDB.put("attestation:#{height}:#{a.entry_hash}:#{a.signer}:#{a.mutations_hash}", Attestation2.pack(a), db_handle(db_opts, :attestation, %{}))
+  #      %{error: :ok}
+  #  end
+  #end
+
+  #[attestation]
+ # attestation:{hash}:{signer}:{muthash} attestation
+  #attestation_agg:{hash}:{muthash} consensus
+
+end
diff --git a/ex/lib/api/db_chain.ex b/ex/lib/api/db_chain.ex
new file mode 100644
index 0000000..07a6d2e
--- /dev/null
+++ b/ex/lib/api/db_chain.ex
@@ -0,0 +1,167 @@
+defmodule DB.Chain do
+  import DB.API
+
+  def tip(db_opts \\ %{}) do RocksDB.get("temporal_tip", db_handle(db_opts, :sysconf, %{})) end
+
+  def tip_entry(db_opts \\ %{}) do
+    DB.Entry.by_hash(tip(db_opts), db_opts)
+  end
+
+  def height(db_opts \\ %{}) do tip_entry(db_opts).header_unpacked.height end
+  def epoch(db_opts \\ %{}) do div(height(db_opts), 100_000) end
+
+  def rooted_tip(db_opts \\ %{}) do RocksDB.get("rooted_tip", db_handle(db_opts, :sysconf, %{})) end
+
+  def rooted_tip_entry(db_opts \\ %{}) do
+    DB.Entry.by_hash(rooted_tip(db_opts), db_opts)
+  end
+
+  def rooted_height(db_opts \\ %{}) do
+      entry = rooted_tip_entry(db_opts)
+      if entry do
+          entry.header_unpacked.height
+      end
+  end
+
+  def segment_vr_hash(db_opts \\ %{}) do
+    RocksDB.get("bic:epoch:segment_vr_hash", db_handle(db_opts, :contractstate, %{}))
+  end
+
+  def diff_bits(db_opts \\ %{}) do
+    RocksDB.get("bic:epoch:diff_bits", db_handle(db_opts, :contractstate, %{to_integer: true})) || 24
+  end
+
+  def total_sols(db_opts \\ %{}) do
+    RocksDB.get("bic:epoch:total_sols", db_handle(db_opts, :contractstate, %{to_integer: true})) || 0
+  end
+
+  def pop(pk, db_opts \\ %{}) do
+    RocksDB.get("bic:epoch:pop:#{pk}", db_handle(db_opts, :contractstate, %{}))
+  end
+
+  def nonce(pk, db_opts \\ %{}) do
+    RocksDB.get("bic:base:nonce:#{pk}", db_handle(db_opts, :contractstate, %{to_integer: true}))
+  end
+
+  def balance(pk, symbol \\ "AMA", db_opts \\ %{}) do
+    RocksDB.get("bic:coin:balance:#{pk}:#{symbol}", db_handle(db_opts, :contractstate, %{to_integer: true})) || 0
+  end
+
+  def tx(tx_hash, db_opts \\ %{}) do
+      map = RocksDB.get(tx_hash, db_handle(db_opts, :tx, %{}))
+      if map do
+          map = map |> RDB.vecpak_decode()
+          entry_bytes = RocksDB.get(map.entry_hash, db_handle(db_opts, :entry, %{}))
+          entry = DB.Entry.by_hash(map.entry_hash, db_opts)
+          tx_bytes = binary_part(entry_bytes, map.index_start, map.index_size)
+          TX.unpack(tx_bytes)
+          |> Map.put(:result, map[:result])
+          |> Map.put(:metadata, %{entry_hash: map.entry_hash, entry_height: entry.header_unpacked.height, entry_slot: entry.header_unpacked.slot})
+      end
+  end
+
+  # Validator
+  def is_validator(pk \\ nil, db_opts \\ %{}) do
+    pks = if pk do [pk] else
+      Application.fetch_env!(:ama, :keys_all_pks)
+    end
+    validators = validators_for_height(height()+1, db_opts)
+    delta = validators -- pks
+    length(validators) != length(delta)
+  end
+
+  def validators_for_height(height, db_opts \\ %{}) do
+    opts = db_handle(db_opts, :contractstate, %{term: true})
+    cond do
+        height in 3195570..3195575 ->
+            RocksDB.get("bic:epoch:trainers:height:000000319557", opts)
+        true ->
+            {_, value} = RocksDB.get_prev_or_first("bic:epoch:trainers:height:", pad_integer(height), opts)
+            value
+    end
+  end
+
+  def validators_for_hash(hash, db_opts \\ %{}) do
+    entry = DB.Entry.by_hash(hash)
+    if entry do validators_for_height(entry.header_unpacked.height, db_opts) end
+  end
+
+  def validators_for_height_my(height, db_opts \\ %{}) do
+    validators = validators_for_height(height, db_opts)
+    Application.fetch_env!(:ama, :keys)
+    |> Enum.filter(& &1.pk in validators)
+    |> Enum.map(& &1.pk)
+  end
+
+  def validator_for_height(height, db_opts \\ %{}) do
+    validators = validators_for_height(height, db_opts)
+    index = rem(height, length(validators))
+    Enum.at(validators, index)
+  end
+
+  def validator_for_height_current(db_opts \\ %{}) do
+    validator_for_height(height(db_opts), db_opts)
+  end
+
+  def validator_for_height_next(db_opts \\ %{}) do
+    validator_for_height(height(db_opts) + 1, db_opts)
+  end
+
+
+  #Rewind
+  def rewind(target_hash) do
+    %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
+    rtx = RocksDB.transaction(db)
+    in_chain = DB.Entry.in_chain(target_hash, %{rtx: rtx})
+    tip_entry = DB.Chain.tip_entry(%{rtx: rtx})
+
+    target_hash_entry = DB.Entry.by_hash(target_hash, %{rtx: rtx})
+    rooted_height = DB.Chain.rooted_height(%{rtx: rtx})
+
+    cond do
+      !in_chain or tip_entry.hash == target_hash ->
+        RocksDB.transaction_rollback(rtx)
+        false
+      target_hash_entry.header_unpacked.height < rooted_height ->
+        IO.inspect "cannot rewind finalized entry"
+        RocksDB.transaction_rollback(rtx)
+        false
+      true ->
+        rewind_1(tip_entry, target_hash, rtx)
+        RocksDB.put("temporal_tip", target_hash, %{rtx: rtx, cf: cf.sysconf})
+        :ok = RocksDB.transaction_commit(rtx)
+        true
+      end
+  end
+  defp rewind_1(current_entry, target_hash, rtx) do
+    m_rev = DB.Entry.muts_rev(current_entry.hash, %{rtx: rtx})
+    revert_muts(m_rev, %{rtx: rtx})
+
+    DB.Entry.delete_UNSAFE(current_entry.hash, %{rtx: rtx})
+    prev_hash = current_entry.header_unpacked.prev_hash
+    if prev_hash == target_hash do
+      :ok
+    else
+      rewind_1(DB.Entry.by_hash(prev_hash, %{rtx: rtx}), target_hash, rtx)
+    end
+  end
+
+  def revert_muts(m_rev, db_opts = %{rtx: _}) do
+    %{cf: cf} = :persistent_term.get({:rocksdb, Fabric})
+    Enum.reverse(m_rev)
+    |> Enum.each(fn(mut)->
+      op = :"#{mut.op}"
+      case op do
+        :put ->
+          RocksDB.put(mut.key, mut.value, %{rtx: db_opts.rtx, cf: cf.contractstate})
+        :delete ->
+          RocksDB.delete(mut.key, %{rtx: db_opts.rtx, cf: cf.contractstate})
+        :clear_bit ->
+          old_value = RocksDB.get(mut.key, %{rtx: db_opts.rtx, cf: cf.contractstate})
+          << left::size(mut.value), _old_bit::size(1), right::bitstring >> = old_value
+          new_value = << left::size(mut.value), 0::size(1), right::bitstring >>
+          RocksDB.put(mut.key, new_value, %{rtx: db_opts.rtx, cf: cf.contractstate})
+      end
+    end)
+  end
+end
diff --git a/ex/lib/api/db_entry.ex b/ex/lib/api/db_entry.ex
new file mode 100644
index 0000000..fc494a2
--- /dev/null
+++ b/ex/lib/api/db_entry.ex
@@ -0,0 +1,158 @@
+defmodule DB.Entry do
+  import DB.API
+
+  def by_hash(hash, db_opts \\ %{}) do
+    RocksDB.get(hash, db_handle(db_opts, :entry, %{}))
+    |> Entry.unpack_from_db()
+  end
+
+  def fix_entry(hash, db_opts \\ %{}) do
+    e = RocksDB.get(hash, db_handle(db_opts, :entry, %{}))
+    |> Entry.unpack_from_db()
+    if is_binary(e.header_unpacked) do
+      if e[:mask] do IO.inspect(e, limit: 11111111); throw %{error: :has_mask} end
+      entry = Map.put(e, :header, :erlang.binary_to_term(e.header_unpacked))
+      entry = Map.put(e, :header_unpacked, :erlang.binary_to_term(e.header_unpacked))
+      entry_packed = Entry.pack_for_db(entry)
+      RocksDB.put(entry.hash, entry_packed, db_handle(db_opts, :entry, %{}))
+    end
+  end
+
+  def by_height(height, db_opts \\ %{}) do
+    RocksDB.get_prefix("by_height:#{pad_integer(height)}:", db_handle(db_opts, :entry_meta, %{}))
+    |> Enum.map(& by_hash(elem(&1,0), db_opts) )
+  end
+
+  def by_height_return_hashes(height, db_opts \\ %{}) do
+    RocksDB.get_prefix("by_height:#{pad_integer(height)}:", db_handle(db_opts, :entry_meta, %{}))
+    |> Enum.map(& elem(&1,0))
+  end
+
+  def by_height_in_main_chain(height, db_opts \\ %{}) do
+    RocksDB.get("by_height_in_main_chain:#{pad_integer(height)}", db_handle(db_opts, :entry_meta, %{}))
+  end
+
+  def seentime(hash, db_opts \\ %{}) do
+    RocksDB.get("entry:#{hash}:seentime", db_handle(db_opts, :entry_meta, %{to_integer: true}))
+  end
+
+  def muts_hash(hash, db_opts \\ %{}) do
+    RocksDB.get("entry:#{hash}:muts_hash", db_handle(db_opts, :entry_meta, %{}))
+  end
+
+  def prev(hash, db_opts \\ %{}) do
+    RocksDB.get("entry:#{hash}:prev", db_handle(db_opts, :entry_meta, %{}))
+  end
+
+  def next(hash, db_opts \\ %{}) do
+    RocksDB.get("entry:#{hash}:next", db_handle(db_opts, :entry_meta, %{}))
+  end
+
+  def in_chain(hash, db_opts \\ %{}) do
+    !!RocksDB.get("entry:#{hash}:in_chain", db_handle(db_opts, :entry_meta, %{}))
+  end
+
+  def muts(hash, db_opts \\ %{}) do
+    RocksDB.get("entry:#{hash}:muts", db_handle(db_opts, :entry_meta, %{}))
+    |> RDB.vecpak_decode()
+  end
+
+  def muts_rev(hash, db_opts \\ %{}) do
+    RocksDB.get("entry:#{hash}:muts_rev", db_handle(db_opts, :entry_meta, %{}))
+    |> RDB.vecpak_decode()
+  end
+
+  def insert(entry, db_opts \\ %{}) when is_map(entry) do
+    db_opts = if db_opts[:rtx] do db_opts else
+      %{db: db, cf: _cf} = :persistent_term.get({:rocksdb, Fabric})
+      rtx = RocksDB.transaction(db)
+      db_opts = Map.put(db_opts, :rtx, rtx)
+      Map.put(db_opts, :rtx_commit, true)
+    end
+
+    entry_packed = Entry.pack_for_db(entry)
+    if !by_hash(entry.hash, db_opts) do
+      RocksDB.put(entry.hash, entry_packed, db_handle(db_opts, :entry, %{}))
+      RocksDB.put("by_height:#{pad_integer(entry.header_unpacked.height)}:#{entry.hash}", entry.hash, db_handle(db_opts, :entry_meta, %{}))
+      RocksDB.put("entry:#{entry.hash}:seentime", :os.system_time(1000), db_handle(db_opts, :entry_meta, %{to_integer: true}))
+    end
+
+    db_opts[:rtx_commit] && RocksDB.transaction_commit(db_opts.rtx)
+  end
+
+  def apply_into_main_chain(entry, muts_hash, muts_rev, receipts, db_opts = %{rtx: _}) do
+    entry_packed = Entry.pack_for_db(entry)
+    RocksDB.put(entry.hash, entry_packed, db_handle(db_opts, :entry, %{}))
+    RocksDB.put("by_height:#{pad_integer(entry.header_unpacked.height)}:#{entry.hash}", entry.hash, db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.put("by_height_in_main_chain:#{pad_integer(entry.header_unpacked.height)}", entry.hash, db_handle(db_opts, :entry_meta, %{}))
+    #RocksDB.put("entry:#{entry.hash}:seentime", :os.system_time(1000), db_handle(db_opts, :entry_meta, %{to_integer: true}))
+    RocksDB.put("entry:#{entry.hash}:prev", entry.header_unpacked.prev_hash, db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.put("entry:#{entry.header_unpacked.prev_hash}:next", entry.hash, db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.put("entry:#{entry.hash}:in_chain", "", db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.put("entry:#{entry.hash}:muts_hash", muts_hash, db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.put("entry:#{entry.hash}:muts_rev", RDB.vecpak_encode(muts_rev), db_handle(db_opts, :entry_meta, %{}))
+
+    Enum.each(Enum.zip(entry.txs, receipts), fn({tx_packed, result})->
+        txu = TX.unpack(tx_packed)
+        case :binary.match(entry_packed, tx_packed) do
+          {index_start, index_size} ->
+            tx_ptr = %{entry_hash: entry.hash, result: result, index_start: index_start, index_size: index_size}
+            |> RDB.vecpak_encode()
+            RocksDB.put(txu.hash, tx_ptr, db_handle(db_opts, :tx, %{}))
+
+            nonce_padded = pad_integer_20(txu.tx.nonce)
+            RocksDB.put("#{txu.tx.signer}:#{nonce_padded}", txu.hash, db_handle(db_opts, :tx_account_nonce, %{}))
+            TX.known_receivers(txu)
+            |> Enum.each(fn(receiver)->
+                RocksDB.put("#{receiver}:#{nonce_padded}", txu.hash, db_handle(db_opts, :tx_receiver_nonce, %{}))
+            end)
+        end
+    end)
+  end
+
+  def apply_into_main_chain_muts(hash, muts, db_opts = %{rtx: _}) do
+    RocksDB.put("entry:#{hash}:muts", RDB.vecpak_encode(muts), db_handle(db_opts, :entry_meta, %{}))
+  end
+
+  def delete_UNSAFE(_a, _db_opts \\ %{})
+  def delete_UNSAFE(nil, _db_opts) do nil end
+  def delete_UNSAFE(hash, db_opts) when is_binary(hash) do
+    entry = by_hash(hash)
+    delete_UNSAFE(entry, db_opts)
+  end
+  def delete_UNSAFE(entry, db_opts = %{rtx: _}) when is_map(entry) do
+    hash = entry.hash
+
+    RocksDB.delete(hash, db_handle(db_opts, :entry, %{}))
+
+    height_padded = pad_integer(entry.header_unpacked.height)
+    main_chain_hash = RocksDB.get("by_height_in_main_chain:#{height_padded}", db_handle(db_opts, :entry_meta, %{}))
+    if hash == main_chain_hash do
+      RocksDB.delete("by_height_in_main_chain:#{height_padded}", db_handle(db_opts, :entry_meta, %{}))
+      RocksDB.delete("entry:#{entry.header_unpacked.prev_hash}:next", db_handle(db_opts, :entry_meta, %{}))
+    end
+    RocksDB.delete("by_height:#{height_padded}:#{hash}", db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.delete("entry:#{hash}:seentime", db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.delete("entry:#{hash}:muts_hash", db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.delete("entry:#{hash}:prev", db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.delete("entry:#{hash}:next", db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.delete("entry:#{hash}:in_chain", db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.delete("entry:#{hash}:muts", db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.delete("entry:#{hash}:muts_rev", db_handle(db_opts, :entry_meta, %{}))
+    RocksDB.delete_prefix("consensus:#{hash}:", db_handle(db_opts, :attestation, %{}))
+    RocksDB.delete_prefix("attestation:#{height_padded}:#{hash}:", db_handle(db_opts, :attestation, %{}))
+
+    Enum.each(entry.txs, fn(tx_packed)->
+        txu = TX.unpack(tx_packed)
+        RocksDB.delete(txu.hash, db_handle(db_opts, :tx, %{}))
+
+        nonce_padded = pad_integer_20(txu.tx.nonce)
+        RocksDB.delete("#{txu.tx.signer}:#{nonce_padded}", db_handle(db_opts, :tx_account_nonce, %{}))
+        TX.known_receivers(txu)
+        |> Enum.each(fn(receiver)->
+            RocksDB.delete("#{receiver}:#{nonce_padded}", db_handle(db_opts, :tx_receiver_nonce, %{}))
+        end)
+    end)
+  end
+
+end
diff --git a/ex/lib/api/rpc_api.ex b/ex/lib/api/rpc_api.ex
index f13b20e..d1352a6 100644
--- a/ex/lib/api/rpc_api.ex
+++ b/ex/lib/api/rpc_api.ex
@@ -2,15 +2,17 @@ defmodule RPC.API do
   def get(path) do
     url = Application.fetch_env!(:ama, :rpc_url)
     {:ok, %{status_code: 200, body: body}} = :comsat_http.get(url <> path, %{},
-      %{ssl_options: [{:server_name_indication, '#{URI.parse(url).host}'}, {:verify, :verify_none}]})
+      %{ssl_options: [{:server_name_indication, ~c"#{URI.parse(url).host}"}, {:verify, :verify_none}]})
     JSX.decode!(body, labels: :attempt_atom)
   end
 
   defmodule Wallet do
     def transfer(seed64, receiver, amount_float, symbol \\ "AMA") do
-      if !BlsEx.validate_public_key(receiver) and receiver != @burn_address do
-        IO.inspect {"sending #{amount_float} AMA to invalid public key", receiver}
-        %{error: :invalid_public_key, pk: receiver}
+      receiver = if byte_size(receiver) != 48, do: Base58.decode(receiver), else: receiver
+      receiver_b58 = Base58.encode(receiver)
+      if !BlsEx.validate_public_key(receiver) and receiver != BIC.Coin.burn_address() do
+        IO.inspect {"sending #{amount_float} AMA to invalid public key", receiver_b58}
+        %{error: :invalid_public_key, pk: receiver_b58}
       else
         tx_packed = API.Wallet.transfer(seed64, receiver, amount_float, symbol, false)
         RPC.API.get("/api/tx/submit/#{Base58.encode(tx_packed)}")
@@ -20,20 +22,25 @@ defmodule RPC.API do
     def transfer_bulk(seed64, receiver_amount_list) do
       Enum.map(receiver_amount_list, fn
         {receiver, amount_float} ->
-          if !BlsEx.validate_public_key(receiver) and receiver != @burn_address do
-            IO.inspect {"sending #{amount_float} AMA to invalid public key", receiver}
-            %{error: :invalid_public_key, pk: receiver}
+          receiver = if byte_size(receiver) != 48, do: Base58.decode(receiver), else: receiver
+          receiver_b58 = Base58.encode(receiver)
+          if !BlsEx.validate_public_key(receiver) and receiver != BIC.Coin.burn_address() do
+            IO.inspect {"sending #{amount_float} AMA to invalid public key", receiver_b58}
+            %{error: :invalid_public_key, pk: receiver_b58}
           else
-            IO.inspect {"sending #{amount_float} AMA to ", receiver}
+            IO.inspect {"sending #{amount_float} AMA to ", receiver_b58}
             tx_packed = API.Wallet.transfer(seed64, receiver, amount_float, "AMA", false)
             RPC.API.get("/api/tx/submit/#{Base58.encode(tx_packed)}")
           end
+
         {receiver, amount_float, symbol} ->
-          if !BlsEx.validate_public_key(receiver) and receiver != @burn_address do
-            IO.inspect {"sending #{amount_float} AMA to invalid public key", receiver}
-            %{error: :invalid_public_key, pk: receiver}
+          receiver = if byte_size(receiver) != 48, do: Base58.decode(receiver), else: receiver
+          receiver_b58 = Base58.encode(receiver)
+          if !BlsEx.validate_public_key(receiver) and receiver != BIC.Coin.burn_address() do
+            IO.inspect {"sending #{amount_float} AMA to invalid public key", receiver_b58}
+            %{error: :invalid_public_key, pk: receiver_b58}
           else
-            IO.inspect {"sending #{amount_float} #{symbol} to ", receiver}
+            IO.inspect {"sending #{amount_float} #{symbol} to ", receiver_b58}
             tx_packed = API.Wallet.transfer(seed64, receiver, amount_float, symbol, false)
             RPC.API.get("/api/tx/submit/#{Base58.encode(tx_packed)}")
           end
diff --git a/ex/lib/bic/coin_symbol_reserved.ex b/ex/lib/bic/coin_symbol_reserved.ex
index 05a3920..6f9a0df 100644
--- a/ex/lib/bic/coin_symbol_reserved.ex
+++ b/ex/lib/bic/coin_symbol_reserved.ex
@@ -48,7 +48,6 @@ defmodule BIC.CoinSymbolReserved do
         "CBBTC" => true,
         "WEETH" => true,
         "PEPE" => true,
-        "DAI" => true,
         "APT" => true,
         "SUSDS" => true,
         "OKB" => true,
@@ -96,7 +95,6 @@ defmodule BIC.CoinSymbolReserved do
         "BNSOL" => true,
         "XDC" => true,
         "OP" => true,
-        "WETH" => true,
         "EOS" => true,
         "VIRTUAL" => true,
         "FARTCOIN" => true,
@@ -120,7 +118,6 @@ defmodule BIC.CoinSymbolReserved do
         "PAXG" => true,
         "IOTA" => true,
         "MSOL" => true,
-        "WBTC" => true,
         "FLOKI" => true,
         "CLBTC" => true,
         "JUPSOL" => true,
@@ -168,7 +165,6 @@ defmodule BIC.CoinSymbolReserved do
         "AIOZ" => true,
         "RUNE" => true,
         "DYDX" => true,
-        "USDC.E" => true,
         "OUSG" => true,
         "PUMPBTC" => true,
         "KAVA" => true,
@@ -179,7 +175,6 @@ defmodule BIC.CoinSymbolReserved do
         "XEC" => true,
         "MOVE" => true,
         "NFT" => true,
-        "WETH" => true,
         "NEO" => true,
         "GRASS" => true,
         "USYC" => true,
@@ -194,7 +189,6 @@ defmodule BIC.CoinSymbolReserved do
         "CHZ" => true,
         "MATIC" => true,
         "CFX" => true,
-        "WETH" => true,
         "BERA" => true,
         "W" => true,
         "OHM" => true,
@@ -221,7 +215,6 @@ defmodule BIC.CoinSymbolReserved do
         "FRAX" => true,
         "RLUSD" => true,
         "SUPER" => true,
-        "WBTC" => true,
         "CTC" => true,
         "CHEEMS" => true,
         "KET" => true,
@@ -260,7 +253,6 @@ defmodule BIC.CoinSymbolReserved do
         "GHO" => true,
         "ZIL" => true,
         "ABTC" => true,
-        "WETH" => true,
         "BTSE" => true,
         "EIGEN" => true,
         "NOT" => true,
@@ -281,7 +273,6 @@ defmodule BIC.CoinSymbolReserved do
         "BAT" => true,
         "KDA" => true,
         "SAVAX" => true,
-        "USDC.E" => true,
         "BBSOL" => true,
         "ZETA" => true,
         "ASTR" => true,
@@ -329,7 +320,6 @@ defmodule BIC.CoinSymbolReserved do
         "PNUT" => true,
         "TETH" => true,
         "HMSTR" => true,
-        "DAI" => true,
         "$RCGE" => true,
         "POLYX" => true,
         "CET" => true,
@@ -365,7 +355,6 @@ defmodule BIC.CoinSymbolReserved do
         "EURS" => true,
         "ZBCN" => true,
         "SQD" => true,
-        "WETH" => true,
         "ME" => true,
         "RLB" => true,
         "CUSDO" => true,
@@ -390,7 +379,6 @@ defmodule BIC.CoinSymbolReserved do
         "GOHOME" => true,
         "AMAPT" => true,
         "CETUS" => true,
-        "USDC" => true,
         "STEAKUSDC" => true,
         "ZKJ" => true,
         "ACH" => true,
@@ -429,14 +417,12 @@ defmodule BIC.CoinSymbolReserved do
         "NKYC" => true,
         "BDCA" => true,
         "ARDR" => true,
-        "HONEY" => true,
         "VVV" => true,
         "GAL" => true,
         "WAVES" => true,
         "MASK" => true,
         "DAKU" => true,
         "BICO" => true,
-        "USDC.E" => true,
         "FLUX" => true,
         "BIO" => true,
         "VCNT" => true,
@@ -497,7 +483,6 @@ defmodule BIC.CoinSymbolReserved do
         "POWR" => true,
         "CGPT" => true,
         "IQ" => true,
-        "WBTC" => true,
         "ACX" => true,
         "MANTA" => true,
         "SPELL" => true,
@@ -529,7 +514,6 @@ defmodule BIC.CoinSymbolReserved do
         "USTBL" => true,
         "WAXP" => true,
         "ZENT" => true,
-        "FRXUSD" => true,
         "DKA" => true,
         "OETH" => true,
         "GFI" => true,
@@ -559,7 +543,6 @@ defmodule BIC.CoinSymbolReserved do
         "DOGS" => true,
         "RSWETH" => true,
         "RUSD" => true,
-        "USDX" => true,
         "DENT" => true,
         "UNP" => true,
         "AUCTION" => true,
@@ -591,7 +574,6 @@ defmodule BIC.CoinSymbolReserved do
         "0X0" => true,
         "MTL" => true,
         "IAG" => true,
-        "WETH" => true,
         "WCT" => true,
         "PTGC" => true,
         "SOLVBTC.CORE" => true,
@@ -614,13 +596,11 @@ defmodule BIC.CoinSymbolReserved do
         "GRIFFAIN" => true,
         "DESO" => true,
         "ACS" => true,
-        "NEIRO" => true,
         "DIA" => true,
         "XAI" => true,
         "BGSC" => true,
         "TON" => true,
         "BITCOIN" => true,
-        "WETH" => true,
         "B2M" => true,
         "ERG" => true,
         "OCEAN" => true,
@@ -639,11 +619,8 @@ defmodule BIC.CoinSymbolReserved do
         "IGT" => true,
         "OMI" => true,
         "USUALX" => true,
-        "BUSD" => true,
         "VANRY" => true,
         "PONKE" => true,
-        "WSTETH" => true,
-        "USDC.E" => true,
         "UDS" => true,
         "ARC" => true,
         "WOLF" => true,
@@ -699,19 +676,15 @@ defmodule BIC.CoinSymbolReserved do
         "FUN" => true,
         "JNFTC" => true,
         "AXGT" => true,
-        "MIM" => true,
         "BB" => true,
         "AGETH" => true,
-        "WBTC" => true,
         "USD+" => true,
         "USDM" => true,
         "FIUSD" => true,
-        "ACT" => true,
         "ANT" => true,
         "MEMEFI" => true,
         "PARTI" => true,
         "TRU" => true,
-        "WETH" => true,
         "HT" => true,
         "TNSR" => true,
         "SHELL" => true,
@@ -727,21 +700,15 @@ defmodule BIC.CoinSymbolReserved do
         "BANANAS31" => true,
         "APEX" => true,
         "SN" => true,
-        "WEETH" => true,
-        "EOS" => true,
         "MERL" => true,
         "TOKEN" => true,
         "CYBER" => true,
-        "USDC.E" => true,
-        "WETH" => true,
         "KTA" => true,
         "ZEREBRO" => true,
         "AVL" => true,
-        "USDC" => true,
         "FWOG" => true,
         "KEEP" => true,
         "USD3" => true,
-        "VELO" => true,
         "DODO" => true,
         "OLAS" => true,
         "METAL" => true,
@@ -749,9 +716,7 @@ defmodule BIC.CoinSymbolReserved do
         "AVA" => true,
         "SHX" => true,
         "LADYS" => true,
-        "GAME" => true,
         "MBL" => true,
-        "WBTC" => true,
         "WZRD" => true,
         "LUSD" => true,
         "RAIL" => true,
@@ -781,7 +746,6 @@ defmodule BIC.CoinSymbolReserved do
         "ANVL" => true,
         "WSTUSR" => true,
         "STMX" => true,
-        "AVAX" => true,
         "OXT" => true,
         "META" => true,
         "EWT" => true,
@@ -832,7 +796,6 @@ defmodule BIC.CoinSymbolReserved do
         "GPS" => true,
         "BC" => true,
         "MNDE" => true,
-        "FARTCOIN" => true,
         "THAPT" => true,
         "NEURAL" => true,
         "TLOS" => true,
@@ -847,7 +810,6 @@ defmodule BIC.CoinSymbolReserved do
         "CUSD" => true,
         "ALEX" => true,
         "BOBA" => true,
-        "BB" => true,
         "SWEAT" => true,
         "CUSDC" => true,
         "HBD" => true,
@@ -865,7 +827,6 @@ defmodule BIC.CoinSymbolReserved do
         "RSC" => true,
         "LMWR" => true,
         "USDT" => true,
-        "USDC" => true,
         "ASM" => true,
         "DEP" => true,
         "SLERF" => true,
diff --git a/ex/lib/bic/contract.ex b/ex/lib/bic/contract.ex
index 7689a2a..a39fed2 100644
--- a/ex/lib/bic/contract.ex
+++ b/ex/lib/bic/contract.ex
@@ -3,7 +3,7 @@ defmodule BIC.Contract do
 
     def validate(wasmbytes, env \\ nil) do
         env = if env do Map.put(env, :readonly, true) else
-            env = Consensus.make_mapenv(EntryGenesis.get())
+            env = FabricGen.make_mapenv(EntryGenesis.get())
 
             Map.merge(env, %{
                 readonly: true,
diff --git a/ex/lib/bic/epoch.ex b/ex/lib/bic/epoch.ex
index e88ada8..61b59a3 100644
--- a/ex/lib/bic/epoch.ex
+++ b/ex/lib/bic/epoch.ex
@@ -280,7 +280,8 @@ defmodule BIC.Epoch do
     end
 
     def slash_trainer_verify(cur_epoch, malicious_pk, trainers, mask, signature) do
-        signers = BLS12AggSig.unmask_trainers(trainers, mask)
+        signers = BLS12AggSig.unmask_trainers(trainers, Util.pad_bitstring_to_bytes(mask), bit_size(mask))
+
         consensus_pct = length(signers) / length(trainers)
 
         apk = BlsEx.aggregate_public_keys!(signers)
@@ -306,7 +307,8 @@ defmodule BIC.Epoch do
         if malicious_pk not in trainers, do: throw(%{error: :invalid_trainer_pk})
 
         # 75% vote
-        signers = BLS12AggSig.unmask_trainers(trainers, mask)
+        signers = BLS12AggSig.unmask_trainers(trainers, Util.pad_bitstring_to_bytes(mask), bit_size(mask))
+
         consensus_pct = length(signers) / length(trainers)
         if consensus_pct < 0.67, do: throw(%{error: :invalid_amount_of_signatures})
 
diff --git a/ex/lib/consensus/consensus.ex b/ex/lib/consensus/consensus.ex
deleted file mode 100644
index 252f6ca..0000000
--- a/ex/lib/consensus/consensus.ex
+++ /dev/null
@@ -1,659 +0,0 @@
-defmodule Consensus do
-    def unpack(consensus_packed) when is_binary(consensus_packed) do
-        :erlang.binary_to_term(consensus_packed, [:safe])
-        |> unpack()
-    end
-    def unpack(consensus_packed) when is_map(consensus_packed) do
-        consensus_packed
-        |> Map.take([:entry_hash, :mutations_hash, :mask, :aggsig])
-    end
-
-
-    def pack(consensus_packed) when is_binary(consensus_packed) do consensus_packed end
-    def pack(consensus_packed) do
-        consensus_packed
-        |> Map.take([:entry_hash, :mutations_hash, :mask, :aggsig])
-        |> :erlang.term_to_binary([:deterministic])
-    end
-
-    def validate_vs_chain(c) do
-        try do
-        to_sign = <<c.entry_hash::binary, c.mutations_hash::binary>>
-
-        entry = Fabric.entry_by_hash(c.entry_hash)
-        if !entry, do: throw(%{error: :invalid_entry})
-        if entry.header_unpacked.height > Consensus.chain_height(), do: throw(%{error: :too_far_in_future})
-
-        #TODO: race here if entry is not proced
-        trainers = trainers_for_height(Entry.height(entry))
-        score = BLS12AggSig.score(trainers, c.mask)
-
-        trainers_signed = BLS12AggSig.unmask_trainers(trainers, c.mask)
-        aggpk = BlsEx.aggregate_public_keys!(trainers_signed)
-        if !BlsEx.verify?(aggpk, c.aggsig, to_sign, BLS12AggSig.dst_att()), do: throw(%{error: :invalid_signature})
-
-        c = Map.put(c, :score, score)
-        %{error: :ok, consensus: c}
-        catch
-            :throw,r -> r
-            e,r -> IO.inspect {Consensus, :validate, e, r, __STACKTRACE__}; %{error: :unknown}
-        end
-    end
-
-    def is_trainer() do
-        Application.fetch_env!(:ama, :trainer_pk) in trainers_for_height(chain_height()+1)
-    end
-
-    def trainers_for_height(height, opts \\ %{}) do
-        options = if opts[:rtx] do
-            %{rtx: opts.rtx, cf: opts.cf.contractstate, term: true}
-        else
-            %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-            %{db: db, cf: cf.contractstate, term: true}
-        end
-
-        cond do
-            height in 3195570..3195575 ->
-                RocksDB.get("bic:epoch:trainers:height:000000319557", options)
-            true ->
-                {_, value} = RocksDB.get_prev_or_first("bic:epoch:trainers:height:", String.pad_leading("#{height}", 12, "0"), options)
-                value
-        end
-    end
-
-    def trainer_for_slot(height, slot) do
-        trainers = trainers_for_height(height)
-        index = rem(slot, length(trainers))
-        Enum.at(trainers, index)
-    end
-
-    def trainer_for_slot_current() do
-        trainer_for_slot(chain_height(), chain_height())
-    end
-
-    def trainer_for_slot_next() do
-        trainer_for_slot(chain_height()+1, chain_height()+1)
-    end
-
-    def trainer_for_slot_next_me?() do
-        pk = Application.fetch_env!(:ama, :trainer_pk)
-        pk == trainer_for_slot_next()
-    end
-
-    def did_trainer_sign_consensus(trainer, entry_hash) do
-        c = Fabric.consensuses_by_entryhash(entry_hash)
-        if c do
-            entry = Fabric.entry_by_hash(entry_hash)
-            trainers = trainers_for_height(entry.header_unpacked.height)
-            res = Enum.reject(c, fn {_mut_hash, %{mask: mask}}->
-                signed = BLS12AggSig.unmask_trainers(trainers, mask)
-                trainer in signed
-            end)
-            res == []
-        end
-    end
-
-    def missing_signatures_for_consensus() do
-      %{hash: hash, header_unpacked: %{height: height}} = Consensus.chain_tip_entry()
-      trainers = Consensus.trainers_for_height(height)
-      consensuses = Fabric.consensuses_by_entryhash(hash)
-      {_, _score, c} = Consensus.best_by_weight(trainers, consensuses)
-      trainers_signed = BLS12AggSig.unmask_trainers(trainers, c.mask)
-      trainers -- trainers_signed
-    end
-
-    #def next_trainer_slot_in_x_slots(pk, epoch, slot, acc \\ 0) do
-    #    trainer = Consensus.trainer_for_slot(epoch, slot + acc)
-    #    cond do
-    #        acc >= 128 -> nil
-    #        pk == trainer -> acc
-    #        true -> next_trainer_slot_in_x_slots(pk, epoch, slot, acc + 1)
-    #    end
-    #end
-
-    def chain_height() do
-        entry = chain_tip_entry()
-        entry.header_unpacked.height
-    end
-
-    def chain_epoch() do
-        div(chain_height(), 100_000)
-    end
-
-    def chain_segment_vr_hash() do
-      %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-      RocksDB.get("bic:epoch:segment_vr_hash", %{db: db, cf: cf.contractstate})
-    end
-
-    def chain_diff_bits() do
-      %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-      RocksDB.get("bic:epoch:diff_bits", %{db: db, cf: cf.contractstate, to_integer: true}) || 24
-    end
-
-    def chain_total_sols() do
-      %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-      RocksDB.get("bic:epoch:total_sols", %{db: db, cf: cf.contractstate, to_integer: true}) || 0
-    end
-
-    def chain_pop(pk) do
-      %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-      RocksDB.get("bic:epoch:pop:#{pk}", %{db: db, cf: cf.contractstate})
-    end
-
-    def chain_nonce(pk) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get("bic:base:nonce:#{pk}", %{db: db, cf: cf.contractstate, to_integer: true})
-    end
-
-    def chain_balance(pk, symbol \\ "AMA") do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get("bic:coin:balance:#{pk}:#{symbol}", %{db: db, cf: cf.contractstate, to_integer: true}) || 0
-    end
-
-    def chain_tip() do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get("temporal_tip", %{db: db, cf: cf.sysconf})
-    end
-
-    def chain_tip_entry() do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get(chain_tip(), %{db: db, cf: cf.entry, term: true})
-        |> Entry.unpack()
-    end
-
-    def chain_muts_rev(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get(hash, %{db: db, cf: cf.muts_rev ,term: true})
-    end
-
-    def chain_muts(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get(hash, %{db: db, cf: cf.muts ,term: true})
-    end
-
-    def chain_rewind(target_hash) do
-        in_chain = Consensus.is_in_chain(target_hash)
-        cond do
-            !in_chain -> false
-            true ->
-                %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-                rtx = RocksDB.transaction(db)
-                Process.put({RocksDB, :ctx}, %{rtx: rtx, cf: cf})
-
-                tip_entry = Consensus.chain_tip_entry()
-                entry = chain_rewind_1(tip_entry, target_hash)
-
-                RocksDB.put("temporal_tip", entry.hash, %{rtx: rtx, cf: cf.sysconf})
-                RocksDB.put("temporal_height", entry.header_unpacked.height, %{rtx: rtx, cf: cf.sysconf, term: true})
-
-                rooted_hash = RocksDB.get("rooted_tip", %{rtx: rtx, cf: cf.sysconf})
-                rooted_entry = RocksDB.get(rooted_hash, %{rtx: rtx, cf: cf.entry})
-                if !rooted_entry do
-                    RocksDB.put("rooted_tip", entry.hash, %{rtx: rtx, cf: cf.sysconf})
-                end
-
-                :ok = RocksDB.transaction_commit(rtx)
-
-                true
-        end
-    end
-    defp chain_rewind_1(current_entry, target_hash) do
-        m_rev = Consensus.chain_muts_rev(current_entry.hash)
-        ConsensusKV.revert(m_rev)
-
-        %{rtx: rtx, cf: cf} = Process.get({RocksDB, :ctx})
-        RocksDB.delete(current_entry.hash, %{rtx: rtx, cf: cf.entry})
-        RocksDB.delete(current_entry.hash, %{rtx: rtx, cf: cf.my_seen_time_for_entry})
-        RocksDB.delete("#{current_entry.header_unpacked.height}:#{current_entry.hash}", %{rtx: rtx, cf: cf.entry_by_height})
-        RocksDB.delete("#{current_entry.header_unpacked.slot}:#{current_entry.hash}", %{rtx: rtx, cf: cf.entry_by_slot})
-        RocksDB.delete(current_entry.hash, %{rtx: rtx, cf: cf.consensus_by_entryhash})
-        RocksDB.delete(current_entry.hash, %{rtx: rtx, cf: cf.my_attestation_for_entry})
-        Enum.each(current_entry.txs, fn(tx_packed)->
-            txu = TX.unpack(tx_packed)
-            RocksDB.delete(txu.hash, %{rtx: rtx, cf: cf.tx})
-            nonce_padded = String.pad_leading("#{txu.tx.nonce}", 20, "0")
-            RocksDB.delete("#{txu.tx.signer}:#{nonce_padded}", %{rtx: rtx, cf: cf.tx_account_nonce})
-            TX.known_receivers(txu)
-            |> Enum.each(fn(receiver)->
-                RocksDB.delete("#{receiver}:#{nonce_padded}", %{rtx: rtx, cf: cf.tx_receiver_nonce})
-            end)
-        end)
-
-        if current_entry.hash == target_hash do
-            prev_entry = Fabric.entry_by_hash_w_mutsrev(current_entry.header_unpacked.prev_hash)
-            if !prev_entry do
-                IO.puts "rewind catastrophically failed"
-                :erlang.halt()
-            else
-                prev_entry
-            end
-        else
-            case Fabric.entry_by_hash_w_mutsrev(current_entry.header_unpacked.prev_hash) do
-                nil ->
-                    IO.puts "rewind catastrophically failed"
-                    :erlang.halt()
-                #prev_entry = %{hash: ^target_hash} -> prev_entry
-                prev_entry -> chain_rewind_1(prev_entry, target_hash)
-            end
-        end
-    end
-
-    def chain_tx(tx_hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        map = RocksDB.get(tx_hash, %{db: db, cf: cf.tx ,term: true})
-        if map do
-            entry_bytes = RocksDB.get(map.entry_hash, %{db: db, cf: cf.entry})
-            entry = Fabric.entry_by_hash(map.entry_hash)
-            tx_bytes = binary_part(entry_bytes, map.index_start, map.index_size)
-            TX.unpack(tx_bytes)
-            |> Map.put(:result, map[:result])
-            |> Map.put(:metadata, %{entry_hash: map.entry_hash, entry_slot: entry.header_unpacked.slot})
-        end
-    end
-
-    def is_in_chain(target_hash) do
-        case Fabric.entry_by_hash_w_mutsrev(target_hash) do
-            nil -> false
-            %{header_unpacked: %{height: target_height}} ->
-                tip_entry = Consensus.chain_tip_entry()
-                tip_hash  = tip_entry.hash
-                tip_height = tip_entry.header_unpacked.height
-
-                if tip_height < target_height do
-                  false
-                else
-                  is_in_chain_1(tip_hash, target_hash, target_height)
-                end
-        end
-    end
-    defp is_in_chain_1(current_hash, target_hash, target_height) do
-        case Fabric.entry_by_hash_w_mutsrev(current_hash) do
-            nil -> false
-            %{hash: ^target_hash} -> true
-            %{header_unpacked: %{prev_hash: prev_hash, height: height}} ->
-                cond do
-                  height <= target_height -> false
-                  true -> is_in_chain_1(prev_hash, target_hash, target_height)
-                end
-        end
-    end
-
-    def best_by_weight(trainers, consensuses) do
-        maxScore = length(trainers)
-        Enum.reduce(consensuses, {nil,nil,nil}, fn({k,v}, {best,bestscore,bestval})->
-            trainers_signed = BLS12AggSig.unmask_trainers(trainers, v.mask)
-            score = Enum.reduce(trainers_signed, 0, fn(pk, acc)->
-                acc + ConsensusWeight.count(pk)
-            end)
-            score = score/maxScore
-            cond do
-                !best -> {k, score, v}
-                score > bestscore -> {k, score, v}
-                true -> {best,bestscore,bestval}
-            end
-        end)
-    end
-
-    def make_mapenv(next_entry) do
-        %{
-            :readonly => false,
-            :seed => nil,
-            :seedf64 => 1.0,
-            :entry_signer => next_entry.header_unpacked.signer,
-            :entry_prev_hash => next_entry.header_unpacked.prev_hash,
-            :entry_slot => next_entry.header_unpacked.slot,
-            :entry_prev_slot => next_entry.header_unpacked.prev_slot,
-            :entry_height => next_entry.header_unpacked.height,
-            :entry_epoch => div(next_entry.header_unpacked.height, 100_000),
-            :entry_vr => next_entry.header_unpacked.vr,
-            :entry_vr_b3 => Blake3.hash(next_entry.header_unpacked.vr),
-            :entry_dr => next_entry.header_unpacked.dr,
-            :tx_index => 0,
-            :tx_signer => nil, #env.txu.tx.signer,
-            :tx_nonce => nil, #env.txu.tx.nonce,
-            :tx_hash => nil, #env.txu.hash,
-            :account_origin => nil, #env.txu.tx.signer,
-            :account_caller => nil, #env.txu.tx.signer,
-            :account_current => nil, #action.contract,
-            :attached_symbol => "",
-            :attached_amount => "",
-            :call_counter => 0,
-            :call_exec_points => 10_000_000,
-            :call_exec_points_remaining => 10_000_000,
-        }
-    end
-
-    def apply_entry_old(next_entry) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-
-        {m, m_rev, l, mhash} = try do apply_entry(next_entry) catch _,_ -> {nil,nil,nil,nil} end
-
-        rtx = RocksDB.transaction(db)
-        height = RocksDB.get("temporal_height", %{rtx: rtx, cf: cf.sysconf, term: true})
-        if !height or (height + 1) == Entry.height(next_entry) do
-            apply_entry_old_1(next_entry, cf, rtx, {m, m_rev, l, mhash})
-        else
-            %{error: :invalid_height}
-        end
-    end
-    def apply_entry_old_1(next_entry, cf, rtx, lol) do
-        Process.put({RocksDB, :ctx}, %{rtx: rtx, cf: cf})
-
-        mapenv = make_mapenv(next_entry)
-
-        txus = Enum.map(next_entry.txs, & TX.unpack(&1))
-        {m_pre, m_rev_pre} = BIC.Base.call_txs_pre_parallel(mapenv, txus)
-
-        {m, m_rev, l} = Enum.reduce(Enum.with_index(txus), {m_pre, m_rev_pre, []}, fn({txu, tx_idx}, {m, m_rev, l})->
-            #ts_m = :os.system_time(1000)
-            mapenv = Map.merge(mapenv, %{tx_index: tx_idx, tx_signer: txu.tx.signer, tx_nonce: txu.tx.nonce, tx_hash: txu.hash,
-                account_origin: txu.tx.signer, account_caller: txu.tx.signer})
-            {m3, m_rev3, m3_gas, m3_gas_rev, result} = BIC.Base.call_tx_actions(mapenv, txu)
-            #IO.inspect {:call_tx, :os.system_time(1000) - ts_m}
-            if result[:error] == :ok do
-                m = m ++ m3 ++ m3_gas
-                m_rev = m_rev ++ m_rev3 ++ m3_gas_rev
-                {m, m_rev, l ++ [result]}
-            else
-                ConsensusKV.revert(m_rev3)
-                {m ++ m3_gas, m_rev ++ m3_gas_rev, l ++ [result]}
-            end
-        end)
-        {m_exit, m_exit_rev} = BIC.Base.call_exit(mapenv)
-
-        Process.delete(SolVerifiedCache)
-
-        m = m ++ m_exit
-        m_rev = m_rev ++ m_exit_rev
-
-        #TODO: store logs
-        #IO.inspect {l ++ m, ConsensusKV.hash_mutations(l ++ m)}, limit: 11111111
-        #IO.inspect {:real, next_entry.header_unpacked.height, m_rev, l, Base58.encode(ConsensusKV.hash_mutations(l ++ m))}
-        #File.write! "/tmp/real", inspect({:real, next_entry.header_unpacked.height, m, m_rev, l, Base58.encode(ConsensusKV.hash_mutations(l ++ m))}, pretty: true, limit: 11111111, printable_limit: 111111111) <> "\n", [:append]
-        #IO.inspect {:real, next_entry.header_unpacked.height, Base58.encode(ConsensusKV.hash_mutations(l ++ m))}
-
-        {m2, m_rev2, l2, mhash2} = lol
-        doit = ConsensusKV.hash_mutations(l ++ m ++ m_rev)
-        if doit != mhash2 do
-          File.write! "/tmp/real", inspect({:real, next_entry.header_unpacked.height, m, m_rev, l, Base58.encode(ConsensusKV.hash_mutations(l ++ m))}, pretty: true, limit: 11111111, printable_limit: 111111111) <> "\n", [:append]
-          if mhash2 != nil do
-            File.write! "/tmp/fake", inspect({:fake, next_entry.header_unpacked.height, m2, m_rev2, l2, Base58.encode(ConsensusKV.hash_mutations(l2 ++ m2))}, pretty: true, limit: 11111111, printable_limit: 111111111) <> "\n", [:append]
-          end
-        end
-
-        mutations_hash = ConsensusKV.hash_mutations(l ++ m)
-
-        attestation = Attestation.sign(next_entry.hash, mutations_hash)
-        attestation_packed = Attestation.pack(attestation)
-        RocksDB.put(next_entry.hash, attestation_packed, %{rtx: rtx, cf: cf.my_attestation_for_entry})
-
-        pk = Application.fetch_env!(:ama, :trainer_pk)
-        trainers = trainers_for_height(Entry.height(next_entry), %{rtx: rtx, cf: cf})
-        is_trainer = pk in trainers
-
-        seen_time = :os.system_time(1000)
-        RocksDB.put(next_entry.hash, seen_time, %{rtx: rtx, cf: cf.my_seen_time_for_entry, term: true})
-
-        RocksDB.put("temporal_tip", next_entry.hash, %{rtx: rtx, cf: cf.sysconf})
-        RocksDB.put("temporal_height", next_entry.header_unpacked.height, %{rtx: rtx, cf: cf.sysconf, term: true})
-        #:ok = :rocksdb.transaction_put(rtx, cf.my_mutations_hash_for_entry, next_entry.hash, mutations_hash)
-        RocksDB.put(next_entry.hash, m_rev, %{rtx: rtx, cf: cf.muts_rev, term: true})
-
-        entry_packed = RocksDB.get(next_entry.hash, %{rtx: rtx, cf: cf.entry})
-        Enum.each(Enum.zip(next_entry.txs, l), fn({tx_packed, result})->
-            txu = TX.unpack(tx_packed)
-            case :binary.match(entry_packed, tx_packed) do
-              {index_start, index_size} ->
-                value = %{entry_hash: next_entry.hash, result: result, index_start: index_start, index_size: index_size}
-                value = :erlang.term_to_binary(value, [:deterministic])
-                RocksDB.put(txu.hash, value, %{rtx: rtx, cf: cf.tx})
-
-                nonce_padded = String.pad_leading("#{txu.tx.nonce}", 20, "0")
-                RocksDB.put("#{txu.tx.signer}:#{nonce_padded}", txu.hash, %{rtx: rtx, cf: cf.tx_account_nonce})
-                TX.known_receivers(txu)
-                |> Enum.each(fn(receiver)->
-                    RocksDB.put("#{receiver}:#{nonce_padded}", txu.hash, %{rtx: rtx, cf: cf.tx_receiver_nonce})
-                end)
-            end
-        end)
-
-        if Application.fetch_env!(:ama, :archival_node) do
-            RocksDB.put(next_entry.hash, m, %{rtx: rtx, cf: cf.muts, term: true})
-        end
-
-        :ok = RocksDB.transaction_commit(rtx)
-
-        ap = if is_trainer do
-            #TODO: not ideal in super tight latency constrains but its 1 line and it works
-            send(FabricCoordinatorGen, {:add_attestation, attestation})
-            attestation_packed
-        end
-
-        %{error: :ok, attestation_packed: ap, mutations_hash: mutations_hash, logs: l, muts: m}
-    end
-
-    def apply_entry2(next_entry) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        height = RocksDB.get("temporal_height", %{db: db, cf: cf.sysconf, term: true})
-        if !height or (height + 1) == Entry.height(next_entry) do
-            apply_entry_2_1(next_entry)
-        else
-            %{error: :invalid_height}
-        end
-    end
-    def apply_entry_2_1(next_entry) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-
-        entry = next_entry
-        next_entry_trimmed_map = %{
-            entry_signer: entry.header_unpacked.signer,
-            entry_prev_hash: entry.header_unpacked.prev_hash,
-            entry_vr: entry.header_unpacked.vr,
-            entry_vr_b3: Blake3.hash(entry.header_unpacked.vr),
-            entry_dr: entry.header_unpacked.dr,
-            entry_slot: entry.header_unpacked.slot,
-            entry_prev_slot: entry.header_unpacked.prev_slot,
-            entry_height: entry.header_unpacked.height,
-            entry_epoch: div(entry.header_unpacked.height,100_000),
-        }
-        txus = Enum.map(entry.txs, & TX.unpack(&1))
-
-        {rtx, m, m_rev, l} = RDB.apply_entry(db, next_entry_trimmed_map, Application.fetch_env!(:ama, :trainer_pk), Application.fetch_env!(:ama, :trainer_sk), entry.txs, txus)
-        rebuild_m_fn = fn(m)->
-          Enum.map(m, fn(inner)->
-            op = :'#{IO.iodata_to_binary(inner[~c"op"])}'
-            case op do
-              :set_bit -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"]), value: :erlang.binary_to_integer("#{inner[~c"value"]}"), bloomsize: :erlang.binary_to_integer("#{inner[~c"bloomsize"]}")}
-              :clear_bit -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"]), value: :erlang.binary_to_integer("#{inner[~c"value"]}")}
-              :delete -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"])}
-              :put -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"]), value: IO.iodata_to_binary(inner[~c"value"])}
-            end
-          end)
-        end
-        rebuild_l_fn = fn(m)->
-          Enum.map(m, fn(inner)->
-            %{error: :"#{inner["error"]}"}
-          end)
-        end
-        m = rebuild_m_fn.(m)
-        m_rev = rebuild_m_fn.(m_rev)
-        l = rebuild_l_fn.(l)
-
-        #call the exit
-        Process.put({RocksDB, :ctx}, %{rtx: rtx, cf: cf})
-        mapenv = make_mapenv(next_entry)
-        {m_exit, m_exit_rev} = BIC.Base.call_exit(mapenv)
-        m = m ++ m_exit
-        m_rev = m_rev ++ m_exit_rev
-
-        RDB.transaction_rollback(rtx)
-        #IO.inspect {:fake, next_entry.header_unpacked.height, m, m_rev, l, Base58.encode(ConsensusKV.hash_mutations(l ++ m))}
-        File.write! "/tmp/fake", inspect({:fake, next_entry.header_unpacked.height, m, m_rev, l, Base58.encode(ConsensusKV.hash_mutations(l ++ m))}, pretty: true, limit: 11111111, printable_limit: 111111111) <> "\n", [:append]
-        IO.inspect {:fake, next_entry.header_unpacked.height, Base58.encode(ConsensusKV.hash_mutations(l ++ m))}
-        1/0
-
-        #TODO: store logs
-        #IO.inspect {l ++ m, ConsensusKV.hash_mutations(l ++ m)}, limit: 11111111
-        mutations_hash = ConsensusKV.hash_mutations(l ++ m)
-
-        attestation = Attestation.sign(next_entry.hash, mutations_hash)
-        attestation_packed = Attestation.pack(attestation)
-        RocksDB.put(next_entry.hash, attestation_packed, %{rtx: rtx, cf: cf.my_attestation_for_entry})
-
-        pk = Application.fetch_env!(:ama, :trainer_pk)
-        trainers = trainers_for_height(Entry.height(next_entry), %{rtx: rtx, cf: cf})
-        is_trainer = pk in trainers
-
-        seen_time = :os.system_time(1000)
-        RocksDB.put(next_entry.hash, seen_time, %{rtx: rtx, cf: cf.my_seen_time_for_entry, term: true})
-
-        RocksDB.put("temporal_tip", next_entry.hash, %{rtx: rtx, cf: cf.sysconf})
-        RocksDB.put("temporal_height", next_entry.header_unpacked.height, %{rtx: rtx, cf: cf.sysconf, term: true})
-        #:ok = :rocksdb.transaction_put(rtx, cf.my_mutations_hash_for_entry, next_entry.hash, mutations_hash)
-        RocksDB.put(next_entry.hash, m_rev, %{rtx: rtx, cf: cf.muts_rev, term: true})
-
-        entry_packed = RocksDB.get(next_entry.hash, %{rtx: rtx, cf: cf.entry})
-        Enum.each(Enum.zip(next_entry.txs, l), fn({tx_packed, result})->
-            txu = TX.unpack(tx_packed)
-            case :binary.match(entry_packed, tx_packed) do
-              {index_start, index_size} ->
-                value = %{entry_hash: next_entry.hash, result: result, index_start: index_start, index_size: index_size}
-                value = :erlang.term_to_binary(value, [:deterministic])
-                RocksDB.put(txu.hash, value, %{rtx: rtx, cf: cf.tx})
-
-                nonce_padded = String.pad_leading("#{txu.tx.nonce}", 20, "0")
-                RocksDB.put("#{txu.tx.signer}:#{nonce_padded}", txu.hash, %{rtx: rtx, cf: cf.tx_account_nonce})
-                TX.known_receivers(txu)
-                |> Enum.each(fn(receiver)->
-                    RocksDB.put("#{receiver}:#{nonce_padded}", txu.hash, %{rtx: rtx, cf: cf.tx_receiver_nonce})
-                end)
-            end
-        end)
-
-        if Application.fetch_env!(:ama, :archival_node) do
-            RocksDB.put(next_entry.hash, m, %{rtx: rtx, cf: cf.muts, term: true})
-        end
-
-        :ok = RocksDB.transaction_commit(rtx)
-
-        ap = if is_trainer do
-            #TODO: not ideal in super tight latency constrains but its 1 line and it works
-            send(FabricCoordinatorGen, {:add_attestation, attestation})
-            attestation_packed
-        end
-
-        %{error: :ok, attestation_packed: ap, mutations_hash: mutations_hash, logs: l, muts: m}
-    end
-
-    def apply_entry(next_entry) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        height = RocksDB.get("temporal_height", %{db: db, cf: cf.sysconf, term: true})
-        if !height or (height + 1) == Entry.height(next_entry) do
-            apply_entry_1(next_entry)
-        else
-            %{error: :invalid_height}
-        end
-    end
-    def apply_entry_1(next_entry) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-
-        entry = next_entry
-        next_entry_trimmed_map = %{
-            entry_signer: entry.header_unpacked.signer,
-            entry_prev_hash: entry.header_unpacked.prev_hash,
-            entry_vr: entry.header_unpacked.vr,
-            entry_vr_b3: Blake3.hash(entry.header_unpacked.vr),
-            entry_dr: entry.header_unpacked.dr,
-            entry_slot: entry.header_unpacked.slot,
-            entry_prev_slot: entry.header_unpacked.prev_slot,
-            entry_height: entry.header_unpacked.height,
-            entry_epoch: div(entry.header_unpacked.height,100_000),
-        }
-        txus = Enum.map(entry.txs, & TX.unpack(&1))
-
-        {rtx, m, m_rev, l} = RDB.apply_entry(db, next_entry_trimmed_map, Application.fetch_env!(:ama, :trainer_pk), Application.fetch_env!(:ama, :trainer_sk), entry.txs, txus)
-        rebuild_m_fn = fn(m)->
-          Enum.map(m, fn(inner)->
-            op = :'#{IO.iodata_to_binary(inner[~c"op"])}'
-            case op do
-              :set_bit -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"]), value: :erlang.binary_to_integer("#{inner[~c"value"]}"), bloomsize: :erlang.binary_to_integer("#{inner[~c"bloomsize"]}")}
-              :clear_bit -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"]), value: :erlang.binary_to_integer("#{inner[~c"value"]}")}
-              :delete -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"])}
-              :put -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"]), value: IO.iodata_to_binary(inner[~c"value"])}
-            end
-          end)
-        end
-        rebuild_l_fn = fn(m)->
-          Enum.map(m, fn(inner)->
-            %{error: :"#{IO.iodata_to_binary(inner["error"])}"}
-          end)
-        end
-        m = rebuild_m_fn.(m)
-        m_rev = rebuild_m_fn.(m_rev)
-        l = rebuild_l_fn.(l)
-
-        #call the exit
-        Process.put({RocksDB, :ctx}, %{rtx: rtx, cf: cf})
-        mapenv = make_mapenv(next_entry)
-        {m_exit, m_exit_rev} = BIC.Base.call_exit(mapenv)
-        m = m ++ m_exit
-        m_rev = m_rev ++ m_exit_rev
-
-        #{m, m_rev, l, ConsensusKV.hash_mutations(l ++ m ++ m_rev)}
-        mutations_hash = ConsensusKV.hash_mutations(l ++ m)
-
-        sk = Application.fetch_env!(:ama, :trainer_sk)
-        attestation = Attestation.sign(sk, next_entry.hash, mutations_hash)
-        attestation_packed = Attestation.pack(attestation)
-        RocksDB.put(next_entry.hash, attestation_packed, %{rtx: rtx, cf: cf.my_attestation_for_entry})
-
-        trainers = trainers_for_height(Entry.height(next_entry), %{rtx: rtx, cf: cf})
-        validator_seeds = Application.fetch_env!(:ama, :keys) |> Enum.filter(& &1.pk in trainers)
-
-        seen_time = :os.system_time(1000)
-        RocksDB.put(next_entry.hash, seen_time, %{rtx: rtx, cf: cf.my_seen_time_for_entry, term: true})
-
-        RocksDB.put("temporal_tip", next_entry.hash, %{rtx: rtx, cf: cf.sysconf})
-        RocksDB.put("temporal_height", next_entry.header_unpacked.height, %{rtx: rtx, cf: cf.sysconf, term: true})
-        #:ok = :rocksdb.transaction_put(rtx, cf.my_mutations_hash_for_entry, next_entry.hash, mutations_hash)
-        RocksDB.put(next_entry.hash, m_rev, %{rtx: rtx, cf: cf.muts_rev, term: true})
-
-        entry_packed = RocksDB.get(next_entry.hash, %{rtx: rtx, cf: cf.entry})
-        Enum.each(Enum.zip(next_entry.txs, l), fn({tx_packed, result})->
-            txu = TX.unpack(tx_packed)
-            case :binary.match(entry_packed, tx_packed) do
-              {index_start, index_size} ->
-                value = %{entry_hash: next_entry.hash, result: result, index_start: index_start, index_size: index_size}
-                value = :erlang.term_to_binary(value, [:deterministic])
-                RocksDB.put(txu.hash, value, %{rtx: rtx, cf: cf.tx})
-
-                nonce_padded = String.pad_leading("#{txu.tx.nonce}", 20, "0")
-                RocksDB.put("#{txu.tx.signer}:#{nonce_padded}", txu.hash, %{rtx: rtx, cf: cf.tx_account_nonce})
-                TX.known_receivers(txu)
-                |> Enum.each(fn(receiver)->
-                    RocksDB.put("#{receiver}:#{nonce_padded}", txu.hash, %{rtx: rtx, cf: cf.tx_receiver_nonce})
-                end)
-            end
-        end)
-
-        if Application.fetch_env!(:ama, :archival_node) do
-            RocksDB.put(next_entry.hash, m, %{rtx: rtx, cf: cf.muts, term: true})
-        end
-
-        :ok = RocksDB.transaction_commit(rtx)
-
-        %{error: :ok, hash: next_entry.hash, validator_seeds: validator_seeds, mutations_hash: mutations_hash, logs: l, muts: m}
-    end
-
-    def produce_entry(sk, slot) do
-        cur_entry = chain_tip_entry()
-        next_entry = Entry.build_next(sk, cur_entry, slot)
-
-        #TODO: embed aggsig of previous vote
-        txs = TXPool.grab_next_valid(100)
-        next_entry = Map.put(next_entry, :txs, txs)
-        next_entry = Entry.sign(sk, next_entry)
-
-        next_entry
-    end
-end
diff --git a/ex/lib/consensus/consensus_kv.ex b/ex/lib/consensus/consensus_kv.ex
index f2677a4..d871011 100644
--- a/ex/lib/consensus/consensus_kv.ex
+++ b/ex/lib/consensus/consensus_kv.ex
@@ -212,24 +212,6 @@ defmodule ConsensusKV do
         |> Blake3.hash()
     end
 
-    def revert(m_rev) do
-        db = Process.get({RocksDB, :ctx})
-        Enum.reverse(m_rev)
-        |> Enum.each(fn(mut)->
-            case mut.op do
-                :put ->
-                    RocksDB.put(mut.key, mut.value, %{rtx: db.rtx, cf: db.cf.contractstate})
-                :delete ->
-                    RocksDB.delete(mut.key, %{rtx: db.rtx, cf: db.cf.contractstate})
-                :clear_bit ->
-                    old_value = RocksDB.get(mut.key, %{rtx: db.rtx, cf: db.cf.contractstate})
-                    << left::size(mut.value), _old_bit::size(1), right::bitstring >> = old_value
-                    new_value = << left::size(mut.value), 0::size(1), right::bitstring >>
-                    RocksDB.put(mut.key, new_value, %{rtx: db.rtx, cf: db.cf.contractstate})
-            end
-        end)
-    end
-
     def merge_nested(left, right) do
         Map.merge(left, right, &merge_nested_resolve/3)
     end
diff --git a/ex/lib/consensus/consensus_weight.ex b/ex/lib/consensus/consensus_weight.ex
deleted file mode 100644
index 90dd4a8..0000000
--- a/ex/lib/consensus/consensus_weight.ex
+++ /dev/null
@@ -1,5 +0,0 @@
-defmodule ConsensusWeight do
-    def count(pk) do
-        1
-    end
-end
diff --git a/ex/lib/consensus/fabric_coordinator_gen.ex b/ex/lib/consensus/coordination/fabric_coordinator_gen.ex
similarity index 57%
rename from ex/lib/consensus/fabric_coordinator_gen.ex
rename to ex/lib/consensus/coordination/fabric_coordinator_gen.ex
index bf13294..d8046e9 100644
--- a/ex/lib/consensus/fabric_coordinator_gen.ex
+++ b/ex/lib/consensus/coordination/fabric_coordinator_gen.ex
@@ -39,7 +39,7 @@ defmodule FabricCoordinatorGen do
 
   def handle_info({:insert_consensus, consensus}, state) do
     calc_syncing(true)
-    Fabric.insert_consensus(consensus)
+    DB.Attestation.set_consensus(consensus)
     calc_syncing(false)
     {:noreply, state}
   end
@@ -47,22 +47,21 @@ defmodule FabricCoordinatorGen do
   def handle_info({:add_attestation, attestation}, state) do
     calc_syncing(true)
 
-    Fabric.aggregate_attestation(attestation)
+    aggregate_attestation(attestation)
 
     #proc cached attestations
     ts_m = :os.system_time(1000)
     cached = :ets.select(AttestationCache, [{{{attestation.entry_hash, :_}, {:"$1", :_}}, [], [:"$1"]}])
     Enum.each(cached, fn(attestation)->
-      Fabric.aggregate_attestation(attestation)
+      aggregate_attestation(attestation)
     end)
     if cached != [] do
-      deleted = :ets.select_delete(AttestationCache, [{{{attestation.entry_hash, :_}, :_}, [], [true]}])
-      #IO.inspect {:os.system_time(1000) - ts_m, length(cached), deleted, attestation.entry_hash |> Base58.encode()}
+      :ets.select_delete(AttestationCache, [{{{attestation.entry_hash, :_}, :_}, [], [true]}])
     end
 
     #clear stales
     case :ets.first_lookup(AttestationCache) do
-      :'$end_of_table' -> nil
+      :"$end_of_table" -> nil
       {key, [{_, {_, ts_m_old}}]} ->
         delta = ts_m - ts_m_old
         if delta >= 10_000 do
@@ -73,4 +72,30 @@ defmodule FabricCoordinatorGen do
     calc_syncing(false)
     {:noreply, state}
   end
+
+  def aggregate_attestation(a) when is_map(a) do
+    %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
+    rtx = RocksDB.transaction(db)
+
+    entry_hash = a.entry_hash
+    mutations_hash = a.mutations_hash
+
+    entry = DB.Entry.by_hash(entry_hash, %{rtx: rtx})
+    trainers = if !entry do nil else DB.Chain.validators_for_height(Entry.height(entry), %{rtx: rtx}) end
+    if !!entry and !!trainers and a.signer in trainers do
+      if entry.header_unpacked.height <= DB.Chain.height(%{rtx: rtx}) do
+        consensus = DB.Attestation.consensus(entry_hash, mutations_hash, %{rtx: rtx}) || %{mutations_hash: mutations_hash, entry_hash: entry_hash}
+        aggsig = cond do
+          !consensus[:aggsig] ->
+            aggsig = BLS12AggSig.new_padded(length(trainers))
+            BLS12AggSig.add_padded(aggsig, trainers, a.signer, a.signature)
+          true ->
+            BLS12AggSig.add_padded(consensus.aggsig, trainers, a.signer, a.signature)
+        end
+        consensus = Map.put(consensus, :aggsig, aggsig)
+        DB.Attestation.set_consensus(consensus, %{rtx: rtx})
+      end
+    end
+    RocksDB.transaction_commit(rtx)
+  end
 end
diff --git a/ex/lib/consensus/fabric_event_gen.ex b/ex/lib/consensus/coordination/fabric_event_gen.ex
similarity index 86%
rename from ex/lib/consensus/fabric_event_gen.ex
rename to ex/lib/consensus/coordination/fabric_event_gen.ex
index dcf169e..b75ee33 100644
--- a/ex/lib/consensus/fabric_event_gen.ex
+++ b/ex/lib/consensus/coordination/fabric_event_gen.ex
@@ -25,9 +25,19 @@ defmodule FabricEventGen do
 
   def tick(state) do
     #IO.inspect "tick"
+    {:message_queue_len, n} = :erlang.process_info(self(), :message_queue_len)
+    n > 100 && purge_pending()
     state
   end
 
+  defp purge_pending do
+    receive do
+      _other -> purge_pending()
+    after 0 ->
+      :ok
+    end
+  end
+
   def handle_info(:tick, state) do
     state = if true do tick(state) else state end
     :erlang.send_after(100, self(), :tick)
diff --git a/ex/lib/consensus/fabric_snapshot.ex b/ex/lib/consensus/coordination/fabric_snapshot.ex
similarity index 94%
rename from ex/lib/consensus/fabric_snapshot.ex
rename to ex/lib/consensus/coordination/fabric_snapshot.ex
index 1678014..b0ab46d 100644
--- a/ex/lib/consensus/fabric_snapshot.ex
+++ b/ex/lib/consensus/coordination/fabric_snapshot.ex
@@ -10,15 +10,15 @@ defmodule FabricSnapshot do
     end
 
     def walk(end_hash, start_hash, opts) do
-        entry = Fabric.entry_by_hash(start_hash)
+        entry = DB.Entry.by_hash(start_hash)
         height = Entry.height(entry)
         IO.inspect {:walk, height}
-        entries = Fabric.entries_by_height(height)
+        entries = DB.Entry.by_height(height)
         entries = entries -- [entry]
 
         RocksDB.delete(entry.hash, %{db: opts.db, cf: opts.cf.my_attestation_for_entry})
         RocksDB.delete(entry.hash, %{db: opts.db, cf: opts.cf.muts_rev})
-        map = Fabric.consensuses_by_entryhash(entry.hash)
+        map = DB.Attestation.consensuses(entry.hash)
         if map_size(map) != 1 do
             IO.inspect {height, map}
             1/0
@@ -52,7 +52,7 @@ defmodule FabricSnapshot do
         opts = %{db: db, cf: cf}
         Enum.reverse(list)
         |> Enum.each(fn(hash)->
-            entry = Fabric.entry_by_hash(hash)
+            entry = DB.Entry.by_hash(hash)
             in_chain = Consensus.is_in_chain(hash)
             if in_chain do
                 true = Consensus.chain_rewind(hash)
@@ -82,7 +82,7 @@ defmodule FabricSnapshot do
     end
 
     def snapshot_tmp() do
-        height = Fabric.rooted_tip_height()
+        height = DB.Chain.rooted_height()
         height_padded = String.pad_leading("#{height}", 12, "0")
 
         %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
diff --git a/ex/lib/consensus/fabric_sync_attest_gen.ex b/ex/lib/consensus/coordination/fabric_sync_attest_gen.ex
similarity index 94%
rename from ex/lib/consensus/fabric_sync_attest_gen.ex
rename to ex/lib/consensus/coordination/fabric_sync_attest_gen.ex
index 53d35a1..e6a6279 100644
--- a/ex/lib/consensus/fabric_sync_attest_gen.ex
+++ b/ex/lib/consensus/coordination/fabric_sync_attest_gen.ex
@@ -57,7 +57,7 @@ defmodule FabricSyncAttestGen do
       Application.fetch_env!(:ama, :testnet) -> true
       !hasQuorum() -> false
       isSynced() != :full -> false
-      Fabric.rooted_tip_height() < Consensus.chain_height() -> false
+      DB.Chain.rooted_height() < DB.Chain.height() -> false
       true -> true
     end
   end
@@ -66,7 +66,7 @@ defmodule FabricSyncAttestGen do
     cond do
       !hasQuorum() -> false
       isSynced() in [:full, :off_by_1] -> true
-      Fabric.rooted_tip_height() < (Consensus.chain_height() - 1) -> false
+      DB.Chain.rooted_height() < (DB.Chain.height() - 1) -> false
       isSynced() not in [:full, :off_by_1] -> false
       true -> true
     end
@@ -76,7 +76,7 @@ defmodule FabricSyncAttestGen do
     cond do
       !hasQuorum() -> false
       isSynced() in [:full, :off_by_1] -> true
-      Fabric.rooted_tip_height() < (Consensus.chain_height() - cnt) -> false
+      DB.Chain.rooted_height() < (DB.Chain.height() - cnt) -> false
       isSynced() not in [:full, :off_by_1] -> false
       true -> true
     end
@@ -127,9 +127,9 @@ defmodule FabricSyncAttestGen do
   end
 
   def tick_synced() do
-    temporal = Consensus.chain_tip_entry()
+    temporal = DB.Chain.tip_entry()
     temporal_height = temporal.header_unpacked.height
-    rooted = Fabric.rooted_tip_entry()
+    rooted = DB.Chain.rooted_tip_entry()
     rooted_height = rooted.header_unpacked.height
 
     {height_rooted_abs, height_abs, height_bft} = NodeANR.highest_validator_height()
diff --git a/ex/lib/consensus/fabric_sync_gen.ex b/ex/lib/consensus/coordination/fabric_sync_gen.ex
similarity index 87%
rename from ex/lib/consensus/fabric_sync_gen.ex
rename to ex/lib/consensus/coordination/fabric_sync_gen.ex
index 1bace7a..f4a1a6c 100644
--- a/ex/lib/consensus/fabric_sync_gen.ex
+++ b/ex/lib/consensus/coordination/fabric_sync_gen.ex
@@ -31,9 +31,9 @@ defmodule FabricSyncGen do
   end
 
   def tick() do
-    temporal = Consensus.chain_tip_entry()
+    temporal = DB.Chain.tip_entry()
     temporal_height = temporal.header_unpacked.height
-    rooted = Fabric.rooted_tip_entry()
+    rooted = DB.Chain.rooted_tip_entry()
     rooted_height = rooted.header_unpacked.height
 
     height_network_temp = FabricSyncAttestGen.highestTemporalHeight()
@@ -78,7 +78,7 @@ defmodule FabricSyncGen do
         |> Enum.uniq()
         {rooted_peers, temporal_peers} = NodeANR.peers_w_min_height(List.last(next_heights), :any)
         next_heights
-        |> Enum.map(& %{height: &1, hashes: Enum.map(Fabric.entries_by_height(&1), fn(%{hash: hash})-> hash end), e: true, c: true})
+        |> Enum.map(& %{height: &1, hashes: Enum.map(DB.Entry.by_height(&1), fn(%{hash: hash})-> hash end), e: true, c: true})
         |> Enum.chunk_every(20)
         |> fetch_chunks(rooted_peers)
 
@@ -89,14 +89,14 @@ defmodule FabricSyncGen do
         |> Enum.uniq()
         {rooted_peers, temporal_peers} = NodeANR.peers_w_min_height(List.last(next_heights), :validators)
         next_heights
-        |> Enum.map(& %{height: &1, hashes: Enum.map(Fabric.entries_by_height(&1), fn(%{hash: hash})-> hash end), e: true, a: true})
+        |> Enum.map(& %{height: &1, hashes: Enum.map(DB.Entry.by_height(&1), fn(%{hash: hash})-> hash end), e: true, a: true})
         |> Enum.chunk_every(10)
         |> fetch_chunks(temporal_peers)
 
       #TODO: fetch only missing heads incase of doubleblock
       behind_temp == 0 ->
         {rooted_peers, temporal_peers} = NodeANR.peers_w_min_height(temporal_height, :validators)
-        chunk = [[%{height: temporal_height, hashes: Enum.map(Fabric.entries_by_height(temporal_height), fn(%{hash: hash})-> hash end), e: true, a: true}]]
+        chunk = [[%{height: temporal_height, hashes: Enum.map(DB.Entry.by_height(temporal_height), fn(%{hash: hash})-> hash end), e: true, a: true}]]
         fetch_chunks(chunk, temporal_peers)
     end
   end
diff --git a/ex/lib/consensus/doms/attestation.ex b/ex/lib/consensus/doms/attestation.ex
deleted file mode 100644
index 560bd48..0000000
--- a/ex/lib/consensus/doms/attestation.ex
+++ /dev/null
@@ -1,94 +0,0 @@
-defmodule Attestation do
-    @doc """
-    attestation {
-        entry_hash: <>,
-        mutations_hash: <>,
-        signer: <>,
-        signature: <entry_hash,mutations_hash>,
-    }
-
-    ssz
-    <<
-      signature::96,
-      signer::48,
-      entry_hash::32,
-      mutations_hash::32
-    >>
-    """
-    def unpack(attestation_packed) when is_binary(attestation_packed) do
-        a = :erlang.binary_to_term(attestation_packed, [:safe])
-        unpack(a)
-    end
-    def unpack(attestation_packed) when is_map(attestation_packed) do
-        Map.take(attestation_packed, [:entry_hash, :mutations_hash, :signer, :signature])
-    end
-    def unpack(nil), do: nil
-
-
-    def pack(attestation_unpacked) when is_binary(attestation_unpacked) do attestation_unpacked end
-    def pack(attestation_unpacked) do
-        attestation_unpacked
-        |> Map.take([:entry_hash, :mutations_hash, :signer, :signature])
-        |> :erlang.term_to_binary([:deterministic])
-    end
-
-    def sign(sk, entry_hash, mutations_hash) do
-        pk = BlsEx.get_public_key!(sk)
-        signature = BlsEx.sign!(sk, <<entry_hash::binary, mutations_hash::binary>>, BLS12AggSig.dst_att())
-        %{
-            entry_hash: entry_hash,
-            mutations_hash: mutations_hash,
-            signer: pk,
-            signature: signature,
-        }
-    end
-
-    def unpack_and_validate(attestation_packed) do
-        try do
-        attestation_size = Application.fetch_env!(:ama, :attestation_size)
-        if byte_size(attestation_packed) >= attestation_size, do: throw(%{error: :too_large})
-        a = :erlang.binary_to_term(attestation_packed, [:safe])
-        |> Map.take([:entry_hash, :mutations_hash, :signer, :signature])
-        if attestation_packed != :erlang.term_to_binary(a, [:deterministic]), do: throw %{error: :not_deterministicly_encoded}
-
-        res = validate(a)
-        cond do
-            res.error != :ok -> throw res
-            true -> %{error: :ok, attestation: a}
-        end
-        catch
-            :throw,r -> r
-            e,r -> IO.inspect {Attestation, :unpack_and_validate, e, r, __STACKTRACE__}; %{error: :unknown}
-        end
-    end
-
-    def validate(a) do
-        try do
-        if !is_binary(a.entry_hash), do: throw(%{error: :entry_hash_not_binary})
-        if byte_size(a.entry_hash) != 32, do: throw(%{error: :entry_hash_not_256_bits})
-        if !is_binary(a.mutations_hash), do: throw(%{error: :mutations_hash_not_binary})
-        if byte_size(a.mutations_hash) != 32, do: throw(%{error: :mutations_hash_not_256_bits})
-        if !is_binary(a.signer), do: throw(%{error: :signer_not_binary})
-        if byte_size(a.signer) != 48, do: throw(%{error: :signer_not_48_bytes})
-
-        bin = <<a.entry_hash::binary, a.mutations_hash::binary>>
-        if !BlsEx.verify?(a.signer, a.signature, bin, BLS12AggSig.dst_att()), do: throw(%{error: :invalid_signature})
-
-        %{error: :ok}
-        catch
-            :throw,r -> r
-            e,r -> IO.inspect {Attestation, :validate, e, r}; %{error: :unknown}
-        end
-    end
-
-    def validate_vs_chain(a) do
-        entry = Fabric.entry_by_hash(a.entry_hash)
-        chain_height = Consensus.chain_height()
-        if !!entry and entry.header_unpacked.height <= Consensus.chain_height() do
-            trainers = Consensus.trainers_for_height(Entry.height(entry))
-            if !!trainers and a.signer in trainers do
-                true
-            end
-        end
-    end
-end
diff --git a/ex/lib/consensus/fabric.ex b/ex/lib/consensus/fabric.ex
index d6e79d6..253c02d 100644
--- a/ex/lib/consensus/fabric.ex
+++ b/ex/lib/consensus/fabric.ex
@@ -32,6 +32,10 @@ defmodule Fabric do
           "muts_rev",
 
           "sysconf",
+          "attestations",
+          "entry_meta",
+          "entry_link",
+          "attestation",
         ]
         try do
           {:ok, db_ref, cf_ref_list} = RDB.open_transaction_db(path, cfs)
@@ -41,7 +45,7 @@ defmodule Fabric do
               my_seen_time_for_entry_cf, my_attestation_for_entry_cf,
               consensus_cf, consensus_by_entryhash_cf,
               contractstate_cf, muts_cf, muts_rev_cf,
-              sysconf_cf,
+              sysconf_cf, attestations_cf, entry_meta_cf, entry_link_cf, attestation_cf,
           ] = cf_ref_list
           cf = %{
               default: default_cf, entry: entry_cf, entry_by_height: entry_height_cf, entry_by_slot: entry_slot_cf,
@@ -50,11 +54,12 @@ defmodule Fabric do
               #my_mutations_hash_for_entry: my_mutations_hash_for_entry_cf,
               consensus: consensus_cf, consensus_by_entryhash: consensus_by_entryhash_cf,
               contractstate: contractstate_cf, muts: muts_cf, muts_rev: muts_rev_cf,
-              sysconf: sysconf_cf,
+              sysconf: sysconf_cf, attestations: attestations_cf, entry_meta: entry_meta_cf, attestation: attestation_cf,
           }
           :persistent_term.put({:rocksdb, Fabric}, %{db: db_ref, cf_list: cf_ref_list, cf: cf, path: path})
         catch
           e,r ->
+            IO.inspect {e, r}
             IO.inspect {:using_old_db, "node might stall during compression, either wait a long time to download from snapshot"}
             init_old()
         end
@@ -111,274 +116,4 @@ defmodule Fabric do
         %{db: db} = :persistent_term.get({:rocksdb, Fabric})
         RDB.close_db(db)
     end
-
-    def entry_by_hash(nil) do nil end
-    def entry_by_hash(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get(hash, %{db: db, cf: cf.entry, term: true})
-        |> Entry.unpack()
-    end
-
-    def entry_by_hash_w_mutsrev(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        entry = RocksDB.get(hash, %{db: db, cf: cf.entry, term: true})
-        |> Entry.unpack()
-        mutsrev = RocksDB.get(hash, %{db: db, cf: cf.muts_rev})
-        if !!mutsrev and !!entry do
-            entry
-        end
-    end
-
-    def entry_muts(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get(hash, %{db: db, cf: cf.muts, term: true})
-    end
-
-    def entry_seentime(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get(hash, %{db: db, cf: cf.my_seen_time_for_entry, term: true})
-    end
-
-    def entries_by_height(height) do
-        softfork_deny_hash = :persistent_term.get(SoftforkDenyHash, [])
-
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get_prefix("#{height}:", %{db: db, cf: cf.entry_by_height})
-        |> Enum.map(& Entry.unpack(entry_by_hash(elem(&1,0))))
-        |> Enum.reject(& &1.hash in softfork_deny_hash)
-    end
-
-    def entries_last_x(cnt) do
-        entry = Consensus.chain_tip_entry()
-        entries_last_x_1(cnt - 1, entry.header_unpacked.prev_hash, [entry])
-    end
-    def entries_last_x_1(cnt, prev_hash, acc) when cnt <= 0, do: acc
-    def entries_last_x_1(cnt, prev_hash, acc) do
-        entry = Fabric.entry_by_hash(prev_hash)
-        entries_last_x_1(cnt - 1, entry.header_unpacked.prev_hash, [entry] ++ acc)
-    end
-
-    def my_attestation_by_height(height) do
-        entries = Fabric.entries_by_height(height)
-        Enum.find_value(entries, fn(entry)->
-            my_attestation_by_entryhash(entry.hash)
-        end)
-    end
-
-    def my_mutations_hash_for_entry(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get(hash, %{db: db, cf: cf.my_mutations_hash_for_entry})
-    end
-
-    def consensuses_by_height(height) do
-        softfork_deny_hash = :persistent_term.get(SoftforkDenyHash, [])
-
-        entries = Fabric.entries_by_height(height)
-        |> Enum.reject(& &1.hash in softfork_deny_hash)
-        Enum.map(entries, fn(entry)->
-            map = consensuses_by_entryhash(entry.hash) || %{}
-            Enum.map(map, fn {mutations_hash, %{mask: mask, aggsig: aggsig}} ->
-                %{entry_hash: entry.hash, mutations_hash: mutations_hash, mask: mask, aggsig: aggsig}
-            end)
-        end)
-        |> List.flatten()
-    end
-
-    def rooted_tip() do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get("rooted_tip", %{db: db, cf: cf.sysconf})
-    end
-
-    def rooted_tip_entry() do
-        entry_by_hash(rooted_tip())
-    end
-
-    def rooted_tip_height() do
-        entry = rooted_tip_entry()
-        if entry do
-            entry.header_unpacked.height
-        end
-    end
-
-    def pruned_hash() do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get("pruned_hash", %{db: db, cf: cf.sysconf}) || EntryGenesis.get().hash
-    end
-
-    def pruned_height() do
-        pruned_hash()
-        |> entry_by_hash()
-        |> Entry.height()
-    end
-
-    def my_attestation_by_entryhash(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get(hash, %{db: db, cf: cf.my_attestation_for_entry, term: true})
-    end
-
-    def consensuses_by_entryhash(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        RocksDB.get(hash, %{db: db, cf: cf.consensus_by_entryhash, term: true})
-    end
-
-    def get_entries_by_height_w_attestation_or_consensus(height) do
-        my_pk = Application.fetch_env!(:ama, :trainer_pk)
-        trainers = Consensus.trainers_for_height(height) || []
-        isTrainer = my_pk in trainers
-
-        consens = consensuses_by_height(height)
-        |> Enum.filter(fn(c)-> BLS12AggSig.score(trainers, c.mask) >= 0.67 end)
-        |> Enum.take(1)
-
-        entries = Fabric.entries_by_height(height)
-        Enum.map(entries, fn(entry)->
-            consen = Enum.find_value(consens, & &1.entry_hash == entry.hash && &1)
-            if consen do
-                %{entry: entry, consensus: consen}
-            else
-                attest = if isTrainer do
-                    my_attestation_by_height(height)
-                end
-                %{entry: entry, attest: attest}
-            end
-        end)
-    end
-
-    def get_attestations_and_consensuses_by_height(height) do
-        my_pk = Application.fetch_env!(:ama, :trainer_pk)
-        trainers = Consensus.trainers_for_height(height) || []
-        isTrainer = my_pk in trainers
-
-        attest = my_attestation_by_height(height)
-
-        consens = consensuses_by_height(height)
-        |> Enum.filter(fn(c)-> BLS12AggSig.score(trainers, c.mask) >= 0.67 end)
-        |> Enum.take(1)
-
-        {List.wrap(attest), List.wrap(consens)}
-    end
-
-    def best_consensus_by_entryhash(trainers, hash) do
-        consensuses = consensuses_by_entryhash(hash)
-        if !consensuses do {nil,nil,nil} else
-            {mut_hash, score, consensus} = Consensus.best_by_weight(trainers, consensuses)
-        end
-    end
-
-    def set_rooted_tip(hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        rtx = RocksDB.transaction(db)
-        RocksDB.put("rooted_tip", hash, %{rtx: rtx, cf: cf.sysconf})
-        :ok = RocksDB.transaction_commit(rtx)
-    end
-
-    def insert_genesis() do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        genesis = EntryGenesis.get()
-        if !RocksDB.get(genesis.hash, %{db: db, cf: cf.entry}) do
-            IO.puts "  Ahhh... Fresh Fabric. Marking genesis.."
-            insert_entry(genesis)
-
-            %{error: :ok, mutations_hash: mutations_hash} = Consensus.apply_entry(genesis)
-            attestation = EntryGenesis.attestation()
-            true = mutations_hash == attestation.mutations_hash
-
-            aggregate_attestation(attestation)
-
-            set_rooted_tip(genesis.hash)
-            RocksDB.put("temporal_height", 0, %{db: db, cf: cf.sysconf, term: true})
-        end
-    end
-
-    def insert_entry(e, seen_time \\ nil)
-    def insert_entry(e, seen_time) when is_binary(e) do insert_entry(Entry.unpack(e), seen_time) end
-    def insert_entry(e, seen_time) when is_map(e) do
-        entry_packed = Entry.pack(e)
-
-        seen_time = if seen_time do seen_time else :os.system_time(1000) end
-
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-        rtx = RocksDB.transaction(db)
-
-        has_entry = RocksDB.get(e.hash, %{rtx: rtx, cf: cf.entry})
-        if !has_entry do
-            RocksDB.put(e.hash, entry_packed, %{rtx: rtx, cf: cf.entry})
-            RocksDB.put(e.hash, seen_time, %{rtx: rtx, cf: cf.my_seen_time_for_entry, term: true})
-            RocksDB.put("#{e.header_unpacked.height}:#{e.hash}", e.hash, %{rtx: rtx, cf: cf.entry_by_height})
-            RocksDB.put("#{e.header_unpacked.slot}:#{e.hash}", e.hash, %{rtx: rtx, cf: cf.entry_by_slot})
-        end
-
-        RocksDB.transaction_commit(rtx)
-    end
-
-    def get_or_resign_my_attestation(entry_hash) do
-        %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-
-        attestation_packed = RocksDB.get(entry_hash, %{db: db, cf: cf.my_attestation_for_entry})
-        if attestation_packed do
-            a = Attestation.unpack(attestation_packed)
-
-            if Application.fetch_env!(:ama, :trainer_pk) == a.signer do a else
-                IO.puts "imported database, resigning attestation #{Base58.encode(entry_hash)}"
-                a = Attestation.sign(entry_hash, a.mutations_hash)
-                RocksDB.put(entry_hash, Attestation.pack(a), %{db: db, cf: cf.my_attestation_for_entry})
-                a
-            end
-            |> Attestation.pack()
-        end
-    end
-
-    def aggregate_attestation(a, opts \\ %{})
-    def aggregate_attestation(a, opts) when is_binary(a) do aggregate_attestation(Attestation.unpack(a), opts) end
-    def aggregate_attestation(a, opts) when is_map(a) do
-        {cf, rtx} = if opts[:rtx] do
-            {opts.cf, opts.rtx}
-        else
-            %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-            rtx = RocksDB.transaction(db)
-            {cf, rtx}
-        end
-
-        entry_hash = a.entry_hash
-        mutations_hash = a.mutations_hash
-
-        entry = entry_by_hash(entry_hash)
-        trainers = if !entry do nil else Consensus.trainers_for_height(Entry.height(entry)) end
-        if !!entry and !!trainers and a.signer in trainers do
-
-            #FIX: make sure we dont race on the trainers_for_height
-            if entry.header_unpacked.height <= Consensus.chain_height() do
-                consensuses = RocksDB.get(entry_hash, %{rtx: rtx, cf: cf.consensus_by_entryhash, term: true}) || %{}
-                consensus = consensuses[mutations_hash]
-                consensus = cond do
-                    !consensus -> BLS12AggSig.new(trainers, a.signer, a.signature)
-                    bit_size(consensus.mask) < length(trainers) -> BLS12AggSig.new(trainers, a.signer, a.signature)
-                    true -> BLS12AggSig.add(consensus, trainers, a.signer, a.signature)
-                end
-                consensuses = Map.put(consensuses, mutations_hash, consensus)
-                RocksDB.put(entry_hash, consensuses, %{rtx: rtx, cf: cf.consensus_by_entryhash, term: true})
-            end
-
-            if !opts[:rtx] do
-                RocksDB.transaction_commit(rtx)
-            end
-        end
-    end
-
-    def insert_consensus(consensus) do
-        entry_hash = consensus.entry_hash
-        entry = Fabric.entry_by_hash(entry_hash)
-        {_, oldScore, _} = best_consensus_by_entryhash(Consensus.trainers_for_height(Entry.height(entry)), entry_hash)
-        if consensus.score >= 0.67 and consensus.score > (oldScore||0) do
-            %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-            rtx = RocksDB.transaction(db)
-
-            consensuses = RocksDB.get(entry_hash, %{rtx: rtx, cf: cf.consensus_by_entryhash, term: true}) || %{}
-            consensuses = put_in(consensuses, [consensus.mutations_hash], %{mask: consensus.mask, aggsig: consensus.aggsig})
-            RocksDB.put(entry_hash, consensuses, %{rtx: rtx, cf: cf.consensus_by_entryhash, term: true})
-            RocksDB.transaction_commit(rtx)
-        else
-            #IO.inspect {:insert_consensus, :rejected_by_score, oldScore, consensus.score}
-        end
-    end
 end
diff --git a/ex/lib/consensus/fabric_cleaner.ex b/ex/lib/consensus/fabric_cleaner.ex
deleted file mode 100644
index 9ef5bab..0000000
--- a/ex/lib/consensus/fabric_cleaner.ex
+++ /dev/null
@@ -1,57 +0,0 @@
-defmodule FabricCleaner do
-  use GenServer
-
-  def start_link() do
-    GenServer.start_link(__MODULE__, %{}, name: __MODULE__)
-  end
-
-  def init(state) do
-    :erlang.send_after(1000, self(), :tick)
-    {:ok, state}
-  end
-
-  def handle_info(:tick, state) do
-    check_and_clean_finality()
-    :erlang.send_after(1000, self(), :tick)
-    {:noreply, state}
-  end
-
-  def check_and_clean_finality() do
-    %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-    finality_clean_next_epoch = RocksDB.get("finality_clean_next_epoch", %{db: db, cf: cf.sysconf, term: true}) || 0
-    epoch = Consensus.chain_epoch()
-    if finality_clean_next_epoch < (epoch-1) do
-      clean_finality(finality_clean_next_epoch)
-    end
-  end
-
-  def clean_finality(epoch) do
-    IO.inspect {:clean_finality_epoch, epoch}
-    %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-    start_height = epoch * 100_000
-    end_height = start_height + 99_999
-
-    stream = Task.async_stream(0..9, fn(idx)->
-      start_index = start_height+idx*10_000
-      clean_muts_rev(epoch, start_index, start_index+9_999)
-    end, [{:timeout, :infinity}])
-    Enum.each(stream, & &1)
-
-    RocksDB.put("finality_clean_next_epoch", epoch+1, %{db: db, cf: cf.sysconf, term: true})
-  end
-
-  def clean_muts_rev(epoch, start, fin) do
-    %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-    rtx = RocksDB.transaction(db)
-    Enum.each(start..fin, fn(height)->
-      if rem(height, 1000) == 0 do
-        IO.inspect {:clean_muts_rev, height}
-      end
-      entries = Fabric.entries_by_height(height)
-      Enum.each(entries, fn %{hash: hash} ->
-        RocksDB.delete(hash, %{rtx: rtx, cf: cf.muts_rev})
-      end)
-    end)
-    :ok = RocksDB.transaction_commit(rtx)
-  end
-end
diff --git a/ex/lib/consensus/fabric_gen.ex b/ex/lib/consensus/fabric_gen.ex
index 9183e94..ff2b743 100644
--- a/ex/lib/consensus/fabric_gen.ex
+++ b/ex/lib/consensus/fabric_gen.ex
@@ -76,42 +76,27 @@ defmodule FabricGen do
   end
 
   def best_entry_for_height(height) do
-    rooted_tip = Fabric.rooted_tip()
+    rooted_tip = DB.Chain.rooted_tip()
     next_entries = height
-    |> Fabric.entries_by_height()
+    |> DB.Entry.by_height()
     #TODO: fix this via a secondary index on is_in_main_chain
     #|> Enum.filter(& &1.header_unpacked.prev_hash == rooted_tip)
     |> Enum.map(fn(entry)->
-        trainers = Consensus.trainers_for_height(Entry.height(entry))
-        {mut_hash, score, _consensus} = Fabric.best_consensus_by_entryhash(trainers, entry.hash)
+        {mut_hash, score} = DB.Attestation.best_consensus_by_entryhash(entry.hash)
         {entry, mut_hash, score}
     end)
     |> Enum.filter(fn {entry, mut_hash, score} -> mut_hash end)
     |> Enum.sort_by(fn {entry, mut_hash, score} -> {-score, entry.header_unpacked.slot, !entry[:mask], entry.hash} end)
   end
 
-  def best_entry_for_height_no_score(height) do
-    rooted_tip = Fabric.rooted_tip()
-    next_entries = height
-    |> Fabric.entries_by_height()
-    |> Enum.filter(& &1.header_unpacked.prev_hash == rooted_tip)
-    |> Enum.map(fn(entry)->
-        trainers = Consensus.trainers_for_height(Entry.height(entry))
-        {mut_hash, score, _consensus} = Fabric.best_consensus_by_entryhash(trainers, entry.hash)
-        {entry, mut_hash, score}
-    end)
-    |> Enum.filter(fn {entry, mut_hash, score} -> mut_hash end)
-    |> Enum.sort_by(fn {entry, mut_hash, score} -> {entry.header_unpacked.slot, !entry[:mask], entry.hash} end)
-  end
-
   def proc_consensus() do
-    entry_root = Fabric.rooted_tip_entry()
-    entry_temp = Consensus.chain_tip_entry()
+    entry_root = DB.Chain.rooted_tip_entry()
+    entry_temp = DB.Chain.tip_entry()
     height_root = entry_root.header_unpacked.height
     height_temp = entry_temp.header_unpacked.height
     if height_root < height_temp do
       proc_consensus_1(height_root+1)
-      if Fabric.rooted_tip() != entry_root.hash do
+      if DB.Chain.rooted_tip() != entry_root.hash do
         #  event_consensus
         #  NodeGen.broadcast_tip()
       end
@@ -120,37 +105,35 @@ defmodule FabricGen do
 
   defp proc_consensus_1(next_height) do
     next_entries = best_entry_for_height(next_height)
-
     #IO.inspect {next_entries, next_height}
     case List.first(next_entries) do
         #TODO: adjust the maliciousness rate via score
-        {best_entry, mut_hash, score} when score >= 0.67 ->
-            mymut = Fabric.my_attestation_by_entryhash(best_entry.hash)
+        {best_entry, muts_hash, score} when score >= 0.67 ->
+            my_muts_hash = DB.Entry.muts_hash(best_entry.hash)
+            in_chain = DB.Entry.in_chain(best_entry.hash)
             cond do
-              !mymut ->
-                IO.puts "softfork: rewind to entry #{Base58.encode(best_entry.hash)}, height #{best_entry.header_unpacked.height}"
-                hash = try do
-                  {entry, mut_hash, score} = List.first(best_entry_for_height(next_height - 1))
-                  entry.hash
-                catch
-                  _,_ -> Consensus.chain_tip()
-                end
-                true = Consensus.chain_rewind(hash)
+              #We did not apply the entry due to doubleblock or slash block
+              #Switch chain to it
+              !in_chain ->
+                rewind_to_hash = DB.Entry.by_height_in_main_chain(best_entry.header_unpacked.height - 1)
+                IO.puts "softfork: rewind to entry #{Base58.encode(rewind_to_hash)}, height #{best_entry.header_unpacked.height - 1}"
+                true = DB.Chain.rewind(rewind_to_hash)
                 proc_consensus()
 
-              mut_hash != mymut.mutations_hash ->
+              muts_hash != my_muts_hash ->
                 height = best_entry.header_unpacked.height
                 slot = best_entry.header_unpacked.slot
+                rewind_to_hash = DB.Entry.by_height_in_main_chain(best_entry.header_unpacked.height - 1)
                 IO.puts "EMERGENCY: consensus chose entry #{Base58.encode(best_entry.hash)} for height/slot #{height}/#{slot}"
-                IO.puts "but our mutations are #{Base58.encode(mymut[:mutations_hash])} while consensus is #{Base58.encode(mut_hash)}"
+                IO.puts "but our mutations are #{Base58.encode(my_muts_hash)} while consensus is #{Base58.encode(muts_hash)}"
                 IO.puts "EMERGENCY: consensus halted as state is out of sync with network"
-                {entry, mut_hash, score} = List.first(best_entry_for_height(next_height - 1))
-                true = Consensus.chain_rewind(entry.hash)
+                true = DB.Chain.rewind(rewind_to_hash)
                 :erlang.halt()
 
               true ->
-                FabricEventGen.event_rooted(best_entry, mut_hash)
-                Fabric.set_rooted_tip(best_entry.hash)
+                FabricEventGen.event_rooted(best_entry, muts_hash)
+                %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
+                RocksDB.put("rooted_tip", best_entry.hash, %{db: db, cf: cf.sysconf})
                 proc_consensus()
             end
         _ -> nil
@@ -161,21 +144,21 @@ defmodule FabricGen do
     softfork_hash = :persistent_term.get(SoftforkHash, [])
     softfork_deny_hash = :persistent_term.get(SoftforkDenyHash, [])
 
-    cur_entry = Consensus.chain_tip_entry()
+    cur_entry = DB.Chain.tip_entry()
     cur_slot = cur_entry.header_unpacked.slot
     height = cur_entry.header_unpacked.height
     next_height = height + 1
     next_entries = next_height
-    |> Fabric.entries_by_height()
+    |> DB.Entry.by_height()
     |> Enum.filter(fn(next_entry)->
       #in slot
       next_slot = next_entry.header_unpacked.slot
-      trainer_for_slot = Consensus.trainer_for_slot(Entry.height(next_entry), next_slot)
+      validator_for_entry = DB.Chain.validator_for_height(Entry.height(next_entry))
       in_slot = cond do
-        next_entry.header_unpacked.signer == trainer_for_slot -> true
+        next_entry.header_unpacked.signer == validator_for_entry -> true
         !!next_entry[:mask] ->
-            trainers = Consensus.trainers_for_height(Entry.height(next_entry))
-            score = BLS12AggSig.score(trainers, next_entry.mask)
+            trainers = DB.Chain.validators_for_height(Entry.height(next_entry))
+            score = BLS12AggSig.score(trainers, Util.pad_bitstring_to_bytes(next_entry.mask), bit_size(next_entry.mask))
             score >= 0.67
 
         true -> false
@@ -197,34 +180,14 @@ defmodule FabricGen do
     case List.first(next_entries) do
       nil -> nil
       entry ->
-        #ts_s = :os.system_time(1000)
-        #%{error: :ok, attestation_packed: attestation_packed,
-        #  mutations_hash: m_hash, logs: l, muts: m} = Consensus.apply_entry(entry)
-        #IO.inspect {:took, entry.header_unpacked.height, :os.system_time(1000) - ts_s}
-
-        task = Task.async(fn -> Consensus.apply_entry(entry) end)
-        %{error: :ok, hash: hash, validator_seeds: vseeds,
-          mutations_hash: m_hash, logs: l, muts: m
+        start_ts = :os.system_time(1000)
+        task = Task.async(fn -> FabricGen.apply_entry(entry) end)
+        %{error: :ok, mutations_hash: m_hash, logs: l, muts: m
         } = case Task.await(task, :infinity) do
           result = %{error: :ok} -> result
         end
 
         FabricEventGen.event_applied(entry, m_hash, m, l)
-
-        Enum.each(vseeds, fn(seed)->
-          attestation = Attestation.sign(seed.seed, hash, m_hash)
-          send(FabricCoordinatorGen, {:add_attestation, attestation})
-          if FabricSyncAttestGen.isQuorumSyncedOffByX(6) do
-            msg = NodeProto.event_attestation(Attestation.pack(attestation))
-            NodeGen.broadcast(msg)
-
-            #Ensure RPC nodes are as up-to-date as possible
-            #TODO: fix this in a better way later
-            peers = Application.fetch_env!(:ama, :seedanrs_as_peers)
-            send(NodeGen.get_socket_gen(), {:send_to, peers, msg})
-          end
-        end)
-
         TXPool.delete_packed(entry.txs)
 
         proc_entries()
@@ -232,50 +195,49 @@ defmodule FabricGen do
   end
 
   def proc_if_my_slot() do
-    entry = Consensus.chain_tip_entry()
+    entry = DB.Chain.tip_entry()
     next_slot = entry.header_unpacked.slot + 1
     next_height = entry.header_unpacked.height + 1
-    slot_trainer = Consensus.trainer_for_slot(next_height, next_slot)
+    next_validator = DB.Chain.validator_for_height(next_height)
+
+    am_i_next = Enum.find(Application.fetch_env!(:ama, :keys), & &1.pk == next_validator)
 
     #prevent double-entries due to severe system lag (you shouldnt be validator in the first place)
     lastSlot = :persistent_term.get(:last_made_entry_slot, nil)
 
-    rooted_tip = Fabric.rooted_tip()
-    emptyHeight = Fabric.entries_by_height(next_height)
-    |> Enum.filter(& &1.header_unpacked.prev_hash == rooted_tip)
+    rooted_tip = DB.Chain.rooted_tip()
+    emptyHeight = DB.Entry.by_height(next_height)
     emptyHeight = emptyHeight == []
 
-    am_i_next = Enum.find(Application.fetch_env!(:ama, :keys), & &1.pk == slot_trainer)
-
     cond do
-      !FabricSyncAttestGen.isQuorumSynced() -> nil
-
       lastSlot == next_slot -> nil
       !emptyHeight -> nil
 
+      !FabricSyncAttestGen.isQuorumSynced() -> nil
+
       am_i_next ->
         :persistent_term.put(:last_made_entry_slot, next_slot)
 
         if :persistent_term.get(:snapshot_before_my_slot, nil) do
           :persistent_term.erase(:snapshot_before_my_slot)
-          IO.inspect "taking snapshot #{Fabric.rooted_tip_height()}"
+          IO.inspect "taking snapshot #{DB.Chain.rooted_height()}"
           FabricSnapshot.snapshot_tmp()
         end
 
         !Application.fetch_env!(:ama, :testnet) && IO.puts(" im in slot #{next_slot}, working.. *Click Clak*")
 
-        proc_if_my_slot_1(am_i_next.seed, next_slot)
+        produce_insert_and_broadcast_next_entry(am_i_next.seed, entry)
 
       true ->
         nil
     end
   end
 
-  def proc_if_my_slot_1(seed, next_slot) do
-    next_entry = Consensus.produce_entry(seed, next_slot)
-    Fabric.insert_entry(next_entry, :os.system_time(1000))
+  def produce_insert_and_broadcast_next_entry(seed, cur_entry) do
+    next_entry = produce_entry(seed, cur_entry)
+    DB.Entry.insert(next_entry)
 
-    msg = NodeProto.event_entry(Entry.pack(next_entry))
+    msg = NodeProto.event_entry(Entry.pack_for_net(next_entry))
     NodeGen.broadcast(msg)
 
     #Ensure RPC nodes are as up-to-date as possible
@@ -286,4 +248,140 @@ defmodule FabricGen do
 
     next_entry
   end
+
+  def produce_entry(seed, cur_entry) do
+    next_entry = Entry.build_next(seed, cur_entry)
+    txs = TXPool.grab_next_valid(100)
+    next_entry = Map.put(next_entry, :txs, txs)
+    next_entry = Entry.sign(seed, next_entry)
+    next_entry
+  end
+
+  def make_mapenv(next_entry) do
+      %{
+          :readonly => false,
+          :seed => nil,
+          :seedf64 => 1.0,
+          :entry_signer => next_entry.header_unpacked.signer,
+          :entry_prev_hash => next_entry.header_unpacked.prev_hash,
+          :entry_slot => next_entry.header_unpacked.slot,
+          :entry_prev_slot => next_entry.header_unpacked.prev_slot,
+          :entry_height => next_entry.header_unpacked.height,
+          :entry_epoch => div(next_entry.header_unpacked.height, 100_000),
+          :entry_vr => next_entry.header_unpacked.vr,
+          :entry_vr_b3 => Blake3.hash(next_entry.header_unpacked.vr),
+          :entry_dr => next_entry.header_unpacked.dr,
+          :tx_index => 0,
+          :tx_signer => nil, #env.txu.tx.signer,
+          :tx_nonce => nil, #env.txu.tx.nonce,
+          :tx_hash => nil, #env.txu.hash,
+          :account_origin => nil, #env.txu.tx.signer,
+          :account_caller => nil, #env.txu.tx.signer,
+          :account_current => nil, #action.contract,
+          :attached_symbol => "",
+          :attached_amount => "",
+          :call_counter => 0,
+          :call_exec_points => 10_000_000,
+          :call_exec_points_remaining => 10_000_000,
+      }
+  end
+
+  def apply_entry(next_entry) do
+      %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
+      height = DB.Chain.height()
+      if !height or (height + 1) == Entry.height(next_entry) do
+          apply_entry_1(next_entry)
+      else
+          %{error: :invalid_height}
+      end
+  end
+  def apply_entry_1(next_entry) do
+      %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
+
+      entry = next_entry
+      next_entry_trimmed_map = %{
+          entry_signer: entry.header_unpacked.signer,
+          entry_prev_hash: entry.header_unpacked.prev_hash,
+          entry_vr: entry.header_unpacked.vr,
+          entry_vr_b3: Blake3.hash(entry.header_unpacked.vr),
+          entry_dr: entry.header_unpacked.dr,
+          entry_slot: entry.header_unpacked.slot,
+          entry_prev_slot: entry.header_unpacked.prev_slot,
+          entry_height: entry.header_unpacked.height,
+          entry_epoch: div(entry.header_unpacked.height,100_000),
+      }
+      txus = Enum.map(entry.txs, & TX.unpack(&1))
+
+      {rtx, m, m_rev, l} = RDB.apply_entry(db, next_entry_trimmed_map, Application.fetch_env!(:ama, :trainer_pk), Application.fetch_env!(:ama, :trainer_sk), entry.txs, txus)
+      rebuild_m_fn = fn(m)->
+        Enum.map(m, fn(inner)->
+          op = :"#{IO.iodata_to_binary(inner[~c"op"])}"
+          case op do
+            :set_bit -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"]), value: :erlang.binary_to_integer("#{inner[~c"value"]}"), bloomsize: :erlang.binary_to_integer("#{inner[~c"bloomsize"]}")}
+            :clear_bit -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"]), value: :erlang.binary_to_integer("#{inner[~c"value"]}")}
+            :delete -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"])}
+            :put -> %{op: op, key: IO.iodata_to_binary(inner[~c"key"]), value: IO.iodata_to_binary(inner[~c"value"])}
+          end
+        end)
+      end
+      rebuild_l_fn = fn(m)->
+        Enum.map(m, fn(inner)->
+          %{error: :"#{IO.iodata_to_binary(inner["error"])}"}
+        end)
+      end
+      m = rebuild_m_fn.(m)
+      m_rev = rebuild_m_fn.(m_rev)
+      l = rebuild_l_fn.(l)
+
+      #call the exit
+      Process.put({RocksDB, :ctx}, %{rtx: rtx, cf: cf})
+      #mapenv = make_mapenv(next_entry)
+      #{m_exit, m_exit_rev} = BIC.Base.call_exit(mapenv)
+      #m = m ++ m_exit
+      #m_rev = m_rev ++ m_exit_rev
+
+      mutations_hash = ConsensusKV.hash_mutations(l ++ m)
+
+      RocksDB.put("temporal_tip", next_entry.hash, %{rtx: rtx, cf: cf.sysconf})
+
+      DB.Entry.apply_into_main_chain(next_entry, mutations_hash, m_rev, l, %{rtx: rtx})
+      if Application.fetch_env!(:ama, :archival_node) do
+          DB.Entry.apply_into_main_chain_muts(next_entry.hash, m, %{rtx: rtx})
+      end
+
+      validators = DB.Chain.validators_for_height(Entry.height(next_entry), %{rtx: rtx})
+      my_validators = Application.fetch_env!(:ama, :keys) |> Enum.filter(& &1.pk in validators)
+      # {next_entry, mutations_hash} = {%{hash: DB.Chain.tip(), header_unpacked: %{height: DB.Chain.height()}}, DB.Entry.muts_hash(DB.Chain.tip())}
+      # my_validators = Application.fetch_env!(:ama, :keys)
+      # rtx = RocksDB.transaction(:persistent_term.get({:rocksdb, Fabric}).db)
+      # :ok = RocksDB.transaction_commit(rtx)
+      attestations = Enum.map(my_validators, fn(seed)->
+        attestation = Attestation.sign(seed.seed, next_entry.hash, mutations_hash)
+        DB.Attestation.put(attestation, Entry.height(next_entry), %{rtx: rtx})
+        #send(FabricCoordinatorGen, {:add_attestation, attestation})
+        if FabricSyncAttestGen.isQuorumSyncedOffByX(6) do
+          msg = NodeProto.event_attestation(Attestation.pack_for_net(attestation))
+          NodeGen.broadcast(msg)
+
+          #Ensure RPC nodes are as up-to-date as possible
+          #TODO: fix this in a better way later
+          peers = Application.fetch_env!(:ama, :seedanrs_as_peers)
+          send(NodeGen.get_socket_gen(), {:send_to, peers, msg})
+        end
+        attestation
+      end)
+      if length(attestations) > 0 do
+        aggsig = BLS12AggSig.aggregate(validators, attestations)
+        consensus = %{
+          aggsig: aggsig,
+          mutations_hash: mutations_hash,
+          entry_hash: next_entry.hash
+        }
+        DB.Attestation.set_consensus(consensus, %{rtx: rtx})
+      end
+
+      :ok = RocksDB.transaction_commit(rtx)
+
+      %{error: :ok, mutations_hash: mutations_hash, logs: l, muts: m}
+  end
 end
diff --git a/ex/lib/consensus/models/attestation.ex b/ex/lib/consensus/models/attestation.ex
new file mode 100644
index 0000000..47161aa
--- /dev/null
+++ b/ex/lib/consensus/models/attestation.ex
@@ -0,0 +1,76 @@
+defmodule Attestation do
+    _ = """
+    attestation {
+        entry_hash: <>,
+        mutations_hash: <>,
+        signer: <>,
+        signature: <entry_hash,mutations_hash>,
+    }
+    """
+
+    def pack_for_db(attestation_unpacked) when is_binary(attestation_unpacked) do attestation_unpacked end
+    def pack_for_db(attestation_unpacked) do
+      attestation_unpacked
+      |> Map.take([:entry_hash, :mutations_hash, :signer, :signature])
+      |> RDB.vecpak_encode()
+    end
+
+    def pack_for_net(attestation_unpacked) do
+      attestation_unpacked
+      |> Map.take([:entry_hash, :mutations_hash, :signer, :signature])
+      |> :erlang.term_to_binary([:deterministic])
+    end
+
+    def sign(sk, entry_hash, mutations_hash) do
+        pk = BlsEx.get_public_key!(sk)
+        signature = BlsEx.sign!(sk, <<entry_hash::binary, mutations_hash::binary>>, BLS12AggSig.dst_att())
+        %{
+            entry_hash: entry_hash,
+            mutations_hash: mutations_hash,
+            signer: pk,
+            signature: signature,
+        }
+    end
+
+    def unpack_and_validate_from_net(a) do
+        try do
+
+        a = if is_map(a) do a else
+          attestation_size = Application.fetch_env!(:ama, :attestation_size)
+          if byte_size(a) >= attestation_size, do: throw(%{error: :too_large})
+
+          a_unpacked = :erlang.binary_to_term(a, [:safe])
+          |> Map.take([:entry_hash, :mutations_hash, :signer, :signature])
+          if a != :erlang.term_to_binary(a_unpacked, [:deterministic]), do: throw %{error: :not_deterministicly_encoded}
+
+          a_unpacked
+        end
+
+        if !is_binary(a.entry_hash), do: throw(%{error: :entry_hash_not_binary})
+        if byte_size(a.entry_hash) != 32, do: throw(%{error: :entry_hash_not_256_bits})
+        if !is_binary(a.mutations_hash), do: throw(%{error: :mutations_hash_not_binary})
+        if byte_size(a.mutations_hash) != 32, do: throw(%{error: :mutations_hash_not_256_bits})
+        if !is_binary(a.signer), do: throw(%{error: :signer_not_binary})
+        if byte_size(a.signer) != 48, do: throw(%{error: :signer_not_48_bytes})
+
+        bin = <<a.entry_hash::binary, a.mutations_hash::binary>>
+        if !BlsEx.verify?(a.signer, a.signature, bin, BLS12AggSig.dst_att()), do: throw(%{error: :invalid_signature})
+
+        %{error: :ok, attestation: a}
+        catch
+            :throw,r -> r
+            e,r -> IO.inspect {Attestation, :validate, e, r}; %{error: :unknown}
+        end
+    end
+
+    def validate_vs_chain(a) do
+        entry = DB.Entry.by_hash(a.entry_hash)
+        chain_height = DB.Chain.height()
+        if !!entry and entry.header_unpacked.height <= DB.Chain.height() do
+            trainers = DB.Chain.validators_for_height(Entry.height(entry))
+            if !!trainers and a.signer in trainers do
+                true
+            end
+        end
+    end
+end
diff --git a/ex/lib/consensus/bls12_aggsig.ex b/ex/lib/consensus/models/bls12_aggsig.ex
similarity index 50%
rename from ex/lib/consensus/bls12_aggsig.ex
rename to ex/lib/consensus/models/bls12_aggsig.ex
index adf30de..06daab0 100644
--- a/ex/lib/consensus/bls12_aggsig.ex
+++ b/ex/lib/consensus/models/bls12_aggsig.ex
@@ -1,4 +1,13 @@
 defmodule BLS12AggSig do
+    @doc """
+    aggsig {
+        aggsig: <>,
+        mask: <>,
+        mask_size: 0,
+        mask_set_size: 0,
+    }
+    """
+
     @dst "AMADEUS_SIG_BLS12381G2_XMD:SHA-256_SSWU_RO_NUL_"
     @dst_pop "AMADEUS_SIG_BLS12381G2_XMD:SHA-256_SSWU_RO_POP_"
     @dst_att "AMADEUS_SIG_BLS12381G2_XMD:SHA-256_SSWU_RO_ATTESTATION_"
@@ -30,6 +39,11 @@ defmodule BLS12AggSig do
         %{mask: mask, aggsig: signature}
     end
 
+    def new_padded(mask_size) do
+        mask = Util.pad_bitstring_to_bytes(<<0::size(mask_size)>>)
+        %{mask: mask, mask_size: mask_size, mask_set_size: 0}
+    end
+
     def add(m = %{mask: mask, aggsig: aggsig}, trainers, pk, signature) do
         index_of_trainer = Util.index_of(trainers, pk)
 
@@ -40,23 +54,47 @@ defmodule BLS12AggSig do
         end
     end
 
+    def add_padded(m = %{mask: mask, mask_size: mask_size}, signers, pk, signature) do
+        index_of_signer = Util.index_of(signers, pk)
+
+        if Util.get_bit(mask, index_of_signer) do m else
+            mask = Util.set_bit(mask, index_of_signer)
+            case m[:aggsig] do
+              nil -> %{mask: mask, mask_size: mask_size, mask_set_size: Util.popcnt(mask), aggsig: signature}
+              aggsig ->
+                aggsig = BlsEx.aggregate_signatures!([aggsig, signature])
+                %{mask: mask, mask_size: mask_size, mask_set_size: Util.popcnt(mask), aggsig: aggsig}
+            end
+        end
+    end
+
     #TODO: optimize walking with mask
-    def unmask_trainers(trainers, mask) do
-        length = bit_size(mask)
-        Enum.reduce(0..length-1, [], fn(index, acc)->
+    def unmask_trainers(_trainers, _mask, mask_size) when mask_size == 0 do [] end
+    def unmask_trainers(trainers, mask, mask_size) do
+        Enum.reduce(0..mask_size-1, [], fn(index, acc)->
             if !Util.get_bit(mask, index) do acc else
                 acc ++ [Enum.at(trainers, index)]
             end
         end)
     end
 
-    def score(trainers, mask) do
-        trainers_signed = unmask_trainers(trainers, mask)
+    def score(_trainers, _mask, mask_size) when mask_size == 0 do 0.0 end
+    def score(trainers, mask, mask_size) do
+        trainers_signed = unmask_trainers(trainers, mask, mask_size)
 
         maxScore = length(trainers)
-        score = Enum.reduce(trainers_signed, 0, fn(pk, acc)->
-            acc + ConsensusWeight.count(pk)
+        score = Enum.reduce(trainers_signed, 0, fn(_pk, acc)->
+            acc + 1
         end)
         score/maxScore
     end
+
+    def aggregate(total_signer_list, signer_signature_list) do
+      signer_signature_list = List.wrap(signer_signature_list)
+      aggsig = BLS12AggSig.new_padded(length(total_signer_list))
+      Enum.reduce(signer_signature_list, aggsig, fn(signer_signature, aggsig)->
+        BLS12AggSig.add_padded(aggsig, total_signer_list, signer_signature.signer, signer_signature.signature)
+      end)
+      |> Map.put(:mask_set_size, length(signer_signature_list))
+    end
 end
diff --git a/ex/lib/consensus/models/consensus.ex b/ex/lib/consensus/models/consensus.ex
new file mode 100644
index 0000000..a2d0168
--- /dev/null
+++ b/ex/lib/consensus/models/consensus.ex
@@ -0,0 +1,66 @@
+defmodule Consensus do
+  _ = """
+  consensus
+    %{
+      mutations_hash: <<215, 178, 135, 49, 141, 108, 154, 141, 105, 41, 234, 36,
+        222, 56, 0, 124, 63, 25, 150, 225, 37, 216, 254, 73, 65, 240, 8, 33, 179,
+        137, 99, 137>>,
+      entry_hash: <<0, 0, 1, 33, 82, 24, 33, 251, 157, 137, 149, 20, 44, 42, 139,
+        162, 226, 19, 228, 5, 44, 177, 156, 39, 199, 30, 4, 131, 143, 137, 87, 5>>,
+      aggsig: %{
+        mask: <<255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 224>>,
+        aggsig: <<177, 1, 30, 184, 160, 151, 62, 89, 92, 237, 190, 215, 51, 33, 49,
+          140, 240, 33, 142, 33, 244, 90, 254, 143, 172, 251, 162, 236, 87, 98, 40,
+          217, 87, 117, 211, 197, 168, 234, 16, 79, 24, 232, 205, 37, 174, 159, 192,
+          22, 13, 17, 25, 243, 85, 159, 182, 191, 161, 77, 48, 94, 93, 94, 255, 140,
+          48, 156, 86, 53, 176, 18, 168, 20, 57, 96, 167, 185, 26, 116, 149, 185,
+          87, 1, 20, 253, 17, 250, 131, 223, 82, 161, 120, 123, 35, 112, 255, 75>>,
+        mask_size: 99,
+        mask_set_size: 99
+      }
+    }
+  """
+
+    def unpack_from_net(consensus_packed) do
+      consensus = :erlang.binary_to_term(consensus_packed, [:safe])
+      |> Map.take([:entry_hash, :mutations_hash, :mask, :aggsig])
+
+      trainers = DB.Chain.validators_for_hash(consensus.entry_hash)
+      if !is_list(trainers), do: throw %{error: :unpack_consensus_no_entry}
+      trainers_signed = BLS12AggSig.unmask_trainers(trainers, Util.pad_bitstring_to_bytes(consensus.mask), bit_size(consensus.mask))
+
+      aggsig = %{
+        aggsig: consensus.aggsig,
+        mask: Util.pad_bitstring_to_bytes(consensus.mask),
+        mask_size: bit_size(consensus.mask),
+        mask_set_size: length(trainers_signed)
+      }
+      %{entry_hash: consensus.entry_hash, mutations_hash: consensus.mutations_hash, aggsig: aggsig}
+    end
+
+    def pack_for_net(consensus) do
+      aggsig = consensus.aggsig.aggsig
+      <<mask::size(consensus.aggsig.mask_size)-bitstring, _::bitstring>> = consensus.aggsig.mask
+      %{entry_hash: consensus.entry_hash, mutations_hash: consensus.mutations_hash, mask: mask, aggsig: aggsig}
+    end
+
+    def validate_vs_chain(c) do
+        try do
+        to_sign = <<c.entry_hash::binary, c.mutations_hash::binary>>
+
+        entry = DB.Entry.by_hash(c.entry_hash)
+        if !entry, do: throw(%{error: :invalid_entry})
+        if entry.header_unpacked.height > DB.Chain.height(), do: throw(%{error: :too_far_in_future})
+
+        trainers = DB.Chain.validators_for_height(Entry.height(entry))
+        trainers_signed = BLS12AggSig.unmask_trainers(trainers, c.aggsig.mask, c.aggsig.mask_size)
+        aggpk = BlsEx.aggregate_public_keys!(trainers_signed)
+        if !BlsEx.verify?(aggpk, c.aggsig.aggsig, to_sign, BLS12AggSig.dst_att()), do: throw(%{error: :invalid_signature})
+
+        %{error: :ok, consensus: c}
+        catch
+            :throw,r -> r
+            e,r -> IO.inspect({Consensus, :validate, e, r, __STACKTRACE__}, limit: 111111); %{error: :unknown}
+        end
+    end
+end
diff --git a/ex/lib/consensus/doms/entry.ex b/ex/lib/consensus/models/entry.ex
similarity index 62%
rename from ex/lib/consensus/doms/entry.ex
rename to ex/lib/consensus/models/entry.ex
index 3e3c096..7d28d6d 100644
--- a/ex/lib/consensus/doms/entry.ex
+++ b/ex/lib/consensus/models/entry.ex
@@ -1,6 +1,5 @@
 defmodule Entry do
-
-    @doc """
+    _ = """
     entry %{
         header %{
             slot: 9,
@@ -17,6 +16,41 @@ defmodule Entry do
         sig <hash>
         optional|mask <bits>
     }
+
+    entry %{
+        header %{
+            height: 6,
+            prev_hash: <<>>,
+            proposer: <>,
+            dr <hash(prev_dr)>
+            vr <hash(sign(prev_vr))>
+            tx_root: <32>   0 1 2 3 4 txs_count txs_hash
+            validator_root: 0 1 2 3 4 validators_count validators_hash last_validators_change
+            chain_root:     0 1 2 3 4 chain_id chain_tip chain_tip_height (leave out for a future update)
+        }
+        hash <header>
+        aggsig { (mask_size always 1 if proposer is not 0) (if proposer is 0, it means proposer is down and VDF executed + network arrived at empty block)
+          signature
+          mask
+          mask_size
+          mask_set_size
+        }
+        txs []
+    }
+    h (header)
+
+    consensus %{
+      receipts_logs_extra_root: <32>,
+      state_root: <32>, all_contract_state
+      entry_hash: <32>,
+      aggsig: %{
+        mask: <<0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0>>,
+        aggsig: <96>,
+        mask_size: 99,
+        mask_set_size: 1
+      }
+    }
+    h (entry_hash || state_root || receipts_logs_extra_root)
     """
 
     def unpack(entry_packed) when is_binary(entry_packed) do
@@ -36,6 +70,51 @@ defmodule Entry do
         |> :erlang.term_to_binary([:deterministic])
     end
 
+    def unpack_from_db(nil), do: nil
+    def unpack_from_db(entry_packed) do
+        entry = if is_binary(entry_packed) do RDB.vecpak_decode(entry_packed) else entry_packed end
+        header_packed = :erlang.term_to_binary(entry.header, [:deterministic])
+        Map.merge(entry, %{header: header_packed, header_unpacked: entry.header})
+    end
+
+    def unpack_from_net(nil), do: nil
+    def unpack_from_net(entry_packed) do
+        e = if is_binary(entry_packed) do :erlang.binary_to_term(entry_packed, [:safe]) else entry_packed end
+        eh = :erlang.binary_to_term(e.header, [:safe])
+        e = Map.put(e, :header_unpacked, eh)
+        if !e[:mask] do e else
+          trainers = DB.Chain.validators_for_height(eh.height)
+          trainers_signed = BLS12AggSig.unmask_trainers(trainers, Util.pad_bitstring_to_bytes(e.mask), bit_size(e.mask))
+          Map.merge(e, %{mask: Util.pad_bitstring_to_bytes(e.mask), mask_size: bit_size(e.mask), mask_set_size: length(trainers_signed)})
+        end
+    end
+
+    def pack_for_db(entry_unpacked) when is_binary(entry_unpacked) do entry_unpacked end
+    def pack_for_db(entry_unpacked) do
+        header = cond do
+          is_map(entry_unpacked.header) -> entry_unpacked.header
+          is_binary(entry_unpacked.header_unpacked) -> :erlang.binary_to_term(entry_unpacked.header_unpacked)
+          is_map(entry_unpacked.header_unpacked) -> entry_unpacked.header_unpacked
+        end
+        entry_unpacked
+        |> Map.take([:txs, :hash, :signature, :mask, :mask_size, :mask_set_size])
+        |> Map.put(:header, header)
+        |> RDB.vecpak_encode()
+    end
+
+    def pack_for_net(entry) do
+      entry = if !entry[:mask] do entry else
+        <<mask::size(entry.mask_size)-bitstring, _::bitstring>> = entry.mask
+        %{header: entry.header, header_unpacked: entry.header_unpacked, txs: entry.txs, hash: entry.hash, signature: entry.signature, mask: mask}
+      end
+      header = entry.header_unpacked |> :erlang.term_to_binary([:deterministic])
+
+      entry
+      |> Map.take([:txs, :hash, :signature, :mask])
+      |> Map.put(:header, header)
+      |> :erlang.term_to_binary([:deterministic])
+    end
+
     def sign(sk, entry_unpacked) do
         txs_hash = Blake3.hash(Enum.join(entry_unpacked.txs))
         entry_unpacked = put_in(entry_unpacked, [:header_unpacked, :txs_hash], txs_hash)
@@ -52,7 +131,7 @@ defmodule Entry do
         }
     end
 
-    def unpack_and_validate(entry_packed) do
+    def unpack_and_validate_from_net(entry_packed) do
         try do
 
         entry_size = Application.fetch_env!(:ama, :entry_size)
@@ -65,9 +144,15 @@ defmodule Entry do
         if e.header != :erlang.term_to_binary(eh, [:deterministic]), do: throw %{error: :not_deterministicly_encoded_header}
 
         e = Map.put(e, :header_unpacked, eh)
-
-        res_sig = validate_signature(e.header, e.signature, e.header_unpacked.signer, e[:mask])
+        res_sig = validate_signature(e)
         res_entry = validate_entry(e)
+
+        e = if !e[:mask] do e else
+          trainers = DB.Chain.validators_for_height(eh.height)
+          trainers_signed = BLS12AggSig.unmask_trainers(trainers, Util.pad_bitstring_to_bytes(e.mask), bit_size(e.mask))
+          Map.merge(e, %{mask: Util.pad_bitstring_to_bytes(e.mask), mask_size: bit_size(e.mask), mask_set_size: length(trainers_signed)})
+        end
+
         cond do
             res_sig.error != :ok -> throw res_sig
             res_entry.error != :ok -> throw res_entry
@@ -79,18 +164,21 @@ defmodule Entry do
         end
     end
 
-    def validate_signature(header, signature, signer, mask \\ nil) do
+    def validate_signature(e) do
+        header = e.header
+        signature = e.signature
+        signer = e.header_unpacked.signer
+        mask = e[:mask]
         hash = Blake3.hash(header)
         try do
         if mask do
             header_unpacked = :erlang.binary_to_term(header, [:safe])
 
-            trainers = Consensus.trainers_for_height(header_unpacked.height)
-            trainers_signed = BLS12AggSig.unmask_trainers(trainers, mask)
+            trainers = DB.Chain.validators_for_height(header_unpacked.height)
+            trainers_signed = BLS12AggSig.unmask_trainers(trainers, Util.pad_bitstring_to_bytes(e.mask), bit_size(e.mask))
             if nil in trainers_signed, do: throw(%{error: :wrong_epoch})
 
             aggpk = BlsEx.aggregate_public_keys!(trainers_signed)
-
             if !BlsEx.verify?(aggpk, signature, hash, BLS12AggSig.dst_entry()), do: throw(%{error: :invalid_mask_signature})
         else
             if !BlsEx.verify?(signer, signature, hash, BLS12AggSig.dst_entry()), do: throw(%{error: :invalid_signature})
@@ -98,7 +186,7 @@ defmodule Entry do
         %{error: :ok, hash: hash}
         catch
             :throw,r -> Map.put(r, :hash, hash)
-            e,r -> IO.inspect {Entry, :validate_signature, e, r}; %{error: :unknown, hash: hash}
+            e,r -> IO.inspect({Entry, :validate_signature, e, r, __STACKTRACE__}, limit: 1111111); %{error: :unknown, hash: hash}
         end
     end
 
@@ -153,9 +241,9 @@ defmodule Entry do
         if !BlsEx.verify?(neh.signer, neh.vr, ceh.vr, BLS12AggSig.dst_vrf()), do: throw(%{error: :invalid_vr})
 
         txus = Enum.map(next_entry.txs, & TX.unpack(&1))
-        chain_epoch = Consensus.chain_epoch()
-        segment_vr_hash = Consensus.chain_segment_vr_hash()
-        diff_bits = Consensus.chain_diff_bits()
+        chain_epoch = DB.Chain.epoch()
+        segment_vr_hash = DB.Chain.segment_vr_hash()
+        diff_bits = DB.Chain.diff_bits()
         Enum.reduce(txus, %{}, fn(txu, batch_state)->
             case TXPool.validate_tx(txu, %{epoch: chain_epoch, segment_vr_hash: segment_vr_hash, diff_bits: diff_bits, batch_state: batch_state}) do
                %{error: :ok, batch_state: batch_state} -> batch_state
@@ -173,7 +261,7 @@ defmodule Entry do
         end
     end
 
-    def build_next(sk, cur_entry, slot) do
+    def build_next(sk, cur_entry) do
         pk = BlsEx.get_public_key!(sk)
 
         dr = Blake3.hash(cur_entry.header_unpacked.dr)
@@ -181,7 +269,7 @@ defmodule Entry do
 
         %{
             header_unpacked: %{
-                slot: slot,
+                slot: cur_entry.header_unpacked.slot + 1,
                 height: cur_entry.header_unpacked.height + 1,
                 prev_slot: cur_entry.header_unpacked.slot,
                 prev_hash: cur_entry.hash,
diff --git a/ex/lib/consensus/doms/entry_genesis.ex b/ex/lib/consensus/models/entry_genesis.ex
similarity index 95%
rename from ex/lib/consensus/doms/entry_genesis.ex
rename to ex/lib/consensus/models/entry_genesis.ex
index 127bf70..3f2b11d 100644
--- a/ex/lib/consensus/doms/entry_genesis.ex
+++ b/ex/lib/consensus/models/entry_genesis.ex
@@ -141,7 +141,7 @@ defmodule EntryGenesis do
 
     def generate_testnet() do
       %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-      if !RocksDB.get("temporal_height", %{db: db, cf: cf.sysconf}) do
+      if !RocksDB.get("temporal_tip", %{db: db, cf: cf.sysconf}) do
         IO.puts "making testnet.."
 
         pk = Application.fetch_env!(:ama, :trainer_pk)
@@ -174,7 +174,6 @@ defmodule EntryGenesis do
         }
         entry_signed = Entry.sign(sk, entry)
 
-
         rtx = RocksDB.transaction(db)
         Process.put({RocksDB, :ctx}, %{rtx: rtx, cf: cf})
 
@@ -184,10 +183,9 @@ defmodule EntryGenesis do
         pop = BlsEx.sign!(sk, pk, BLS12AggSig.dst_pop())
         entry_signed = Entry.pack(entry_signed) |> Entry.unpack()
 
-        RocksDB.put(entry_signed.hash, Entry.pack(entry_signed), %{rtx: rtx, cf: cf.entry})
-        RocksDB.put(entry_signed.hash, :os.system_time(1000), %{rtx: rtx, cf: cf.my_seen_time_for_entry, term: true})
+        DB.Entry.insert(entry_signed, %{rtx: rtx})
+        DB.Entry.apply_into_main_chain(entry_signed, mutations_hash, [], [], %{rtx: rtx})
         RocksDB.put("temporal_tip", entry_signed.hash, %{rtx: rtx, cf: cf.sysconf})
-        RocksDB.put("temporal_height", 0, %{rtx: rtx, cf: cf.sysconf, term: true})
         RocksDB.put("rooted_tip", entry_signed.hash, %{rtx: rtx, cf: cf.sysconf})
 
         validator_pks = Application.fetch_env!(:ama, :keys) |> Enum.map(& &1.pk)
@@ -200,8 +198,6 @@ defmodule EntryGenesis do
           RocksDB.put("bic:epoch:pop:#{key.pk}", key.pop, %{rtx: rtx, cf: cf.contractstate})
         end)
         rtx = RocksDB.transaction_commit(rtx)
-
-        #Fabric.aggregate_attestation(attestation |> Attestation.pack())
       end
     end
 end
diff --git a/ex/lib/consensus/doms/tx.ex b/ex/lib/consensus/models/tx.ex
similarity index 87%
rename from ex/lib/consensus/doms/tx.ex
rename to ex/lib/consensus/models/tx.ex
index d1f514c..2fb1091 100644
--- a/ex/lib/consensus/doms/tx.ex
+++ b/ex/lib/consensus/models/tx.ex
@@ -1,5 +1,5 @@
 defmodule TX do
-   @doc """
+   _ = """
    %{
      tx: %{
       signer: Base58PK,
@@ -10,6 +10,25 @@ defmodule TX do
      hash: <<>>,
      signature: <<>>
    }
+   tx = TX.build(Application.fetch_env!(:ama, :trainer_sk), "Coin", "transfer", [])
+   {tx1,_} = VanillaSer.decode(tx)
+   tx2 = RDB.vecpak_decode(tx)
+   VanillaSer.decode(tx1["tx_encoded"])
+   VanillaSer.decode(tx2.tx_encoded)
+   RDB.vecpak_decode(tx1["tx_encoded"])
+   RDB.vecpak_decode(tx2.tx_encoded)
+
+   VanillaSer.encode(VanillaSer.decode(tx1["tx_encoded"]) |> elem(0)) |> RDB.vecpak_decode()
+   RDB.vecpak_encode(tx2.tx_encoded) |> RDB.vecpak_decode()
+
+   <<5, 1, 2, 111, 112>>
+   <<5, 1, 4, 97, 114, 103, 115>>
+   <<5, 1, 8, 99, 111, 110, 116, 114, 97, 99, 116>>
+   <<5, 1, 8, 102, 117, 110, 99, 116, 105, 111, 110>>
+   <<5, 1, 5, 110, 111, 110, 99, 101>>
+   <<5, 1, 6, 115, 105, 103, 110, 101, 114>>
+   <<5, 1, 7, 97, 99, 116, 105, 111, 110, 115>>
+
    """
 
    def normalize_atoms(txu) do
@@ -66,7 +85,7 @@ defmodule TX do
       if !is_binary(action[:function]), do: throw %{error: :function_must_be_binary}
       if !is_list(action[:args]), do: throw %{error: :args_must_be_list}
 
-      epoch = Consensus.chain_epoch()
+      epoch = DB.Chain.epoch()
       Enum.each(action.args, fn(arg)->
             if !is_binary(arg), do: throw(%{error: :arg_must_be_binary})
       end)
@@ -126,10 +145,10 @@ defmodule TX do
    def chain_valid(tx_packed) when is_binary(tx_packed) do chain_valid(TX.unpack(tx_packed)) end
    def chain_valid(txu) do
       #TODO: once more than 1 tx allowed per entry fix this
-      chainNonce = Consensus.chain_nonce(txu.tx.signer)
-      chainEpoch = Consensus.chain_epoch()
+      chainNonce = DB.Chain.nonce(txu.tx.signer)
+      chainEpoch = DB.Chain.epoch()
       nonceValid = !chainNonce or txu.tx.nonce > chainNonce
-      hasBalance = BIC.Base.exec_cost(chainEpoch, txu) <= Consensus.chain_balance(txu.tx.signer)
+      hasBalance = BIC.Base.exec_cost(chainEpoch, txu) <= DB.Chain.balance(txu.tx.signer)
 
       hasSol = Enum.find_value(txu.tx.actions, fn(a)-> a.function == "submit_sol" and hd(a.args) end)
       epochSolValid = if !hasSol do true else
@@ -155,8 +174,6 @@ defmodule TX do
       f = action.function
       a = action.args
       case {c,f,a} do
-         {"Coin", "transfer", [receiver, _amount]} -> valid_pk(receiver) && [receiver]
-         {"Coin", "transfer", ["AMA", receiver, _amount]} -> valid_pk(receiver) && [receiver]
          {"Coin", "transfer", [receiver, _amount, _symbol]} -> valid_pk(receiver) && [receiver]
          {"Epoch", "slash_trainer", [_epoch, malicious_pk, _signature, _mask_size, _mask]} -> valid_pk(malicious_pk) && [malicious_pk]
          _ -> nil
diff --git a/ex/lib/consensus/special_meeting/special_meeting_attest_gen.ex b/ex/lib/consensus/special_meeting/special_meeting_attest_gen.ex
index d012413..80a49d1 100644
--- a/ex/lib/consensus/special_meeting/special_meeting_attest_gen.ex
+++ b/ex/lib/consensus/special_meeting/special_meeting_attest_gen.ex
@@ -2,7 +2,7 @@ defmodule SpecialMeetingAttestGen do
   use GenServer
 
   def getSlow() do
-    cur_epoch = Consensus.chain_epoch()
+    cur_epoch = DB.Chain.epoch()
     slow = :persistent_term.get({SpecialMeeting, :slow}, nil)
     if !!slow and slow.epoch == cur_epoch do
       slow
@@ -32,7 +32,7 @@ defmodule SpecialMeetingAttestGen do
   end
 
   def init(state) do
-    state = Map.put(state, :slow, %{epoch: Consensus.chain_epoch(), last_height: Consensus.chain_height(), running: %{}})
+    state = Map.put(state, :slow, %{epoch: DB.Chain.epoch(), last_height: DB.Chain.height(), running: %{}})
     :erlang.send_after(3000, self(), :tick_slow)
     :erlang.send_after(3000, self(), :tick_stalled)
     :erlang.send_after(3000, self(), :tick_offline)
@@ -41,7 +41,7 @@ defmodule SpecialMeetingAttestGen do
 
   def handle_info(:tick_slow, state) do
     state = tick_slow(state)
-    milliseconds = trunc((length(Consensus.trainers_for_height(Consensus.chain_height()+1)) / 2) * 1000)
+    milliseconds = trunc((length(DB.Chain.validators_for_height(DB.Chain.height()+1)) / 2) * 1000)
     :erlang.send_after(milliseconds, self(), :tick_slow)
     {:noreply, state}
   end
@@ -59,28 +59,28 @@ defmodule SpecialMeetingAttestGen do
   end
 
   def tick_slow(state) do
-    cur_epoch = Consensus.chain_epoch()
+    cur_epoch = DB.Chain.epoch()
     if cur_epoch != state.slow.epoch do
-      Map.put(state, :slow, %{epoch: cur_epoch, last_height: Consensus.chain_height(), running: %{}})
+      Map.put(state, :slow, %{epoch: cur_epoch, last_height: DB.Chain.height(), running: %{}})
     else
       tick_slow_1(state)
     end
   end
   def tick_slow_1(state) do
-    cur_epoch = Consensus.chain_epoch()
-    cur_height = Consensus.chain_height()
+    cur_epoch = DB.Chain.epoch()
+    cur_height = DB.Chain.height()
 
     last_entries_cnt = cur_height - state.slow.last_height
     if last_entries_cnt <= 0 do state else
       state = put_in(state, [:slow, :last_height], cur_height)
 
-      entries = Fabric.entries_last_x(last_entries_cnt+1)
+      entries = entries_last_x(last_entries_cnt+1)
       entries = Enum.filter(entries, & div(&1.header_unpacked.height, 100_000) == cur_epoch)
       [hd | entries] = entries
 
-      hd_seentime = Fabric.entry_seentime(hd.hash)
+      hd_seentime = DB.Entry.seentime(hd.hash)
       state = Enum.reduce(entries, {state, hd_seentime}, fn(entry, {state, last_seen})->
-        seentime = Fabric.entry_seentime(entry.hash)
+        seentime = DB.Entry.seentime(entry.hash)
         delta = seentime - last_seen
 
         timings = get_in(state, [:slow, :running, entry.header_unpacked.signer]) || []
@@ -95,16 +95,15 @@ defmodule SpecialMeetingAttestGen do
     end
   end
 
-  def tick_stalled(state) do
+  def tick_stalled(_state) do
     isSynced = FabricSyncAttestGen.isQuorumSyncedOffBy1()
 
-    entry = Consensus.chain_tip_entry()
-    next_slot = entry.header_unpacked.slot + 1
+    entry = DB.Chain.tip_entry()
     next_height = entry.header_unpacked.height + 1
-    next_slot_trainer = Consensus.trainer_for_slot(next_height, next_slot)
+    next_slot_trainer = DB.Chain.validator_for_height(next_height)
 
     ts_m = :os.system_time(1000)
-    seen_time = Fabric.entry_seentime(entry.hash)
+    seen_time = DB.Entry.seentime(entry.hash)
     delta = ts_m - seen_time
 
     nextSlotStalled = :persistent_term.get({SpecialMeeting, :nextSlotStalled}, nil)
@@ -141,7 +140,7 @@ defmodule SpecialMeetingAttestGen do
     my_pk = Application.fetch_env!(:ama, :trainer_pk)
     isSynced = FabricSyncAttestGen.isQuorumSyncedOffBy1()
 
-    trainers = Consensus.trainers_for_height(Consensus.chain_height()+1)
+    trainers = DB.Chain.validators_for_height(DB.Chain.height()+1)
     {vals, _} = NodeANR.handshaked_and_online()
     onlineTrainers = Enum.map(vals, & &1.pk)
     onlineTrainers = if my_pk in onlineTrainers do onlineTrainers else onlineTrainers ++ [my_pk] end
@@ -168,7 +167,7 @@ defmodule SpecialMeetingAttestGen do
   end
 
   def has_double_entry(malicious_pk) do
-    hasDouble = Fabric.entries_by_height(Consensus.chain_height())
+    hasDouble = DB.Entry.by_height(DB.Chain.height())
     |> Enum.frequencies_by(& &1.header_unpacked.signer)
     |> Enum.filter(fn {signer, _count} -> signer == malicious_pk end)
     |> Enum.any?(fn {_signer, count} -> count > 1 end)
@@ -178,7 +177,7 @@ defmodule SpecialMeetingAttestGen do
     slotStallTrainer = isNextSlotStalled()
     cond do
         byte_size(malicious_pk) != 48 -> nil
-        Consensus.chain_epoch() != epoch -> nil
+        DB.Chain.epoch() != epoch -> nil
 
         #TODO: check for Slowloris
         #avg_seentimes_last_10_slots(malicious_pk) > 1second -> true
@@ -203,8 +202,8 @@ defmodule SpecialMeetingAttestGen do
 
   def maybe_attest("slash_trainer_entry", entry_packed) do
     slotStallTrainer = isNextSlotStalled()
-    cur_entry = Fabric.rooted_tip_entry()
-    %{error: :ok, entry: entry} = Entry.unpack_and_validate(entry_packed)
+    cur_entry = DB.Chain.rooted_tip_entry()
+    %{error: :ok, entry: entry} = Entry.unpack_and_validate_from_net(entry_packed)
 
     1 = length(entry.txs)
     txu = TX.unpack(hd(entry.txs))
@@ -215,10 +214,10 @@ defmodule SpecialMeetingAttestGen do
 
     <<mask::size(mask_size)-bitstring, _::bitstring>> = mask
 
-    trainers = Consensus.trainers_for_height(entry.header_unpacked.height)
+    trainers = DB.Chain.validators_for_height(entry.header_unpacked.height)
 
     cond do
-        Consensus.chain_epoch() != epoch -> nil
+        DB.Chain.epoch() != epoch -> nil
         Entry.validate_next(cur_entry, entry) != %{error: :ok} -> nil
         BIC.Epoch.slash_trainer_verify(epoch, malicious_pk, trainers, mask, signature) != nil -> nil
 
@@ -242,4 +241,14 @@ defmodule SpecialMeetingAttestGen do
         true -> nil
     end
   end
+
+  def entries_last_x(cnt) do
+      entry = DB.Chain.tip_entry()
+      entries_last_x_1(cnt - 1, entry.header_unpacked.prev_hash, [entry])
+  end
+  def entries_last_x_1(cnt, prev_hash, acc) when cnt <= 0, do: acc
+  def entries_last_x_1(cnt, prev_hash, acc) do
+      entry = DB.Entry.by_hash(prev_hash)
+      entries_last_x_1(cnt - 1, entry.header_unpacked.prev_hash, [entry] ++ acc)
+  end
 end
diff --git a/ex/lib/consensus/special_meeting/special_meeting_gen.ex b/ex/lib/consensus/special_meeting/special_meeting_gen.ex
index 387b0e8..2ede777 100644
--- a/ex/lib/consensus/special_meeting/special_meeting_gen.ex
+++ b/ex/lib/consensus/special_meeting/special_meeting_gen.ex
@@ -3,7 +3,7 @@ defmodule SpecialMeetingGen do
 
   def try_slash_trainer_entry_next() do
     if SpecialMeetingAttestGen.isNextSlotStalled() do
-      mpk = Consensus.trainer_for_slot_next()
+      mpk = DB.Chain.validator_for_height_next()
       send(SpecialMeetingGen, {:try_slash_trainer_entry, mpk})
     end
   end
@@ -62,13 +62,14 @@ defmodule SpecialMeetingGen do
   def handle_info({:add_slash_trainer_tx_reply, pk, signature}, state = %{slash_trainer: _}) do
     st = state.slash_trainer
 
-    trainers = Consensus.trainers_for_height(st.height + 1)
+    trainers = DB.Chain.validators_for_height(st.height + 1)
     if pk in trainers do
       ma = BLS12AggSig.add(%{mask: st.mask, aggsig: st.aggsig}, trainers, pk, signature)
       state = put_in(state, [:slash_trainer, :mask], ma.mask)
       state = put_in(state, [:slash_trainer, :aggsig], ma.aggsig)
 
-      score = BLS12AggSig.score(trainers, state.slash_trainer.mask)
+      score = BLS12AggSig.score(trainers, Util.pad_bitstring_to_bytes(state.slash_trainer.mask), bit_size(state.slash_trainer.mask))
+
       state = put_in(state, [:slash_trainer, :score_tx], score)
       IO.inspect {:tx, score}
       {:noreply, state}
@@ -81,13 +82,14 @@ defmodule SpecialMeetingGen do
     entry = state.slash_trainer.entry
     true = entry.hash == entry_hash
 
-    trainers = Consensus.trainers_for_height(entry.header_unpacked.height + 1)
+    trainers = DB.Chain.validators_for_height(entry.header_unpacked.height + 1)
     if pk in trainers do
       ma = BLS12AggSig.add(%{mask: entry.mask, aggsig: entry.signature}, trainers, pk, signature)
       state = put_in(state, [:slash_trainer, :entry, :mask], ma.mask)
       state = put_in(state, [:slash_trainer, :entry, :signature], ma.aggsig)
 
-      score = BLS12AggSig.score(trainers, state.slash_trainer.entry.mask)
+      score = BLS12AggSig.score(trainers, Util.pad_bitstring_to_bytes(state.slash_trainer.entry.mask), bit_size(state.slash_trainer.entry.mask))
+
       state = put_in(state, [:slash_trainer, :score_entry], score)
       IO.inspect {:entry, score}
       {:noreply, state}
@@ -98,8 +100,8 @@ defmodule SpecialMeetingGen do
 
   def tick(state) do
     my_pk = Application.fetch_env!(:ama, :trainer_pk)
-    height = Consensus.chain_height()
-    trainers = Consensus.trainers_for_height(height + 1)
+    height = DB.Chain.height()
+    trainers = DB.Chain.validators_for_height(height + 1)
 
     #IO.inspect state[:slash_trainer]
 
@@ -113,23 +115,40 @@ defmodule SpecialMeetingGen do
         IO.inspect tx_packed
         TXPool.insert_and_broadcast(tx_packed, %{peers: 0})
         Map.delete(state, :slash_trainer)
+
       state.slash_trainer.type == :entry and state.slash_trainer.state == :gather_tx_sigs and state.slash_trainer[:score_tx] >= 0.67 ->
         entry = build_slash_entry(state.slash_trainer)
         state = put_in(state, [:slash_trainer, :entry], entry)
         put_in(state, [:slash_trainer, :state], :gather_entry_sigs)
+
       state.slash_trainer.state == :gather_tx_sigs ->
         business = %{op: "slash_trainer_tx", epoch: state.slash_trainer.epoch, malicious_pk: state.slash_trainer.malicious_pk}
         NodeGen.broadcast(NodeProto.special_business(business), %{peers: 0, self: true})
+
+        Enum.each(Application.fetch_env!(:ama, :keys), fn(%{pk: pk, seed: seed})->
+          msg = <<"slash_trainer", state.slash_trainer.epoch::32-little, state.slash_trainer.malicious_pk::binary>>
+          signature = BlsEx.sign!(seed, msg, BLS12AggSig.dst_motion())
+          send(SpecialMeetingGen, {:add_slash_trainer_tx_reply, pk, signature})
+        end)
+
         put_in(state, [:slash_trainer, :attempts], state.slash_trainer.attempts + 1)
 
       state.slash_trainer.type == :entry and state.slash_trainer[:score_entry] >= 0.67 ->
         IO.inspect {:entry_with_score, state.slash_trainer[:score_entry]}
         IO.inspect state.slash_trainer.entry, limit: 1111111111, printable_limit: 1111111111
-        Fabric.insert_entry(state.slash_trainer.entry, :os.system_time(1000))
+        DB.Entry.insert(state.slash_trainer.entry)
         Map.delete(state, :slash_trainer)
+
       state.slash_trainer.state == :gather_entry_sigs ->
-        business = %{op: "slash_trainer_entry", entry_packed: Entry.pack(state.slash_trainer.entry)}
+        business = %{op: "slash_trainer_entry", entry_packed: Entry.pack_for_net(state.slash_trainer.entry)}
         NodeGen.broadcast(NodeProto.special_business(business), %{peers: 0, self: true})
+
+        Enum.each(Application.fetch_env!(:ama, :keys), fn(%{pk: pk, seed: seed})->
+          h = :erlang.term_to_binary(state.slash_trainer.entry.header_unpacked, [:deterministic])
+          signature = BlsEx.sign!(seed, Blake3.hash(h), BLS12AggSig.dst_entry())
+          send(SpecialMeetingGen, {:add_slash_trainer_entry_reply, state.slash_trainer.entry.hash, pk, signature})
+        end)
+
         put_in(state, [:slash_trainer, :attempts], state.slash_trainer.attempts + 1)
 
       true ->
@@ -139,9 +158,10 @@ defmodule SpecialMeetingGen do
   end
 
   def build_slash_tx_business(mpk) do
-    height = Consensus.chain_height()
-    epoch = Consensus.chain_epoch()
-    trainers = Consensus.trainers_for_height(height+1)
+    height = DB.Chain.height()
+    epoch = DB.Chain.epoch()
+    trainers = DB.Chain.validators_for_height(height+1)
+
     my_pk = Application.fetch_env!(:ama, :trainer_pk)
 
     signature = SpecialMeetingAttestGen.maybe_attest("slash_trainer_tx", epoch, mpk)
@@ -151,9 +171,7 @@ defmodule SpecialMeetingGen do
   end
 
   def build_slash_tx(st) do
-    my_pk = Application.fetch_env!(:ama, :trainer_pk)
     my_sk = Application.fetch_env!(:ama, :trainer_sk)
-    #nonce = TXPool.lowest_nonce(my_pk) || Consensus.chain_nonce(my_pk)
     TX.build(my_sk, "Epoch", "slash_trainer",
       ["#{st.epoch}", st.malicious_pk, st.aggsig, "#{bit_size(st.mask)}", Util.pad_bitstring_to_bytes(st.mask)])
   end
@@ -164,16 +182,16 @@ defmodule SpecialMeetingGen do
     packed_tx = build_slash_tx(st)
 
     true = FabricSyncAttestGen.isQuorumSynced()
-    cur_entry = Fabric.rooted_tip_entry()
+    cur_entry = DB.Chain.rooted_tip_entry()
     cur_height = cur_entry.header_unpacked.height
     cur_slot = cur_entry.header_unpacked.slot
 
-    next_entry = Entry.build_next(sk, cur_entry, cur_slot + 1)
+    next_entry = Entry.build_next(sk, cur_entry)
     txs = [packed_tx]
     next_entry = Map.put(next_entry, :txs, txs)
     next_entry = Entry.sign(sk, next_entry)
 
-    trainers = Consensus.trainers_for_height(next_entry.header_unpacked.height + 1)
+    trainers = DB.Chain.validators_for_height(next_entry.header_unpacked.height + 1)
     mask = <<0::size(length(trainers))>>
     mask = Util.set_bit(mask, Util.index_of(trainers, my_pk))
     Map.put(next_entry, :mask, mask)
@@ -181,14 +199,13 @@ defmodule SpecialMeetingGen do
 
   def my_tickslice() do
     pk = Application.fetch_env!(:ama, :trainer_pk)
-    entry = Consensus.chain_tip_entry()
+    entry = DB.Chain.tip_entry()
 
     my_height = entry.header_unpacked.height
     slot = entry.header_unpacked.slot
-    next_slot = slot + 1
     next_height = my_height + 1
 
-    trainers = Consensus.trainers_for_height(next_height + 1)
+    trainers = DB.Chain.validators_for_height(next_height + 1)
     #TODO: make this 3 or 6 later
     ts_s = :os.system_time(1)
     sync_round_offset = rem(div(ts_s, 60), length(trainers))
@@ -207,7 +224,7 @@ defmodule SpecialMeetingGen do
     end
   end
 
-  def check_business(business = %{op: "slash_trainer", malicious_pk: malicious_pk}) do
+  def check_business(_business = %{op: "slash_trainer", malicious_pk: malicious_pk}) do
     slotStallTrainer = SpecialMeetingAttestGen.isNextSlotStalled()
 
     cond do
diff --git a/ex/lib/ex.ex b/ex/lib/ex.ex
index 7160799..2ec102a 100644
--- a/ex/lib/ex.ex
+++ b/ex/lib/ex.ex
@@ -13,6 +13,9 @@ defmodule Ama do
 
     IO.puts "config folder is #{Application.fetch_env!(:ama, :work_folder)}"
     IO.puts "version: #{Application.fetch_env!(:ama, :version)}"
+    IO.puts "pk: #{Application.fetch_env!(:ama, :trainer_pk) |> Base58.encode()}"
+
+    {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: PG, start: {:pg, :start_link, []}})
 
     if Application.fetch_env!(:ama, :autoupdate) do
       IO.puts " auto-update enabled"
@@ -20,44 +23,10 @@ defmodule Ama do
       {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: AutoUpdateGen, start: {AutoUpdateGen, :start_link, []}})
     end
 
-    IO.puts "Initing Fabric.."
-    Fabric.init()
-    #Fabric.insert_genesis()
-
-    IO.puts "Initing TXPool.."
-    TXPool.init()
-
-    if !Application.fetch_env!(:ama, :offline) and !Application.fetch_env!(:ama, :testnet) do
-      rooted_tip_height = Fabric.rooted_tip_height()
-      if rooted_tip_height == nil or rooted_tip_height < Application.fetch_env!(:ama, :snapshot_height) do
-        IO.inspect {"tip - snapshot_height", rooted_tip_height, Application.fetch_env!(:ama, :snapshot_height)}
-        padded_height = String.pad_leading("#{Application.fetch_env!(:ama, :snapshot_height)}", 12, "0")
-        IO.inspect {"or download manually | aria2c -x 4 https://snapshots.amadeus.bot/#{padded_height}.zip"}
-        Fabric.close()
-        FabricSnapshot.download_latest()
-        Fabric.init()
-      end
-    else
-      if !Consensus.chain_tip() do
-        if Application.fetch_env!(:ama, :testnet) do
-          EntryGenesis.generate_testnet()
-        else
-          %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-          RocksDB.put("bic:epoch:trainers:height:#{String.pad_leading("0", 12, "0")}",
-            :erlang.term_to_binary([EntryGenesis.signer()]), %{db: db, cf: cf.contractstate})
-
-          entry = EntryGenesis.get()
-          Fabric.insert_entry(entry, :os.system_time(1000))
-          Consensus.apply_entry(entry)
-        end
-      end
-    end
-
-    #FabricSnapshot.backstep_temporal([Base58.decode("65ixJL6XkQAH2mrHn9nrHUaZfRZqUDpUqBqzMCdoPNku")])
-
-    pk = Application.fetch_env!(:ama, :trainer_pk)
-    IO.puts "systems functional. welcome #{Base58.encode(pk)}"
+    DB.API.init()
 
+    :ets.new(TXPool, [:ordered_set, :named_table, :public,
+      {:write_concurrency, true}, {:read_concurrency, true}, {:decentralized_counters, false}])
     :ets.new(AttestationCache, [:ordered_set, :named_table, :public,
       {:write_concurrency, true}, {:read_concurrency, true}, {:decentralized_counters, false}])
     :ets.new(SharedSecretCache, [:ordered_set, :named_table, :public,
@@ -74,53 +43,10 @@ defmodule Ama do
       %{path: Path.join([Application.fetch_env!(:ama, :work_folder), "local_kv/"])}
     )
 
-    if !Application.fetch_env!(:ama, :offline) do
-      if !Application.fetch_env!(:ama, :testnet) do
-        {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricSyncAttestGen, start: {FabricSyncAttestGen, :start_link, []}})
-        {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricSyncGen, start: {FabricSyncGen, :start_link, []}})
-      end
-
-      #{:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: ComputorGen, start: {ComputorGen, :start_link, []}})
-      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: LoggerGen, start: {LoggerGen, :start_link, []}})
-      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricGen, start: {FabricGen, :start_link, []}})
-      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricCoordinatorGen, start: {FabricCoordinatorGen, :start_link, []}})
-      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricEventGen, start: {FabricEventGen, :start_link, []}})
-      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: SpecialMeetingAttestGen, start: {SpecialMeetingAttestGen, :start_link, []}})
-      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: SpecialMeetingGen, start: {SpecialMeetingGen, :start_link, []}})
-
-      ip4 = Application.fetch_env!(:ama, :udp_ipv4_tuple)
-      port = Application.fetch_env!(:ama, :udp_port)
-      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: NodeGen, start: {NodeGen, :start_link, [ip4, port]}, restart: :permanent})
-      Enum.each(0..31, fn(idx)->
-        atom = :'NodeGenReassemblyGen#{idx}'
-        {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: atom, start: {NodeGenReassemblyGen, :start_link, [atom]}, restart: :permanent})
-      end)
-
-      Enum.each(0..7, fn(idx)->
-        :ets.new(:'NODENetGuardTotalFrames#{idx}', [:ordered_set, :named_table, :public,
-          {:write_concurrency, true}, {:read_concurrency, true}, {:decentralized_counters, false}])
-        :ets.new(:'NODENetGuardPer6Seconds#{idx}', [:ordered_set, :named_table, :public,
-          {:write_concurrency, true}, {:read_concurrency, true}, {:decentralized_counters, false}])
-      end)
-      Enum.each(0..7, fn(idx)->
-        {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor,
-          %{id: :'NodeGenSocketGen#{idx}', start: {NodeGenSocketGen, :start_link, [ip4, port, idx]}, restart: :permanent})
-      end)
-
-      #web panel
-      ipv4 = {a,b,c,d} = Application.fetch_env!(:ama, :http_ipv4)
-      if ipv4 != {0,0,0,0} do
-        {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: PG, start: {:pg, :start_link, []}})
-        {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: PGWSPanel, start: {:pg, :start_link, [PGWSRPC]}})
-
-        ipv4_string = "#{a}.#{b}.#{c}.#{d}"
-        port = Application.fetch_env!(:ama, :http_port)
-        IO.puts "started http-api on #{ipv4_string}:#{port}"
-
-        {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{
-          id: Photon.GenTCPAcceptor, start: {Photon.GenTCPAcceptor, :start_link, [ipv4, port, Ama.MultiServer]}
-        })
-      end
+    cond do
+      Application.fetch_env!(:ama, :offline) -> offline_node()
+      Application.fetch_env!(:ama, :testnet) -> testnet_node()
+      true -> full_node()
     end
 
     :persistent_term.put(NodeInited, true)
@@ -128,6 +54,96 @@ defmodule Ama do
     supervisor
   end
 
+  def offline_node() do
+    %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
+    if !DB.Entry.by_hash(EntryGenesis.get().hash) do
+      RocksDB.put("bic:epoch:trainers:height:#{String.pad_leading("0", 12, "0")}",
+        :erlang.term_to_binary([EntryGenesis.signer()]), %{db: db, cf: cf.contractstate})
+
+      entry = EntryGenesis.get()
+      DB.Entry.insert(entry)
+      FabricGen.apply_entry(entry)
+    end
+  end
+
+  def testnet_node() do
+    if !DB.Chain.tip() do
+      EntryGenesis.generate_testnet()
+    end
+    ipv4 = {a,b,c,d} = Application.fetch_env!(:ama, :http_ipv4)
+    if ipv4 != {0,0,0,0} do
+      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: TestNetHTTPSProxy, start: {TestNetHTTPSProxy, :start_link, [%{ip: ipv4, port: 443}]}})
+    end
+    run_node_services()
+  end
+
+  def full_node() do
+    rooted_height = DB.Chain.tip() && DB.Chain.rooted_height()
+    if rooted_height == nil or rooted_height < Application.fetch_env!(:ama, :snapshot_height) do
+      IO.inspect {"tip - snapshot_height", rooted_height, Application.fetch_env!(:ama, :snapshot_height)}
+      padded_height = String.pad_leading("#{Application.fetch_env!(:ama, :snapshot_height)}", 12, "0")
+      IO.inspect {"or download manually | aria2c -x 4 https://snapshots.amadeus.bot/#{padded_height}.zip"}
+      DB.API.close()
+      FabricSnapshot.download_latest()
+      DB.API.init()
+    end
+    run_node_services()
+  end
+
+  def run_node_services() do
+    if !Application.fetch_env!(:ama, :testnet) do
+      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricSyncAttestGen, start: {FabricSyncAttestGen, :start_link, []}})
+      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricSyncGen, start: {FabricSyncGen, :start_link, []}})
+    end
+
+    #{:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: ComputorGen, start: {ComputorGen, :start_link, []}})
+    {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: LoggerGen, start: {LoggerGen, :start_link, []}})
+    {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricGen, start: {FabricGen, :start_link, []}})
+    {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricCoordinatorGen, start: {FabricCoordinatorGen, :start_link, []}})
+    {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: FabricEventGen, start: {FabricEventGen, :start_link, []}})
+    {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: SpecialMeetingAttestGen, start: {SpecialMeetingAttestGen, :start_link, []}})
+    {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: SpecialMeetingGen, start: {SpecialMeetingGen, :start_link, []}})
+    run_udp_listener()
+    run_webpanel()
+  end
+
+  def run_udp_listener() do
+    ip4 = Application.fetch_env!(:ama, :udp_ipv4_tuple)
+    port = Application.fetch_env!(:ama, :udp_port)
+    {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: NodeGen, start: {NodeGen, :start_link, [ip4, port]}, restart: :permanent})
+    Enum.each(0..31, fn(idx)->
+      atom = :"NodeGenReassemblyGen#{idx}"
+      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: atom, start: {NodeGenReassemblyGen, :start_link, [atom]}, restart: :permanent})
+    end)
+
+    Enum.each(0..7, fn(idx)->
+      :ets.new(:"NODENetGuardTotalFrames#{idx}", [:ordered_set, :named_table, :public,
+        {:write_concurrency, true}, {:read_concurrency, true}, {:decentralized_counters, false}])
+      :ets.new(:"NODENetGuardPer6Seconds#{idx}", [:ordered_set, :named_table, :public,
+        {:write_concurrency, true}, {:read_concurrency, true}, {:decentralized_counters, false}])
+    end)
+    Enum.each(0..7, fn(idx)->
+      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor,
+        %{id: :"NodeGenSocketGen#{idx}", start: {NodeGenSocketGen, :start_link, [ip4, port, idx]}, restart: :permanent})
+    end)
+  end
+
+  def run_webpanel() do
+    #web panel
+    ipv4 = {a,b,c,d} = Application.fetch_env!(:ama, :http_ipv4)
+    if ipv4 != {0,0,0,0} do
+      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{id: PGWSPanel, start: {:pg, :start_link, [PGWSRPC]}})
+
+      ipv4_string = "#{a}.#{b}.#{c}.#{d}"
+      port = Application.fetch_env!(:ama, :http_port)
+      IO.puts "started http-api on #{ipv4_string}:#{port}"
+
+      {:ok, _} = DynamicSupervisor.start_child(Ama.Supervisor, %{
+        id: Photon.GenTCPAcceptor, start: {Photon.GenTCPAcceptor, :start_link, [ipv4, port, Ama.MultiServer]}
+      })
+    end
+  end
+
   def wait_node_inited(timeout_deadline \\ nil) do
     timeout_deadline = if timeout_deadline == nil do :os.system_time(1000) + 10*60_000 else timeout_deadline end
     ts = :os.system_time(1000)
diff --git a/ex/lib/http/multiserver.ex b/ex/lib/http/multiserver.ex
index 3c580bf..ff7e2f3 100644
--- a/ex/lib/http/multiserver.ex
+++ b/ex/lib/http/multiserver.ex
@@ -38,7 +38,7 @@ defmodule Ama.MultiServer do
                         end
                 end
 
-            {:tcp_closed, socket} -> :closed
+            {:tcp_closed, _socket} -> :closed
             m -> IO.inspect("MultiServer: #{inspect m}")
         end
     end
@@ -139,15 +139,17 @@ defmodule Ama.MultiServer do
                 quick_reply(state, %{error: :ok, emission_address: result})
 
             r.method == "POST" and String.starts_with?(r.path, "/api/contract/validate_bytecode") ->
-                {_, bytecode} = Photon.HTTP.read_body_all(state.socket, r)
+                {r, bytecode} = Photon.HTTP.read_body_all(state.socket, r)
                 result = API.Contract.validate_bytecode(bytecode)
-                quick_reply(state, result)
-            r.method == "GET" and String.starts_with?(r.path, "/api/contract/get") ->
-                key = String.replace(r.path, "/api/contract/get/", "")
-                [contract, key] = :binary.split(key, "/")
-                contract = Base58.decode(contract)
-                result = API.Contract.get("c:"<>contract<>":"<>key)
-                quick_reply(state, JSX.encode!(result))
+                quick_reply(%{state|request: r}, result)
+            r.method == "POST" and r.path == "/api/contract/get" ->
+                {r, key} = Photon.HTTP.read_body_all(state.socket, r)
+                result = API.Contract.get(key)
+                quick_reply(%{state|request: r}, JSX.encode!(result))
+            r.method == "POST" and r.path == "/api/contract/get_prefix" ->
+                {r, key} = Photon.HTTP.read_body_all(state.socket, r)
+                result = API.Contract.get_prefix(key)
+                quick_reply(%{state|request: r}, RDB.vecpak_encode(result))
             r.method == "GET" and String.starts_with?(r.path, "/api/contract/richlist") ->
                 result = API.Contract.richlist()
                 quick_reply(state, JSX.encode!(%{error: :ok, richlist: result}))
@@ -190,15 +192,24 @@ defmodule Ama.MultiServer do
                 balances = API.Wallet.balance_all(pk)
                 quick_reply(state, %{error: :ok, balances: balances})
 
-            r.method == "POST" and String.starts_with?(r.path, "/api/tx/submit") ->
+            r.method == "POST" and r.path == "/api/tx/submit" ->
                 {r, tx_packed} = Photon.HTTP.read_body_all(state.socket, r)
                 tx_packed = if Base58.likely(tx_packed) do Base58.decode(tx_packed |> String.trim()) else tx_packed end
                 result = API.TX.submit(tx_packed)
-                quick_reply(state, result)
+                quick_reply(%{state|request: r}, result)
+            r.method == "POST" and r.path == "/api/tx/submit_and_wait" ->
+                {r, tx_packed} = Photon.HTTP.read_body_all(state.socket, r)
+                tx_packed = if Base58.likely(tx_packed) do Base58.decode(tx_packed |> String.trim()) else tx_packed end
+                result = API.TX.submit_and_wait(tx_packed)
+                quick_reply(%{state|request: r}, result)
             r.method == "GET" and String.starts_with?(r.path, "/api/tx/submit/") ->
                 tx_packed = String.replace(r.path, "/api/tx/submit/", "")
                 result = API.TX.submit(Base58.decode(tx_packed))
                 quick_reply(state, result)
+            r.method == "GET" and String.starts_with?(r.path, "/api/tx/submit_and_wait/") ->
+                tx_packed = String.replace(r.path, "/api/tx/submit_and_wait/", "")
+                result = API.TX.submit_and_wait(Base58.decode(tx_packed))
+                quick_reply(state, result)
 
             #r.method == "GET" ->
             #    bin = build_dashboard(state)
diff --git a/ex/lib/http/ws_rpc.ex b/ex/lib/http/ws_rpc.ex
index 08634b2..7203747 100644
--- a/ex/lib/http/ws_rpc.ex
+++ b/ex/lib/http/ws_rpc.ex
@@ -21,7 +21,6 @@ defmodule HTTP.WS.RPC do
             {:tcp_closed, socket} -> :closed
 
             {:update_stats_entry_tx, stats, entry, txs} ->
-                #TODO: later get the stats once and broadcast to all group
                 :ok = :gen_tcp.send(s.socket, Photon.WS.encode(:text, JSX.encode!(%{op: :event_stats, stats: stats})))
                 :ok = :gen_tcp.send(s.socket, Photon.WS.encode(:text, JSX.encode!(%{op: :event_entry, entry: entry})))
                 if length(txs) > 0 do
diff --git a/ex/lib/misc/autoupdate_gen.ex b/ex/lib/misc/autoupdate_gen.ex
index 3204f9d..4f9b11f 100644
--- a/ex/lib/misc/autoupdate_gen.ex
+++ b/ex/lib/misc/autoupdate_gen.ex
@@ -24,7 +24,7 @@ defmodule AutoUpdateGen do
   def upgrade(is_boot \\ false) do
     url = "https://api.github.com/repos/amadeus-robot/node/releases/latest"
     {:ok, %{status_code: 200, body: body}} = :comsat_http.get(url, %{},
-        %{ssl_options: [{:server_name_indication, 'api.github.com'}, {:verify, :verify_none}]})
+      %{ssl_options: [{:server_name_indication, ~c"api.github.com"}, {:verify, :verify_none}]})
     json = JSX.decode!(body, labels: :atom)
     if Application.fetch_env!(:ama, :version) < String.trim(json.tag_name, "v") do
         download_url = Enum.find_value(json.assets, fn(asset)->
@@ -33,7 +33,7 @@ defmodule AutoUpdateGen do
         if download_url do
             IO.inspect {:downloading_upgrade, download_url}
             {:ok, %{status_code: 200, body: bin}} = :comsat_http.get(download_url, %{},
-                %{timeout: 300_000, ssl_options: [{:server_name_indication, 'github.com'}, {:verify, :verify_none}]})
+              %{timeout: 300_000, ssl_options: [{:server_name_indication, ~c"github.com"}, {:verify, :verify_none}]})
 
             cwd_dir = File.cwd!()
             path_tmp = Path.join(cwd_dir, "amadeusd_tmp")
@@ -44,13 +44,13 @@ defmodule AutoUpdateGen do
 
             cond do
               is_boot -> :erlang.halt()
-              Consensus.is_trainer() ->
+              DB.Chain.is_validator() ->
                 FabricGen.exitAfterMySlot()
 
                 #incase
-                now_height = Consensus.chain_height()
+                now_height = DB.Chain.height()
                 Process.sleep(30*1000)
-                delta = Consensus.chain_height() - now_height
+                delta = DB.Chain.height() - now_height
                 if delta <= 3 do
                   :erlang.halt()
                 end
diff --git a/ex/lib/misc/jcs.ex b/ex/lib/misc/jcs.ex
deleted file mode 100644
index 4116901..0000000
--- a/ex/lib/misc/jcs.ex
+++ /dev/null
@@ -1,41 +0,0 @@
-defmodule JCS do
-    def serialize(map) when is_map(map) do
-        map
-        |> serialize_1()
-        |> JSX.encode!()
-    end
-    defp serialize_1(map) do
-        serialize_list = fn(list, self)->
-            Enum.map(list, fn(v)->
-                cond do
-                    is_map(v)-> serialize_1(v)
-                    is_list(v)-> self.(v)
-                    true -> v
-                end
-            end)
-        end
-        Enum.map(map, fn{k,v}->
-            cond do
-                is_map(v) -> {k, serialize_1(v)}
-                is_list(v) -> {k, serialize_list.(v, serialize_list)}
-                true -> {k,v}
-            end
-        end)
-        |> Enum.sort_by(& &1)
-        |> case do
-            [] -> %{}
-            list -> list
-        end
-    end
-
-    def validate(binary) do
-        map = JSX.decode!(binary, labels: :attempt_atom)
-        map
-        |> serialize()
-        |> Kernel.==(binary)
-        |> case do
-            true -> map
-            false -> nil
-        end
-    end
-end
diff --git a/ex/lib/misc/offline.ex b/ex/lib/misc/offline.ex
deleted file mode 100644
index 509ff56..0000000
--- a/ex/lib/misc/offline.ex
+++ /dev/null
@@ -1,38 +0,0 @@
-defmodule Offline do
-  def add_balance(amount \\ nil, pk \\ nil) do
-    pk = if pk do pk else Application.fetch_env!(:ama, :trainer_pk) end
-    amount = if amount do amount else "1000000000000" end
-
-    %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-    RocksDB.put("bic:coin:balance:#{pk}:AMA", "#{amount}", %{db: db, cf: cf.contractstate})
-  end
-
-  def deploy(wasmpath, pk \\ nil) do
-    pk = if pk do pk else Application.fetch_env!(:ama, :trainer_pk) end
-
-    wasmbytes = File.read!(wasmpath)
-
-    %{db: db, cf: cf} = :persistent_term.get({:rocksdb, Fabric})
-    RocksDB.put("bic:contract:account:#{pk}:bytecode", wasmbytes, %{db: db, cf: cf.contractstate})
-  end
-
-  def call(sk, pk, function, args, attach_symbol \\ nil, attach_amount \\ nil) do
-    packed_tx = TX.build(sk, pk, function, args, nil, attach_symbol, attach_amount)
-    TXPool.insert(packed_tx)
-    entry = Consensus.produce_entry(Consensus.chain_height()+1)
-    Fabric.insert_entry(entry, :os.system_time(1000))
-    Consensus.apply_entry(entry)
-  end
-
-  def produce_entry(clean_txpool \\ true) do
-    entry = Consensus.produce_entry(Consensus.chain_height()+1)
-    Fabric.insert_entry(entry, :os.system_time(1000))
-    result = Consensus.apply_entry(entry)
-    clean_txpool && TXPool.purge_stale()
-    result
-  end
-
-  def state(pk \\ nil) do
-
-  end
-end
diff --git a/ex/lib/misc/rocksdb.ex b/ex/lib/misc/rocksdb.ex
index 334a5b3..0270fd5 100644
--- a/ex/lib/misc/rocksdb.ex
+++ b/ex/lib/misc/rocksdb.ex
@@ -20,6 +20,22 @@ defmodule RocksDB do
         end
     end
 
+    def exists(key, opts) do
+        db = opts[:db]
+        cf = opts[:cf]
+        rtx = opts[:rtx]
+        cond do
+            !!rtx and !!cf -> RDB.transaction_exists_cf(rtx, cf, key)
+            !!rtx -> RDB.transaction_exists(rtx, key)
+            !!db and !!cf -> RDB.exists_cf(cf, key)
+            !!db -> RDB.exists(db, key)
+        end
+        |> case do
+            {:ok, true} -> true
+            {:ok, false} -> false
+        end
+    end
+
     def get_next(prefix, key, opts) do
         {:ok, it} = iterator(opts)
 
@@ -94,7 +110,7 @@ defmodule RocksDB do
       |> case do
           {:ok, nil} -> nil
           {:ok, value} ->
-            << left::size(bit_idx), bit::size(1), _::bitstring >> = value
+            <<_left::size(bit_idx), bit::size(1), _::bitstring >> = value
             bit
       end
     end
@@ -142,6 +158,22 @@ defmodule RocksDB do
         end
     end
 
+    def delete_prefix(prefix, opts) do
+        {:ok, it} = iterator(opts)
+        res = RDB.iterator_move(it, {:seek, prefix})
+        delete_prefix_1(prefix, it, res, opts)
+    end
+    defp delete_prefix_1(prefix, it, res, opts) do
+        case res do
+            {:ok, <<^prefix::binary, key::binary>>, value} ->
+                res = RDB.iterator_move(it, :next)
+                RocksDB.delete(key, opts)
+                delete_prefix_1(prefix, it, res, opts)
+            {:error, :invalid_iterator} -> :ok
+            _ -> :ok
+        end
+    end
+
     defp iterator(opts) do
         db = opts[:db]
         cf = opts[:cf]
@@ -163,8 +195,12 @@ defmodule RocksDB do
       :ok = RDB.transaction_commit(rtx)
     end
 
-    def dump(db_ref, cf) do
-        {:ok, it} = RDB.iterator_cf(db_ref, cf)
+    def transaction_rollback(rtx) do
+      :ok = RDB.transaction_rollback(rtx)
+    end
+
+    def dump(cf) do
+        {:ok, it} = RDB.iterator_cf(cf)
         res = RDB.iterator_move(it, :first)
         dump_1(it, res)
     end
@@ -199,7 +235,7 @@ defmodule RocksDB do
     end
 
     def flush_wal(db) do
-        RDB.flush_wal(db, true)
+        RDB.flush_wal(db)
     end
 
     def compact_all(cfs) do
diff --git a/ex/lib/misc/testnet.ex b/ex/lib/misc/testnet.ex
index 2d02683..c6428d4 100644
--- a/ex/lib/misc/testnet.ex
+++ b/ex/lib/misc/testnet.ex
@@ -9,19 +9,22 @@ defmodule Testnet do
     RocksDB.get(key, %{db: db, cf: cf.contractstate})
   end
 
-  def slash_trainer() do
-    trainers = Consensus.trainers_for_height(Consensus.chain_height()+1)
-    signer_pk = List.first(trainers)
-    signer_sk = Application.fetch_env!(:ama, :keys_by_pk)[signer_pk].seed
-    malicious_pk = List.last(trainers)
+  def slash_trainer(signer_count \\ 1) do
+    validators = DB.Chain.validators_for_height(DB.Chain.height()+1)
+    malicious_pk = List.last(validators)
+    validators_signing = DB.Chain.validators_for_height_my(DB.Chain.height()+1) |> Enum.take(signer_count)
 
-    msg = <<"slash_trainer", 0::32-little, malicious_pk::binary>>
-    signature = BlsEx.sign!(signer_sk, msg, BLS12AggSig.dst_motion())
+    aggsig = BLS12AggSig.new_padded(length(validators))
+    aggsig = Enum.reduce(validators_signing, aggsig, fn(signer_pk, aggsig)->
+      msg = <<"slash_trainer", 0::32-little, malicious_pk::binary>>
+      seed = Application.fetch_env!(:ama, :keys_by_pk)[signer_pk].seed
+      signature = BlsEx.sign!(seed, msg, BLS12AggSig.dst_motion())
+      BLS12AggSig.add_padded(aggsig, validators, signer_pk, signature)
+    end)
 
-    ma = BLS12AggSig.new(trainers, signer_pk, signature)
-
-    args = ["0", malicious_pk, signature, "#{bit_size(ma.mask)}", Util.pad_bitstring_to_bytes(ma.mask)]
+    args = ["0", malicious_pk, aggsig.aggsig, "#{aggsig.mask_size}", aggsig.mask]
 
+    signer_sk = Application.fetch_env!(:ama, :trainer_sk)
     Testnet.call(signer_sk, "Epoch", "slash_trainer", args)
   end
 end
diff --git a/ex/lib/misc/testnet_https.ex b/ex/lib/misc/testnet_https.ex
new file mode 100644
index 0000000..2757ff0
--- /dev/null
+++ b/ex/lib/misc/testnet_https.ex
@@ -0,0 +1,130 @@
+defmodule LocalCert do
+  def ensure!(certfile, keyfile, hosts) do
+    File.mkdir_p!(Path.dirname(certfile))
+    if File.exists?(certfile) and File.exists?(keyfile), do: :ok, else: gen(hosts)
+  end
+
+  def gen(hosts \\ nil) do
+    hosts = try do
+      File.read!("/etc/hosts")
+      |> String.split("\n")
+      |> Enum.map(fn(string)->
+        String.split(string, " ") |> List.last
+      end)
+      |> Enum.filter(& &1 != "" and !String.starts_with?(&1, "ip6-"))
+    catch _,_ -> [] end
+    # Key (you can switch to EC with X509.PrivateKey.new_ec(:prime256v1))
+    priv = X509.PrivateKey.new_rsa(2048)
+
+    # Subject Alt Names (DNS + IP)
+    sans = for h <- hosts do
+      case :inet.parse_address(String.to_charlist(h)) do
+        {:ok, ip} -> {:iPAddress, ip}
+        _ -> {:dNSName, h}
+      end
+    end
+
+    subject = X509.RDNSequence.new("/CN=#{Enum.at(hosts, 0) || "localhost"}")
+
+    cert =
+      X509.Certificate.self_signed(
+        priv,
+        subject,
+        template: :server,
+        hash: :sha256,
+        serial: serial = :crypto.strong_rand_bytes(8) |> :binary.decode_unsigned(),
+        subject_alt_name: sans,
+        key_usage: [:digitalSignature, :keyEncipherment],
+        extended_key_usage: [:serverAuth]
+      )
+
+
+    %{
+      cert_der: X509.Certificate.to_der(cert),
+      # Use PKCS#8 (PrivateKeyInfo) so it works regardless of key type
+      key_der: X509.PrivateKey.to_der(priv)
+    }
+  end
+end
+
+defmodule TestNetHTTPSProxy do
+  use GenServer
+
+  def start_link(opts \\ %{}) do
+    GenServer.start_link(__MODULE__, opts, name: __MODULE__)
+  end
+
+  def allowselfsigned(_, reason, state) do
+    {:valid, state}
+  end
+
+  def init(state) do
+    :erlang.send_after(0, self(), :accept)
+    Logger.put_module_level(:ssl_alert, :error)
+
+    #{:ok, ip} = :inet.parse_ipv4_address(~c"#{state[:ip] || "127.0.0.1"}")
+    ip = state[:ip] || {127,0,0,1}
+    ip_string = "#{elem(ip,0)}.#{elem(ip,1)}.#{elem(ip,2)}.#{elem(ip,3)}"
+    port = state[:port] || 443
+
+    IO.puts("TestNet HTTPS->HTTP Proxy listening (in-mem cert) on https://#{ip_string}:#{port}")
+
+    :ok = :ssl.start()
+    %{cert_der: cert_der, key_der: key_der} = LocalCert.gen()
+    ssl_opts = [
+      {:ip, ip},
+      {:reuseaddr, true},
+      {:cert, cert_der},
+      {:key, {:RSAPrivateKey, key_der}},
+      {:supported_groups, [:x25519, :secp256r1]},
+      {:versions, [:"tlsv1.3", :"tlsv1.2"]},
+      {:binary, true},
+      {:active, false},
+      #cb_info: {:gen_tcp, :tcp, :tcp_closed, :tcp_error},
+      {:verify, :verify_none},
+      {:fail_if_no_peer_cert, false},
+      #{:verify_fun, {:allowselfsigned, []}}
+    ]
+    {:ok, listen_socket} = :ssl.listen(port, ssl_opts)
+
+    state = Map.merge(state, %{listen_socket: listen_socket})
+    {:ok, state}
+  end
+
+  def handle_info(:accept, state) do
+    {:ok, ssl_socket} = :ssl.transport_accept(state.listen_socket)
+    case :ssl.handshake(ssl_socket) do
+      {:ok, ssl_socket} ->
+        pid = :erlang.spawn(__MODULE__, :client_loop, [%{ssl_socket: ssl_socket}])
+        :ok = :ssl.controlling_process(ssl_socket, pid)
+      {:error, reason} ->
+        :ssl.close(ssl_socket)
+    end
+
+    :erlang.send_after(1, self(), :accept)
+    {:noreply, state}
+  end
+
+  def client_loop(state) do
+    up_host = Application.fetch_env!(:ama, :http_ipv4)
+    up_port = 80
+    {:ok, up_socket} = :gen_tcp.connect(up_host, up_port, [:binary, active: false], 5_000)
+    :ok = :ssl.setopts(state.ssl_socket, active: :once)
+    :ok = :inet.setopts(up_socket, active: :once)
+    client_loop_1(state.ssl_socket, up_socket)
+  end
+  def client_loop_1(ssl_socket, up_socket) do
+    receive do
+    {:ssl, ssl_socket, data} ->
+        :ok = :gen_tcp.send(up_socket, data)
+        :ok = :ssl.setopts(ssl_socket, active: :once)
+        client_loop_1(ssl_socket, up_socket)
+      {:tcp, up_socket, data} ->
+        :ok = :ssl.send(ssl_socket, data)
+        :ok = :inet.setopts(up_socket, active: :once)
+        client_loop_1(ssl_socket, up_socket)
+      {:ssl_closed, ssl_socket} -> :ssl.close(ssl_socket)
+      msg -> IO.inspect( msg )
+    after 60_000 -> nil end
+  end
+end
diff --git a/ex/lib/misc/util.ex b/ex/lib/misc/util.ex
index dbf30e0..1598f20 100644
--- a/ex/lib/misc/util.ex
+++ b/ex/lib/misc/util.ex
@@ -125,7 +125,7 @@ defmodule Util do
     def get(url, headers \\ %{}, opts \\ %{}) do
         %{host: host} = URI.parse(url)
         ssl_opts = [
-            {:server_name_indication, '#{host}'},
+            {:server_name_indication, ~c"#{host}"},
             {:verify,:verify_peer},
             {:depth,99},
             {:cacerts, :certifi.cacerts()},
@@ -147,7 +147,7 @@ defmodule Util do
     def delete(url, body, headers \\ %{}, opts \\ %{}) do
         %{host: host} = URI.parse(url)
         ssl_opts = [
-            {:server_name_indication, '#{host}'},
+            {:server_name_indication, ~c"#{host}"},
             {:verify,:verify_peer},
             {:depth,99},
             {:cacerts, :certifi.cacerts()},
@@ -169,7 +169,7 @@ defmodule Util do
     def post(url, body, headers \\ %{}, opts \\ %{}) do
         %{host: host} = URI.parse(url)
         ssl_opts = [
-            {:server_name_indication, '#{host}'},
+            {:server_name_indication, ~c"#{host}"},
             {:verify,:verify_peer},
             {:depth,99},
             {:cacerts, :certifi.cacerts()},
@@ -192,7 +192,7 @@ defmodule Util do
     def put(url, body, headers \\ %{}, opts \\ %{}) do
         %{host: host} = URI.parse(url)
         ssl_opts = [
-            {:server_name_indication, '#{host}'},
+            {:server_name_indication, ~c"#{host}"},
             {:verify,:verify_peer},
             {:depth,99},
             {:cacerts, :certifi.cacerts()},
@@ -247,6 +247,52 @@ defmodule Util do
         bit == 1
     end
 
+    def popcnt(bs) when is_bitstring(bs) do
+      pc4 = <<0,1,1,2,1,2,2,3,1,2,2,3,2,3,3,4>>
+
+      total_bits = bit_size(bs)
+      full_bytes = div(total_bits, 8)
+      rem_bits   = rem(total_bits, 8)
+
+      <<bytes::binary-size(full_bytes), rest::bitstring-size(rem_bits)>> = bs
+
+      # byte popcount via two 4-bit lookups per byte, looped with an anonymous recursion
+      byte_count =
+        (fn loop, i, acc ->
+           if i == byte_size(bytes) do
+             acc
+           else
+             b  = :binary.at(bytes, i)
+             hi = :erlang.bsr(b, 4)
+             lo = :erlang.band(b, 15)
+             loop.(loop, i + 1, acc + :binary.at(pc4, hi) + :binary.at(pc4, lo))
+           end
+         end).(fn loop, i, acc ->
+                if i == byte_size(bytes) do
+                  acc
+                else
+                  b  = :binary.at(bytes, i)
+                  hi = :erlang.bsr(b, 4)
+                  lo = :erlang.band(b, 15)
+                  loop.(loop, i + 1, acc + :binary.at(pc4, hi) + :binary.at(pc4, lo))
+                end
+              end, 0, 0)
+
+      # tail (7 bits): pack to int and Kernighan-count with an anonymous recursion
+      tail_count =
+        if rem_bits == 0 do
+          0
+        else
+          <<v::unsigned-integer-size(rem_bits)>> = rest
+          (fn k, x, a -> if x == 0, do: a, else: k.(k, :erlang.band(x, x - 1), a + 1) end).(
+            fn k, x, a -> if x == 0, do: a, else: k.(k, :erlang.band(x, x - 1), a + 1) end,
+            v, 0
+          )
+        end
+
+      byte_count + tail_count
+    end
+
     def index_of(list, key) do
         {result, index} = Enum.reduce_while(list, {nil, 0}, fn(element, {result, index})->
             if element == key do
@@ -264,4 +310,13 @@ defmodule Util do
         {res, _} = System.shell("timedatectl status")
         String.contains?(res, "System clock synchronized: yes")
     end
+
+    def ensure_copied(bin) when is_binary(bin) do
+      if :binary.referenced_byte_size(bin) > byte_size(bin) do
+        IO.inspect {:ensure_copied, :binary.referenced_byte_size(bin), byte_size(bin)}
+        :binary.copy(bin)
+      else
+        bin
+      end
+    end
 end
diff --git a/ex/lib/misc/vanillaser.ex b/ex/lib/misc/vanillaser.ex
index 0562bd5..40d659b 100644
--- a/ex/lib/misc/vanillaser.ex
+++ b/ex/lib/misc/vanillaser.ex
@@ -32,11 +32,25 @@ defmodule VanillaSer do
             is_map(term) ->
                 acc = <<acc::binary, 7>>
                 acc = encode_varint(:erlang.map_size(term), acc)
+
                 Enum.sort_by(term, & elem(&1,0))
                 |> Enum.reduce(acc, fn({k, v}, acc)->
                     acc = encode(k, acc)
                     encode(v, acc)
                 end)
+            #ENABLE LATER
+            #is_map(term) ->
+            #    acc = <<acc::binary, 7>>
+            #    acc = encode_varint(:erlang.map_size(term), acc)
+            #
+            #    Enum.map(term, fn {k, v} ->
+            #      {encode(k, <<>>), encode(v, <<>>)}
+            #    end)
+            #    |> Enum.sort_by(& elem(&1,0))
+            #    |> Enum.reduce(acc, fn({k, v}, acc)->
+            #    acc = acc <> k
+            #    acc <> v
+            #    end)
         end
     end
     def encode_varint(0, acc) do acc <> <<0>> end
diff --git a/ex/lib/native/rdb.ex b/ex/lib/native/rdb.ex
index 30dd5c5..2ad2396 100644
--- a/ex/lib/native/rdb.ex
+++ b/ex/lib/native/rdb.ex
@@ -7,6 +7,7 @@ defmodule RDB do
 
   def open_transaction_db(_path, _cf_names), do: :erlang.nif_error(:nif_not_loaded)
   def close_db(_db), do: :erlang.nif_error(:nif_not_loaded)
+  def drop_cf(_db, _cf), do: :erlang.nif_error(:nif_not_loaded)
   def property_value(_db, _key), do: :erlang.nif_error(:nif_not_loaded)
   def property_value_cf(_cf, _key), do: :erlang.nif_error(:nif_not_loaded)
   def compact_range_cf_all(_cf), do: :erlang.nif_error(:nif_not_loaded)
@@ -16,6 +17,8 @@ defmodule RDB do
   def flush_cf(_cf), do: :erlang.nif_error(:nif_not_loaded)
   def get(_db, _key), do: :erlang.nif_error(:nif_not_loaded)
   def get_cf(_cf, _key), do: :erlang.nif_error(:nif_not_loaded)
+  def exists(_db, _key), do: :erlang.nif_error(:nif_not_loaded)
+  def exists_cf(_cf, _key), do: :erlang.nif_error(:nif_not_loaded)
   def put(_db, _key, _value), do: :erlang.nif_error(:nif_not_loaded)
   def put_cf(_cf, _key, _value), do: :erlang.nif_error(:nif_not_loaded)
   def delete(_db, _key), do: :erlang.nif_error(:nif_not_loaded)
@@ -30,6 +33,8 @@ defmodule RDB do
   def transaction_rollback_to_savepoint(_tx), do: :erlang.nif_error(:nif_not_loaded)
   def transaction_get(_tx, _key), do: :erlang.nif_error(:nif_not_loaded)
   def transaction_get_cf(_tx, _cf, _key), do: :erlang.nif_error(:nif_not_loaded)
+  def transaction_exists(_tx, _key), do: :erlang.nif_error(:nif_not_loaded)
+  def transaction_exists_cf(_tx, _cf, _key), do: :erlang.nif_error(:nif_not_loaded)
   def transaction_put(_tx, _key, _value), do: :erlang.nif_error(:nif_not_loaded)
   def transaction_put_cf(_tx, _cf, _key, _value), do: :erlang.nif_error(:nif_not_loaded)
   def transaction_delete(_tx, _key), do: :erlang.nif_error(:nif_not_loaded)
diff --git a/ex/lib/node/computor_gen.ex b/ex/lib/node/computor_gen.ex
index 595bde5..ad8786c 100644
--- a/ex/lib/node/computor_gen.ex
+++ b/ex/lib/node/computor_gen.ex
@@ -56,8 +56,8 @@ defmodule ComputorGen do
     pk = Application.fetch_env!(:ama, :trainer_pk)
     pop = Application.fetch_env!(:ama, :trainer_pop)
 
-    coins = Consensus.chain_balance(pk)
-    epoch = Consensus.chain_epoch()
+    coins = DB.Chain.balance(pk)
+    epoch = DB.Chain.epoch()
     hasExecCoins = coins >= BIC.Coin.to_cents(100)
     cond do
         (state.type == :trainer and !hasExecCoins) or state.type == nil ->
diff --git a/ex/lib/node/logger_gen.ex b/ex/lib/node/logger_gen.ex
index c025d05..1700e06 100644
--- a/ex/lib/node/logger_gen.ex
+++ b/ex/lib/node/logger_gen.ex
@@ -35,11 +35,10 @@ defmodule LoggerGen do
   end
 
   def tick(state) do
-    entry_rooted = Fabric.rooted_tip_entry()
+    entry_rooted = DB.Chain.rooted_tip_entry()
     rooted_height = entry_rooted.header_unpacked.height
 
-    entry = Consensus.chain_tip_entry()
-    entry = Entry.unpack(entry)
+    entry = DB.Chain.tip_entry()
     height = entry.header_unpacked.height
     slot = entry.header_unpacked.slot
     txpool_size = :ets.info(TXPool, :size)
@@ -48,9 +47,9 @@ defmodule LoggerGen do
     peer_cnt = length(vals++peers) + 1
 
     pk = Application.fetch_env!(:ama, :trainer_pk)
-    coins = Consensus.chain_balance(pk)
+    coins = DB.Chain.balance(pk)
 
-    trainers = Consensus.trainers_for_height(Entry.height(entry)+1)
+    trainers = DB.Chain.validators_for_height(Entry.height(entry)+1)
 
     #Moneybag mean the money in my bag
     #Moneybag mean the money in the bag
diff --git a/ex/lib/node/node_anr.ex b/ex/lib/node/node_anr.ex
index 30ff02f..25e0351 100644
--- a/ex/lib/node/node_anr.ex
+++ b/ex/lib/node/node_anr.ex
@@ -89,7 +89,7 @@ defmodule NodeANR do
       goodDelta = (ts - anr.ts) > -3600 #60 minutes max into future
 
       # Not too big
-      bin = :erlang.term_to_binary(anr, [:deterministic])
+      bin = RDB.vecpak_encode(anr)
       anr = Map.take(anr, @keys)
       if byte_size(bin) <= @max_anr_size and goodDelta and verify_signature(anr) do
         anr
@@ -111,7 +111,7 @@ defmodule NodeANR do
   end
 
   def insert(anr) do
-    anr = Map.put(anr, :hasChainPop, !!Consensus.chain_pop(anr.pk))
+    anr = Map.put(anr, :hasChainPop, !!DB.Chain.pop(anr.pk))
     old_anr = MnesiaKV.get(NODEANR, anr.pk)
     routed = if !Application.fetch_env!(:ama, :check_routed_peer) do true else CymruRouting.globally_routed?(anr.ip4) end
     cond do
@@ -137,15 +137,15 @@ defmodule NodeANR do
   end
 
   def not_handshaked_pk_ip4() do
-    :ets.select(:"Elixir.NODEANR_index", [{{{:'$1', false, :'$2', :_}, :_}, [], [%{pk: :'$1', ip4: :'$2'}]}])
+    :ets.select(:"Elixir.NODEANR_index", [{{{:"$1", false, :"$2", :_}, :_}, [], [%{pk: :"$1", ip4: :"$2"}]}])
   end
 
   def handshaked_pk_ip4() do
-    :ets.select(:"Elixir.NODEANR_index", [{{{:'$1', true, :'$2', :_}, :_}, [], [{{:'$1', :'$2'}}]}])
+    :ets.select(:"Elixir.NODEANR_index", [{{{:"$1", true, :"$2", :_}, :_}, [], [{{:"$1", :"$2"}}]}])
   end
 
   def handshaked() do
-    :ets.select(:"Elixir.NODEANR_index", [{{{:'$1', true, :'$2', :_}, :_}, [], [%{pk: :'$1', ip4: :'$2'}]}])
+    :ets.select(:"Elixir.NODEANR_index", [{{{:"$1", true, :"$2", :_}, :_}, [], [%{pk: :"$1", ip4: :"$2"}]}])
   end
 
   def handshaked(pk) when is_binary(pk) do
@@ -156,16 +156,16 @@ defmodule NodeANR do
   end
 
   def by_pks_ip(pks) when is_list(pks) do
-    match_spec = Enum.map(pks, fn(pk)-> {{{pk, true, :'$1', :_}, :_}, [], [:'$1']} end)
+    match_spec = Enum.map(pks, fn(pk)-> {{{pk, true, :"$1", :_}, :_}, [], [:"$1"]} end)
     :ets.select(:"Elixir.NODEANR_index", match_spec)
   end
 
   def b3_f4() do
-    :ets.select(:"Elixir.NODEANR_index", [{{{:_, :_, :_, :_}, %{pk_b3_f4: :'$1'}}, [], [:'$1']}])
+    :ets.select(:"Elixir.NODEANR_index", [{{{:_, :_, :_, :_}, %{pk_b3_f4: :"$1"}}, [], [:"$1"]}])
   end
 
   def by_pks_b3_f4(pks) when is_list(pks) do
-    match_spec = Enum.map(pks, fn(pk)-> {{{pk, true, :_, :_}, %{pk_b3_f4: :'$1'}}, [], [:'$1']} end)
+    match_spec = Enum.map(pks, fn(pk)-> {{{pk, true, :_, :_}, %{pk_b3_f4: :"$1"}}, [], [:"$1"]} end)
     :ets.select(:"Elixir.NODEANR_index", match_spec)
   end
 
@@ -180,12 +180,12 @@ defmodule NodeANR do
     ts_m = :os.system_time(1000)
     cutoff = ts_m - 30_000
 
-    cur_validator = Consensus.trainer_for_slot_current()
-    validators = Consensus.trainers_for_height(Consensus.chain_height()+1)
+    cur_validator = DB.Chain.validator_for_height_current()
+    validators = DB.Chain.validators_for_height(DB.Chain.height()+1)
     {left, rest} = Enum.split_while(validators, &(&1 != cur_validator))
     validators = rest ++ left
 
-    peers = :ets.select(:"Elixir.NODEANR_index", [{{{:'$1', true, :'$2', :_}, :_}, [], [%{pk: :'$1', ip4: :'$2'}]}])
+    peers = :ets.select(:"Elixir.NODEANR_index", [{{{:"$1", true, :"$2", :_}, :_}, [], [%{pk: :"$1", ip4: :"$2"}]}])
     |> Enum.filter(& NodeANR.get_last_message(&1.pk) >= cutoff)
     validator_peers = Enum.filter(peers, & &1.pk in validators)
     {validator_peers, Enum.shuffle(peers -- validator_peers)}
@@ -200,7 +200,7 @@ defmodule NodeANR do
   end
 
   def all_validators() do
-    validators = Consensus.trainers_for_height(Consensus.chain_height()+1)
+    validators = DB.Chain.validators_for_height(DB.Chain.height()+1)
     match_spec = Enum.map(validators, fn(pk)-> {{pk, :_}, [], [{:element, 2, :"$_"}]} end)
     :ets.select(NODEANR, match_spec)
   end
@@ -222,7 +222,7 @@ defmodule NodeANR do
   def clear_verified_offline() do
     ts_m = :os.system_time(1000)
     cutoff = ts_m - 30_000
-    :ets.select(:"Elixir.NODEANR_index", [{{{:'$1', true, :_, :_}, :_}, [], [:'$1']}])
+    :ets.select(:"Elixir.NODEANR_index", [{{{:"$1", true, :_, :_}, :_}, [], [:"$1"]}])
     |> Enum.each(fn(pk)->
       if get_last_message(pk) < cutoff do
         set_handshaked(pk, false)
diff --git a/ex/lib/node/node_gen.ex b/ex/lib/node/node_gen.ex
index dae3d61..e18647a 100644
--- a/ex/lib/node/node_gen.ex
+++ b/ex/lib/node/node_gen.ex
@@ -22,12 +22,12 @@ defmodule NodeGen do
 
   def get_socket_gen() do
     idx = :rand.uniform(8) - 1
-    :'NodeGenSocketGen#{idx}'
+    :"NodeGenSocketGen#{idx}"
   end
 
   def get_reassembly_gen(pk, ts_nano) do
     idx = :erlang.phash2({pk, ts_nano}, 32)
-    :'NodeGenReassemblyGen#{idx}'
+    :"NodeGenReassemblyGen#{idx}"
   end
 
   def broadcast(msg, opts \\ %{validators: 1000, peers: 10}) do
diff --git a/ex/lib/node/node_gen_netguard.ex b/ex/lib/node/node_gen_netguard.ex
index c73e8d9..ca75c4e 100644
--- a/ex/lib/node/node_gen_netguard.ex
+++ b/ex/lib/node/node_gen_netguard.ex
@@ -13,8 +13,8 @@ defmodule NodeGenNetguard do
     catchup_reply: 20,
     event_tip: 30,
     event_entry: 30,
-    event_tx: 6000,
-    event_attestation: 6000,
+    event_tx: 8000,
+    event_attestation: 8000,
     solicit_entry: 2,
     sell_sol: 10_000,
   }
@@ -22,14 +22,14 @@ defmodule NodeGenNetguard do
 
   def frame_ok(peer_ip) do
     phash = :erlang.phash2(peer_ip, 8)
-    counter = :ets.update_counter(:'NODENetGuardTotalFrames#{phash}', peer_ip, 1, {peer_ip, 0})
+    counter = :ets.update_counter(:"NODENetGuardTotalFrames#{phash}", peer_ip, 1, {peer_ip, 0})
     counter < @max_frames_per_6_sec
   end
 
   def op_ok(peer_ip, op) do
     if @msg_ops[op] do
       phash = :erlang.phash2(peer_ip, 8)
-      counter = :ets.update_counter(:'NODENetGuardPer6Seconds#{phash}', {peer_ip, op}, 1, {{peer_ip, op}, 0})
+      counter = :ets.update_counter(:"NODENetGuardPer6Seconds#{phash}", {peer_ip, op}, 1, {{peer_ip, op}, 0})
       counter < @max_msg_per_6_sec[op]
     end
   end
@@ -37,14 +37,14 @@ defmodule NodeGenNetguard do
   def decrement_buckets(idx) do
     step = trunc(@max_frames_per_6_sec / 2)
     :ets.foldl(fn({peer_ip, _}, _)->
-      ctr = :ets.update_counter(:'NODENetGuardTotalFrames#{idx}', peer_ip, {2, -step, 0, 0})
-      ctr == 0 && :ets.delete(:'NODENetGuardTotalFrames#{idx}', peer_ip)
-    end, nil, :'NODENetGuardTotalFrames#{idx}')
+      ctr = :ets.update_counter(:"NODENetGuardTotalFrames#{idx}", peer_ip, {2, -step, 0, 0})
+      ctr == 0 && :ets.delete(:"NODENetGuardTotalFrames#{idx}", peer_ip)
+    end, nil, :"NODENetGuardTotalFrames#{idx}")
 
     :ets.foldl(fn({{peer_ip, op}, _}, _)->
       step = trunc(@max_msg_per_6_sec[op] / 2)
-      ctr = :ets.update_counter(:'NODENetGuardPer6Seconds#{idx}', {peer_ip, op}, {2, -step, 0, 0})
-      ctr == 0 && :ets.delete(:'NODENetGuardPer6Seconds#{idx}', {peer_ip, op})
-    end, nil, :'NODENetGuardPer6Seconds#{idx}')
+      ctr = :ets.update_counter(:"NODENetGuardPer6Seconds#{idx}", {peer_ip, op}, {2, -step, 0, 0})
+      ctr == 0 && :ets.delete(:"NODENetGuardPer6Seconds#{idx}", {peer_ip, op})
+    end, nil, :"NODENetGuardPer6Seconds#{idx}")
   end
 end
diff --git a/ex/lib/node/node_gen_reassembly_gen.ex b/ex/lib/node/node_gen_reassembly_gen.ex
index 02dbe1e..bddfcba 100644
--- a/ex/lib/node/node_gen_reassembly_gen.ex
+++ b/ex/lib/node/node_gen_reassembly_gen.ex
@@ -12,10 +12,12 @@ defmodule NodeGenReassemblyGen do
   end
 
   def clear_stale(state) do
-    threshold = :os.system_time(:nanosecond) - 8_000_000_000
+    ts_nano = :os.system_time(:nanosecond)
+    threshold_min = ts_nano - 8_000_000_000
+    threshold_max = ts_nano + 300_000_000_000
     reorg = state.reorg
     |> Map.filter(fn {{_pk, ts_nano, _shard_total}, _value} ->
-        ts_nano > threshold
+        ts_nano > threshold_min and ts_nano < threshold_max
     end)
     put_in(state, [:reorg], reorg)
   end
diff --git a/ex/lib/node/node_gen_socket_gen.ex b/ex/lib/node/node_gen_socket_gen.ex
index 0b17c6c..7d4263d 100644
--- a/ex/lib/node/node_gen_socket_gen.ex
+++ b/ex/lib/node/node_gen_socket_gen.ex
@@ -2,7 +2,7 @@ defmodule NodeGenSocketGen do
   use GenServer
 
   def start_link(ip_tuple, port, idx) do
-    GenServer.start_link(__MODULE__, [ip_tuple, port, idx], name: :'NodeGenSocketGen#{idx}')
+    GenServer.start_link(__MODULE__, [ip_tuple, port, idx], name: :"NodeGenSocketGen#{idx}")
   end
 
   def init([ip_tuple, port, idx]) do
@@ -66,9 +66,14 @@ defmodule NodeGenSocketGen do
     key = :crypto.hash(:sha256, [shared_secret, :binary.encode_unsigned(ts_nano), iv])
     plaintext = :crypto.crypto_one_time_aead(:aes_256_gcm, key, iv, ciphertext, <<>>, tag, false)
 
-    msg = plaintext
-    |> NodeProto.deflate_decompress()
-    |> :erlang.binary_to_term([:safe])
+    msg = if version >= "1.2.3" do
+      msg = plaintext
+      |> NodeProto2.decompress_and_unpack()
+    else
+      msg = plaintext
+      |> NodeProto.deflate_decompress()
+      |> :erlang.binary_to_term([:safe])
+    end
 
     if !NodeGenNetguard.op_ok(peer_ip, msg.op) do
       IO.inspect {:dropping_due_to_op_flood, peer_ip, msg.op}
@@ -127,16 +132,31 @@ defmodule NodeGenSocketGen do
 
       {:send_to, peer_pairs, msg} ->
         port = Application.fetch_env!(:ama, :udp_port)
-        msg_compressed = NodeProto.compress(msg)
         Enum.each(peer_pairs, fn(%{ip4: ip4, pk: pk})->
-          {:ok, ip} = :inet.parse_address(~c'#{ip4}')
-          NodeProto.encrypt_message(msg_compressed, NodeANR.get_shared_secret(pk))
-          |> Enum.each(fn(msg_packed)->
-            case :gen_udp.send(state.socket, ip, port, msg_packed) do
-              :ok -> :ok
-              {:error, :eperm} -> :rand.uniform(100) == 1 && IO.puts("udp_send_error eperm")
-            end
-          end)
+          version = NodeANR.get_version(pk)
+          if version >= "1.2.3" do
+            msg_compressed = NodeProto2.compress(msg)
+
+            {:ok, ip} = :inet.parse_address(~c'#{ip4}')
+            NodeProto.encrypt_message(msg_compressed, NodeANR.get_shared_secret(pk))
+            |> Enum.each(fn(msg_packed)->
+              case :gen_udp.send(state.socket, ip, port, msg_packed) do
+                :ok -> :ok
+                {:error, :eperm} -> :rand.uniform(100) == 1 && IO.puts("udp_send_error eperm")
+              end
+            end)
+          else
+            msg_compressed = NodeProto.compress(msg)
+
+            {:ok, ip} = :inet.parse_address(~c'#{ip4}')
+            NodeProto.encrypt_message(msg_compressed, NodeANR.get_shared_secret(pk))
+            |> Enum.each(fn(msg_packed)->
+              case :gen_udp.send(state.socket, ip, port, msg_packed) do
+                :ok -> :ok
+                {:error, :eperm} -> :rand.uniform(100) == 1 && IO.puts("udp_send_error eperm")
+              end
+            end)
+          end
         end)
 
       {:udp_passive, _socket} ->
diff --git a/ex/lib/node/node_proto.ex b/ex/lib/node/node_proto.ex
index 73754da..0b54cf8 100644
--- a/ex/lib/node/node_proto.ex
+++ b/ex/lib/node/node_proto.ex
@@ -24,9 +24,9 @@ defmodule NodeProto do
   end
 
   def event_tip() do
-    tip = Consensus.chain_tip_entry()
+    tip = DB.Chain.tip_entry()
     temporal = tip |> Map.take([:header, :signature, :mask])
-    rooted = Fabric.rooted_tip_entry() |> Map.take([:header, :signature, :mask])
+    rooted = DB.Chain.rooted_tip_entry() |> Map.take([:header, :signature, :mask])
     %{op: :event_tip, temporal: temporal, rooted: rooted, ts_m: :os.system_time(1000)}
   end
 
@@ -58,26 +58,23 @@ defmodule NodeProto do
     %{op: :special_business_reply, business: business}
   end
 
+    def deflate_compress(data) do
+      z = :zlib.open()
+      :zlib.deflateInit(z, 6, :deflated, -15, 8, :default)
+      compressed = :zlib.deflate(z, data, :finish)
+      :zlib.deflateEnd(z)
+      :zlib.close(z)
+      :erlang.list_to_binary(compressed)
+    end
 
-
-
-  def deflate_compress(data) do
-    z = :zlib.open()
-    :zlib.deflateInit(z, 6, :deflated, -15, 8, :default)
-    compressed = :zlib.deflate(z, data, :finish)
-    :zlib.deflateEnd(z)
-    :zlib.close(z)
-    :erlang.list_to_binary(compressed)
-  end
-
-  def deflate_decompress(compressed_data) do
-    z = :zlib.open()
-    :zlib.inflateInit(z, -15)
-    decompressed = :zlib.inflate(z, compressed_data)
-    :zlib.inflateEnd(z)
-    :zlib.close(z)
-    :erlang.list_to_binary(decompressed)
-  end
+    def deflate_decompress(compressed_data) do
+      z = :zlib.open()
+      :zlib.inflateInit(z, -15)
+      decompressed = :zlib.inflate(z, compressed_data)
+      :zlib.inflateEnd(z)
+      :zlib.close(z)
+      :erlang.list_to_binary(decompressed)
+    end
 
   def compress(msg) do
     msg
@@ -85,6 +82,13 @@ defmodule NodeProto do
     |> deflate_compress()
   end
 
+  def compress2(msg) do
+    msg
+    |> RDB.vecpak_encode()
+    |> :zstd.compress()
+    |> IO.iodata_to_binary()
+  end
+
   def encrypt_message(msg_compressed, shared_key) do
     pk = Application.fetch_env!(:ama, :trainer_pk)
     version_3byte = Application.fetch_env!(:ama, :version_3b)
diff --git a/ex/lib/node/node_proto2.ex b/ex/lib/node/node_proto2.ex
new file mode 100644
index 0000000..7a4c7b7
--- /dev/null
+++ b/ex/lib/node/node_proto2.ex
@@ -0,0 +1,118 @@
+defmodule NodeProto2 do
+  def new_phone_who_dis() do
+    %{op: :new_phone_who_dis}
+  end
+  def new_phone_who_dis_reply() do
+    anr = NodeANR2.build()
+    %{op: :new_phone_who_dis_reply, anr: anr}
+  end
+
+  def get_peer_anrs() do
+    existing_peers = NodeANR2.b3_f4()
+    %{op: :get_peer_anrs, hasPeersb3f4: existing_peers}
+  end
+  def get_peer_anrs_reply(missing_anrs) do
+    %{op: :get_peer_anrs_reply, anrs: missing_anrs}
+  end
+
+  def ping(ts_m) do
+    %{op: :ping, ts_m: ts_m}
+  end
+  def ping_reply(ts_m) do
+    %{op: :ping_reply, ts_m: ts_m}
+  end
+
+  def event_tip() do
+    tip = DB.Chain.tip_entry()
+    temporal = tip |> Map.take([:header, :signature, :mask])
+    rooted = DB.Chain.rooted_tip_entry() |> Map.take([:header, :signature, :mask])
+    %{op: :event_tip, temporal: temporal, rooted: rooted, ts_m: :os.system_time(1000)}
+  end
+
+  def event_tx(tx_packed) when is_binary(tx_packed) do event_tx([tx_packed]) end
+  def event_tx(txs_packed) when is_list(txs_packed) do
+    %{op: :event_tx, txs_packed: txs_packed}
+  end
+
+  def event_entry(entry_packed) do
+    %{op: :event_entry, entry_packed: entry_packed}
+  end
+
+  def event_attestation(attestation_packed) do
+    %{op: :event_attestation, attestation_packed: attestation_packed}
+  end
+
+  def catchup(height_flags) do
+    %{op: :catchup, height_flags: height_flags}
+  end
+  def catchup_reply(tries) do
+    %{op: :catchup_reply, tries: tries}
+  end
+
+  def special_business(business) do
+    %{op: :special_business, business: business}
+  end
+
+  def special_business_reply(business) do
+    %{op: :special_business_reply, business: business}
+  end
+
+  def decompress_and_unpack(compressed_data) do
+    compressed_data
+    |> :zstd.decompress()
+    |> IO.iodata_to_binary()
+    |> RDB.vecpak_decode()
+  end
+
+  def compress(msg) do
+    msg
+    |> RDB.vecpak_encode()
+    |> :zstd.compress()
+    |> IO.iodata_to_binary()
+  end
+
+  def encrypt_message(msg_compressed, shared_key) do
+    pk = Application.fetch_env!(:ama, :trainer_pk)
+    version_3byte = Application.fetch_env!(:ama, :version_3b)
+
+    ts_n = :os.system_time(:nanosecond)
+    iv = :crypto.strong_rand_bytes(12)
+    key = :crypto.hash(:sha256, [shared_key, :binary.encode_unsigned(ts_n), iv])
+    {ciphertext, tag} = :crypto.crypto_one_time_aead(:aes_256_gcm, key, iv, msg_compressed, <<>>, 16, true)
+
+    payload = <<iv::binary, tag::binary, ciphertext::binary>>
+    if byte_size(payload) < 1360 do
+      [<<"AMA", version_3byte::binary, 0, pk::binary, 0::16, 1::16, ts_n::64, byte_size(payload)::32, payload::binary>>]
+    else
+      shards = div(byte_size(payload)+1023, 1024)
+      r = ReedSolomonEx.create_resource(shards, shards, 1024)
+      ReedSolomonEx.encode_shards(r, payload)
+      |> Enum.take(shards+1+div(shards,4))
+      |> Enum.map(fn {idx, shard}->
+        <<"AMA", version_3byte::binary, 0, pk::binary, idx::16, (shards*2)::16, ts_n::64, byte_size(payload)::32, shard::binary>>
+      end)
+    end
+  end
+
+  def unpack_message(<<"AMA", va, vb, vc, 0::8, pk::48-binary, s_idx::16, s_total::16, ts_n::64, original_size::32, payload::binary>>) do
+    try do
+      if pk == Application.fetch_env!(:ama, :trainer_pk), do: throw(%{error: :msg_to_self})
+
+      version = "#{va}.#{vb}.#{vc}"
+      if version < "1.2.3", do: throw(%{error: :old_version})
+
+      if s_total >= 10_000, do: throw(%{error: :too_large_shard})
+      if original_size >= 1024_0_000, do: throw(%{error: :too_large_size})
+
+      %{pk: pk, ts_nano: ts_n, shard_index: s_idx, shard_total: s_total, version: version,
+        original_size: original_size, payload: :binary.copy(payload)}
+    catch
+      throw,r -> %{error: r}
+      e,r -> %{error: e, reason: r}
+    end
+  end
+
+  def unpack_message(data) do
+    %{error: :unknown_data}
+  end
+end
diff --git a/ex/lib/node/node_state.ex b/ex/lib/node/node_state.ex
index 477a5d2..f274eca 100644
--- a/ex/lib/node/node_state.ex
+++ b/ex/lib/node/node_state.ex
@@ -71,12 +71,12 @@ defmodule NodeState do
   end
 
   def handle(:event_tip, istate, term) do
-    temporal = Entry.unpack(term.temporal)
-    rooted = Entry.unpack(term.rooted)
+    temporal = Entry.unpack_from_net(term.temporal)
+    rooted = Entry.unpack_from_net(term.rooted)
 
-    %{error: err_t, hash: hash_t} = Entry.validate_signature(temporal.header, temporal.signature, temporal.header_unpacked.signer, temporal[:mask])
+    %{error: err_t, hash: hash_t} = Entry.validate_signature(temporal)
     temporal = Map.merge(temporal, %{hash: hash_t, sig_error: err_t})
-    %{error: err_r, hash: hash_r} = Entry.validate_signature(rooted.header, rooted.signature, rooted.header_unpacked.signer, rooted[:mask])
+    %{error: err_r, hash: hash_r} = Entry.validate_signature(rooted)
     rooted = Map.merge(rooted, %{hash: hash_r, sig_error: err_r})
 
     NodeANR.set_tips(istate.peer.pk, rooted, temporal)
@@ -89,16 +89,20 @@ defmodule NodeState do
 
   def handle(:event_entry, istate, term) do
     seen_time = :os.system_time(1000)
-    %{error: :ok, entry: entry} = Entry.unpack_and_validate(term.entry_packed)
-    if Entry.height(entry) >= Fabric.rooted_tip_height() do
-      Fabric.insert_entry(entry, seen_time)
+    %{error: :ok, entry: entry} = Entry.unpack_and_validate_from_net(term.entry_packed)
+    if Entry.height(entry) >= DB.Chain.rooted_height() do
+      DB.Entry.insert(entry)
       NodeANR.set_tips(istate.peer.pk, nil, Map.merge(entry, %{sig_error: :ok}))
     end
   end
 
   def handle(:event_attestation, istate, term) do
-    %{error: :ok, attestation: a} = Attestation.unpack_and_validate(term.attestation_packed)
-    send(FabricCoordinatorGen, {:add_attestation, a})
+    res = Attestation.unpack_and_validate_from_net(term.attestation_packed)
+    if res.error == :ok and Attestation.validate_vs_chain(res.attestation) do
+      send(FabricCoordinatorGen, {:add_attestation, res.attestation})
+    else
+      :ets.insert(AttestationCache, {{res.attestation.entry_hash, res.attestation.signer}, {res.attestation, :os.system_time(1000)}})
+    end
   end
 
   def handle(:catchup, istate, term) do
@@ -109,9 +113,9 @@ defmodule NodeState do
       needAttest = opts[:a] || false
       needConsensus = opts[:c] || false
       trie = %{height: height}
-      trie = if !needEntry do trie else Map.put(trie, :entries, Fabric.entries_by_height(height) |> Enum.filter(& &1.hash not in hasHashes) |> Enum.map(& Entry.pack(&1))) end
-      trie = if !needAttest do trie else Map.put(trie, :attestations, [Fabric.my_attestation_by_height(height) |> Attestation.pack()]) end
-      trie = if !needConsensus do trie else Map.put(trie, :consensuses, Fabric.consensuses_by_height(height) |> Enum.map(& Consensus.pack(&1))) end
+      trie = if !needEntry do trie else Map.put(trie, :entries, DB.Entry.by_height(height) |> Enum.filter(& &1.hash not in hasHashes) |> Enum.map(& Entry.pack_for_net(&1))) end
+      trie = if !needAttest do trie else Map.put(trie, :attestations, DB.Attestation.by_height_my(height) |> Enum.map(& Attestation.pack_for_net(&1))) end
+      trie = if !needConsensus do trie else Map.put(trie, :consensuses, DB.Attestation.consensuses_by_height(height) |> Enum.map(& Consensus.pack_for_net(&1))) end
       trie
     end)
     send(NodeGen.get_socket_gen(), {:send_to, [%{ip4: istate.peer.ip4, pk: istate.peer.pk}], NodeProto.catchup_reply(tries)})
@@ -119,19 +123,18 @@ defmodule NodeState do
   def handle(:catchup_reply, istate, term) do
     #IO.inspect {:catchup_reply_from, istate.peer.ip4, Enum.map(term.tries, & &1.height)}
     Enum.each(term.tries, fn(trie)->
-      rooted_tip = Fabric.rooted_tip_height()
+      rooted_tip = DB.Chain.rooted_height()
 
       Enum.each(trie[:entries]||[], fn(entry_packed)->
-        seen_time = :os.system_time(1000)
-        %{error: :ok, entry: entry} = Entry.unpack_and_validate(entry_packed)
+        %{error: :ok, entry: entry} = Entry.unpack_and_validate_from_net(entry_packed)
         if Entry.height(entry) >= rooted_tip do
-          Fabric.insert_entry(entry, seen_time)
+          DB.Entry.insert(entry)
           NodeANR.set_tips(istate.peer.pk, nil, Map.merge(entry, %{sig_error: :ok}))
         end
       end)
 
       Enum.each(trie[:attestations]||[], fn(attestation_packed)->
-        res = Attestation.unpack_and_validate(attestation_packed)
+        res = Attestation.unpack_and_validate_from_net(attestation_packed)
         if res.error == :ok and Attestation.validate_vs_chain(res.attestation) do
           send(FabricCoordinatorGen, {:add_attestation, res.attestation})
         else
@@ -140,7 +143,7 @@ defmodule NodeState do
       end)
 
       Enum.each(trie[:consensuses]||[], fn(consensus_packed)->
-        consensus = Consensus.unpack(consensus_packed)
+        consensus = Consensus.unpack_from_net(consensus_packed)
         case Consensus.validate_vs_chain(consensus) do
           %{error: :ok, consensus: consensus} ->
             send(FabricCoordinatorGen, {:insert_consensus, consensus})
@@ -165,7 +168,7 @@ defmodule NodeState do
         end
       op == "slash_trainer_entry" ->
         signature = SpecialMeetingAttestGen.maybe_attest("slash_trainer_entry", term.business.entry_packed)
-        entry = Entry.unpack(term.business.entry_packed)
+        entry = Entry.unpack_from_net(term.business.entry_packed)
         if signature do
           pk = Application.fetch_env!(:ama, :trainer_pk)
           business = %{op: "slash_trainer_entry_reply", entry_hash: entry.hash, pk: pk, signature: signature}
diff --git a/ex/lib/node/txpool.ex b/ex/lib/node/txpool.ex
index 9c4bf71..25a8be7 100644
--- a/ex/lib/node/txpool.ex
+++ b/ex/lib/node/txpool.ex
@@ -1,11 +1,4 @@
 defmodule TXPool do
-    def init() do
-        :ets.new(TXPool, [:ordered_set, :named_table, :public,
-            {:write_concurrency, true}, {:read_concurrency, true}, {:decentralized_counters, false}])
-        :ets.new(GiftedSolCache, [:ordered_set, :named_table, :public,
-            {:write_concurrency, true}, {:read_concurrency, true}, {:decentralized_counters, false}])
-    end
-
     def insert(tx_packed) when is_binary(tx_packed) do insert([tx_packed]) end
     def insert([]) do :ok end
     def insert(txs_packed) do
@@ -31,7 +24,7 @@ defmodule TXPool do
     end
 
     def purge_stale() do
-        cur_epoch = Consensus.chain_epoch()
+        cur_epoch = DB.Chain.epoch()
         :ets.tab2list(TXPool)
         |> Enum.each(fn {key, txu} ->
             if is_stale(txu, cur_epoch) do
@@ -41,18 +34,18 @@ defmodule TXPool do
     end
 
     def validate_tx(txu, args \\ %{}) do
-      chain_epoch = Map.get_lazy(args, :epoch, fn()-> Consensus.chain_epoch() end)
-      chain_segment_vr_hash = Map.get_lazy(args, :segment_vr_hash, fn()-> Consensus.chain_segment_vr_hash() end)
-      chain_diff_bits = Map.get_lazy(args, :diff_bits, fn()-> Consensus.chain_diff_bits() end)
+      chain_epoch = Map.get_lazy(args, :epoch, fn()-> DB.Chain.epoch() end)
+      chain_segment_vr_hash = Map.get_lazy(args, :segment_vr_hash, fn()-> DB.Chain.segment_vr_hash() end)
+      chain_diff_bits = Map.get_lazy(args, :diff_bits, fn()-> DB.Chain.diff_bits() end)
       batch_state = Map.get_lazy(args, :batch_state, fn()-> %{} end)
 
       try do
-        chainNonce = Map.get_lazy(batch_state, {:chain_nonce, txu.tx.signer}, fn()-> Consensus.chain_nonce(txu.tx.signer) end)
+        chainNonce = Map.get_lazy(batch_state, {:chain_nonce, txu.tx.signer}, fn()-> DB.Chain.nonce(txu.tx.signer) end)
         nonceValid = !chainNonce or txu.tx.nonce > chainNonce
         if !nonceValid, do: throw(%{error: :invalid_tx_nonce, key: {txu.tx.nonce, txu.hash}})
         batch_state = Map.put(batch_state, {:chain_nonce, txu.tx.signer}, txu.tx.nonce)
 
-        balance = Map.get_lazy(batch_state, {:balance, txu.tx.signer}, fn()-> Consensus.chain_balance(txu.tx.signer) end)
+        balance = Map.get_lazy(batch_state, {:balance, txu.tx.signer}, fn()-> DB.Chain.balance(txu.tx.signer) end)
         balance = balance - BIC.Base.exec_cost(chain_epoch, txu)
         balance = balance - BIC.Coin.to_cents(1)
         if balance < 0, do: throw(%{error: :not_enough_tx_exec_balance, key: {txu.tx.nonce, txu.hash}})
@@ -76,9 +69,9 @@ defmodule TXPool do
 
     def validate_tx_batch(tx_packed) when is_binary(tx_packed) do validate_tx_batch([tx_packed]) end
     def validate_tx_batch(txs_packed) when is_list(txs_packed) do
-      chain_epoch = Consensus.chain_epoch()
-      segment_vr_hash = Consensus.chain_segment_vr_hash()
-      diff_bits = Consensus.chain_diff_bits()
+      chain_epoch = DB.Chain.epoch()
+      segment_vr_hash = DB.Chain.segment_vr_hash()
+      diff_bits = DB.Chain.diff_bits()
 
       {good, _} = Enum.reduce(txs_packed, {[], %{}}, fn(tx_packed, {acc, batch_state})->
         case TX.validate(tx_packed) do
@@ -96,8 +89,8 @@ defmodule TXPool do
 
     def grab_next_valid(amt \\ 1) do
         try do
-            chain_epoch = Consensus.chain_epoch()
-            segment_vr_hash = Consensus.chain_segment_vr_hash()
+            chain_epoch = DB.Chain.epoch()
+            segment_vr_hash = DB.Chain.segment_vr_hash()
             {acc, state} = :ets.foldl(fn({key, txu}, {acc, state_old})->
                 try do
                   case validate_tx(txu, %{epoch: chain_epoch, segment_vr_hash: segment_vr_hash, batch_state: state_old}) do
@@ -123,7 +116,7 @@ defmodule TXPool do
     end
 
     def is_stale(txu, cur_epoch) do
-        chainNonce = Consensus.chain_nonce(txu.tx.signer)
+        chainNonce = DB.Chain.nonce(txu.tx.signer)
         nonceValid = !chainNonce or txu.tx.nonce > chainNonce
 
         hasSol = Enum.find_value(txu.tx.actions, fn(a)-> a.function == "submit_sol" and hd(a.args) end)
diff --git a/ex/lib/node/upow.ex b/ex/lib/node/upow.ex
index b8657ce..8b0fb0d 100644
--- a/ex/lib/node/upow.ex
+++ b/ex/lib/node/upow.ex
@@ -25,7 +25,7 @@ defmodule UPOW do
 
             pk = Application.fetch_env!(:ama, :trainer_pk)
             pop = Application.fetch_env!(:ama, :trainer_pop)
-            epoch = Consensus.DB.chain_epoch()
+            epoch = DB.Chain.epoch()
 
             {hash, sol} = branch_sol(epoch, <<>>, pk, pop, pk)
             if hash < best do
diff --git a/ex/mix.exs b/ex/mix.exs
index a3aec19..02dd010 100644
--- a/ex/mix.exs
+++ b/ex/mix.exs
@@ -6,7 +6,7 @@ defmodule Ama.MixProject do
   def project do
     [
       app: @app,
-      version: "1.2.2",
+      version: "1.2.5",
       elixir: ">= 1.18.0",
       start_permanent: Mix.env() == :prod,
       deps: deps(),
@@ -36,12 +36,13 @@ defmodule Ama.MixProject do
 
       {:rustler, ">= 0.36.1", optional: true},
       {:blake3_ex, git: "https://github.com/vans163/blake3", branch: "finalize_xof"},
-      {:bls_ex, git: "https://github.com/amadeus-robot/bls_ex"},
-      {:reedsolomon_ex, git: "https://github.com/amadeus-robot/reedsolomon_ex"},
-      {:wasmer_ex, git: "https://github.com/amadeus-robot/wasmer_ex"},
+      {:bls_ex, git: "https://github.com/amadeusprotocol/bls_ex"},
+      {:reedsolomon_ex, git: "https://github.com/amadeusprotocol/reedsolomon_ex"},
+      {:wasmer_ex, git: "https://github.com/amadeusprotocol/wasmer_ex"},
 
       {:comsat, git: "https://github.com/vans163/ComSat.git"},
       {:ex_stun, git: "https://github.com/elixir-webrtc/ex_stun.git"},
+      {:x509, git: "https://github.com/voltone/x509"},
     ]
   end
 
diff --git a/ex/mix.lock b/ex/mix.lock
index 89181d1..1479432 100644
--- a/ex/mix.lock
+++ b/ex/mix.lock
@@ -2,8 +2,8 @@
   "bakeware": {:git, "https://github.com/vans163/bakeware", "c7f2c6c77cd6f053d5608ffa4e0b47e42c937349", [branch: "main"]},
   "blake3": {:git, "https://github.com/vans163/blake3", "396c613f7100700123805df654f63fdd7e908e15", [branch: "finalize_xof"]},
   "blake3_ex": {:git, "https://github.com/vans163/blake3", "94e0ca383c2cbe86d09d52344b8a6ed7912ab675", [branch: "finalize_xof"]},
-  "bls_ex": {:git, "https://github.com/amadeus-robot/bls_ex", "6651824947c3dc9b131e2f79341732fa5c052cf1", []},
-  "comsat": {:git, "https://github.com/vans163/ComSat.git", "7178d64dfda9d4669ba9f1e475dbcf6ee93e0ef5", []},
+  "bls_ex": {:git, "https://github.com/amadeusprotocol/bls_ex", "6651824947c3dc9b131e2f79341732fa5c052cf1", []},
+  "comsat": {:git, "https://github.com/vans163/ComSat.git", "cda8f6370a8044d2f2d549e33b811f23dec9f173", []},
   "elixir_make": {:hex, :elixir_make, "0.9.0", "6484b3cd8c0cee58f09f05ecaf1a140a8c97670671a6a0e7ab4dc326c3109726", [:mix], [], "hexpm", "db23d4fd8b757462ad02f8aa73431a426fe6671c80b200d9710caf3d1dd0ffdb"},
   "ex_stun": {:git, "https://github.com/elixir-webrtc/ex_stun.git", "caf8851c0fcd0962e9009a9e28172172732e447c", []},
   "exjsx": {:hex, :exjsx, "4.0.0", "60548841e0212df401e38e63c0078ec57b33e7ea49b032c796ccad8cde794b5c", [:mix], [{:jsx, "~> 2.8.0", [hex: :jsx, repo: "hexpm", optional: false]}], "hexpm", "32e95820a97cffea67830e91514a2ad53b888850442d6d395f53a1ac60c82e07"},
@@ -12,9 +12,10 @@
   "mnesia_kv": {:git, "https://github.com/xenomorphtech/mnesia_kv.git", "890109669975807b72506adceea7f20682bc6a67", []},
   "parse_trans": {:git, "https://github.com/uwiger/parse_trans", "d99fb36755c813a5db23e6f93741aa58323ef911", []},
   "photon": {:git, "https://github.com/vans163/photon.git", "4e39655e421bac2c94087527cad976f4b6a2d147", []},
-  "reedsolomon_ex": {:git, "https://github.com/amadeus-robot/reedsolomon_ex", "e11ddb33a50a4a3ccb1419a438fcc00b3c7ba8d4", []},
+  "reedsolomon_ex": {:git, "https://github.com/amadeusprotocol/reedsolomon_ex", "e11ddb33a50a4a3ccb1419a438fcc00b3c7ba8d4", []},
   "rocksdb": {:git, "https://gitlab.com/vans/erlang-rocksdb.git", "18add8e992a374771e6f1e97b1f50db6bf31a16f", [branch: "fix-gcc13"]},
   "rustler": {:hex, :rustler, "0.37.1", "721434020c7f6f8e1cdc57f44f75c490435b01de96384f8ccb96043f12e8a7e0", [:mix], [{:jason, "~> 1.0", [hex: :jason, repo: "hexpm", optional: false]}], "hexpm", "24547e9b8640cf00e6a2071acb710f3e12ce0346692e45098d84d45cdb54fd79"},
   "ssl_verify_fun": {:hex, :ssl_verify_fun, "1.1.7", "354c321cf377240c7b8716899e182ce4890c5938111a1296add3ec74cf1715df", [:make, :mix, :rebar3], [], "hexpm", "fe4c190e8f37401d30167c8c405eda19469f34577987c76dde613e838bbc67f8"},
-  "wasmer_ex": {:git, "https://github.com/amadeus-robot/wasmer_ex", "9ee91d612a8f24296d793e5f85624f12c25a4c93", []},
+  "wasmer_ex": {:git, "https://github.com/amadeusprotocol/wasmer_ex", "9ee91d612a8f24296d793e5f85624f12c25a4c93", []},
+  "x509": {:git, "https://github.com/voltone/x509", "341619ae36e483f6daea39df486036eda2b70350", []},
 }
diff --git a/ex/native/rdb/src/consensus/bic/epoch.rs b/ex/native/rdb/src/consensus/bic/epoch.rs
index 18190ff..4be369f 100644
--- a/ex/native/rdb/src/consensus/bic/epoch.rs
+++ b/ex/native/rdb/src/consensus/bic/epoch.rs
@@ -1,8 +1,10 @@
 use std::panic::panic_any;
+use std::collections::HashSet;
 use crate::consensus::aggsig::DST_MOTION;
 use crate::{bcat, consensus};
 
-use crate::consensus::consensus_kv::{kv_get, kv_put, kv_exists, kv_set_bit, kv_increment};
+use crate::consensus::consensus_kv::{kv_get, kv_get_next, kv_put, kv_exists, kv_delete, kv_set_bit, kv_increment};
+use crate::consensus::consensus_apply::ApplyEnv;
 
 pub const EPOCH_EMISSION_BASE: i128 = 1_000_000_000_000_000;
 pub const EPOCH_INTERVAL: i128 = 100_000;
@@ -274,6 +276,145 @@ pub fn call_slash_trainer(env: &mut crate::consensus::consensus_apply::ApplyEnv,
     kv_put(env, &bcat(&[b"bic:epoch:trainers:height:", &height]), term_trainers.as_slice());
 }
 
-pub fn next(env: &mut crate::consensus::consensus_apply::ApplyEnv) {
-    //Currently handled on elixir side
+pub fn next(env: &mut ApplyEnv) {
+    let epoch_cur = env.caller_env.entry_epoch;
+    let epoch_next = env.caller_env.entry_epoch + 1;
+    let peddlebike67_map: HashSet<Vec<u8>> = PEDDLEBIKE67.iter().map(|pk| pk.to_vec()).collect();
+
+    // slash sols for malicious trainers
+    let trainers = kv_get_trainers(env, &bcat(&[b"bic:epoch:trainers:", epoch_cur.to_string().as_bytes()]));
+    let trainers_map: HashSet<Vec<u8>> = trainers.into_iter().collect();
+    let trainers_removed = kv_get_trainers(env, &bcat(&[b"bic:epoch:trainers:removed:", epoch_cur.to_string().as_bytes()]));
+    let trainers_removed_map: HashSet<Vec<u8>> = trainers_removed.into_iter().collect();
+    let mut leaders: Vec<(Vec<u8>, i128)> = Vec::new();
+    let mut cursor: Vec<u8> = Vec::new();
+    while let Some((next_key_wo_prefix, val)) = kv_get_next(env, b"bic:epoch:solutions_count:", &cursor) {
+        if !trainers_removed_map.contains(&next_key_wo_prefix) {
+            let count = std::str::from_utf8(&val).ok().and_then(|s| s.parse::<i128>().ok()).unwrap_or_else(|| panic_any("invalid_solutions_count"));
+            leaders.push((next_key_wo_prefix.clone(), count));
+        }
+        cursor = next_key_wo_prefix;
+    }
+    // sort descending; Highest score first; tiebreak on PK
+    leaders.sort_unstable_by(|(ka, ca), (kb, cb)| {
+        match cb.cmp(ca) {
+            std::cmp::Ordering::Equal => kb.cmp(ka),
+            other => other,
+        }
+    });
+
+    let trainers_to_recv_emissions: Vec<(Vec<u8>, i128)> = leaders
+        .iter().cloned()
+        .filter(|(pk, _)| trainers_map.contains(pk) && !peddlebike67_map.contains(pk))
+        .take(99)
+        .collect();
+
+    let epoch_total_emission = epoch_emission(epoch_cur);
+    let epoch_early_adopter_emission = epoch_total_emission / 7;
+    let epoch_communityfund_emission = epoch_total_emission - epoch_early_adopter_emission;
+
+    distribute_peddlebike67_community_fund(env, epoch_communityfund_emission);
+
+    let total_sols: i128 = trainers_to_recv_emissions.iter().map(|(_, count)| count).sum();
+    distribute_emissions_to_trainers(env, &trainers_to_recv_emissions, epoch_early_adopter_emission, total_sols);
+
+    //Update validators for next epoch
+    let new_validators = build_and_shuffle_new_validators(env, &leaders);
+    let new_validators = consensus::bic::eetf_list_of_binaries(new_validators).unwrap();
+    let _ = kv_put(env, &bcat(&[b"bic:epoch:trainers:", &epoch_next.to_string().as_bytes()]), &new_validators);
+    let height = format!("{:012}", env.caller_env.entry_height + 1);
+    let _ = kv_put(env, &bcat(&[b"bic:epoch:trainers:height:", height.as_bytes()]), &new_validators);
+
+    update_difficulty_and_log_sols(env, epoch_cur, epoch_next, total_sols);
+    clear_epoch_data(env);
+}
+
+fn distribute_emissions_to_trainers(env: &mut ApplyEnv, trainers_to_recv: &Vec<(Vec<u8>, i128)>, total_emission: i128, total_sols: i128) {
+    if total_sols == 0 {
+        return;
+    }
+
+    for (trainer, trainer_sols) in trainers_to_recv {
+        let coins = (trainer_sols * total_emission) / total_sols;
+
+        let emission_address = kv_get(env, &bcat(&[b"bic:epoch:emission_address:", trainer]));
+        let balance_key = if let Some(addr) = emission_address {
+            bcat(&[b"bic:coin:balance:", &addr, b":AMA"])
+        } else {
+            bcat(&[b"bic:coin:balance:", trainer, b":AMA"])
+        };
+
+        let _ = kv_increment(env, &balance_key, coins);
+    }
+}
+
+fn distribute_peddlebike67_community_fund(env: &mut ApplyEnv, total_emission: i128) {
+    let n_count = PEDDLEBIKE67.len() as i128;
+    let q = total_emission / n_count;
+    let r = total_emission % n_count;
+
+    for (i, peddle_pk) in PEDDLEBIKE67.iter().enumerate() {
+        let coins = if (i as i128) < r { q + 1 } else { q };
+
+        let emission_address = kv_get(env, &bcat(&[b"bic:epoch:emission_address:", peddle_pk.as_slice()]));
+        let balance_key = if let Some(addr) = emission_address {
+            bcat(&[b"bic:coin:balance:", &addr, b":AMA"])
+        } else {
+            bcat(&[b"bic:coin:balance:", peddle_pk.as_slice(), b":AMA"])
+        };
+
+        let _ = kv_increment(env, &balance_key, coins);
+    }
+}
+
+fn build_and_shuffle_new_validators(env: &ApplyEnv, leaders: &Vec<(Vec<u8>, i128)>) -> Vec<Vec<u8>> {
+    let leader_pks: Vec<Vec<u8>> = leaders.iter().map(|(pk, _)| pk.clone()).collect();
+    let filtered_leaders: Vec<Vec<u8>> =
+        leader_pks.into_iter().filter(|pk| !PEDDLEBIKE67.iter().any(|p| p.as_slice() == pk.as_slice())).collect();
+
+    let mut new_validators: Vec<Vec<u8>> = PEDDLEBIKE67.iter().map(|p| p.to_vec()).collect();
+    new_validators.extend(filtered_leaders);
+    new_validators.truncate(99);
+
+    let seed_bytes = &env.caller_env.seed;
+    let seed_array: [u8; 32] = seed_bytes.get(..32).and_then(|s| s.try_into().ok()).unwrap_or([0u8; 32]);
+    let mut rng = crate::consensus::bic::exsss::Exsss::from_seed(&seed_array);
+    rng.shuffle(&mut new_validators);
+
+    new_validators
+}
+
+fn update_difficulty_and_log_sols(env: &mut ApplyEnv, epoch_cur: u64, epoch_next: u64, total_sols: i128) {
+    use crate::consensus::consensus_kv::kv_put;
+    let old_diff_bits = kv_get(env, b"bic:epoch:diff_bits").unwrap();
+    let old_diff_bits = std::str::from_utf8(&old_diff_bits).ok().and_then(|s| s.parse::<u32>().ok()).unwrap_or_else(|| panic_any("invalid_diff_bits"));
+
+    let next_diff_bits = crate::consensus::bic::sol_difficulty::next(old_diff_bits, total_sols as u64);
+    let _ = kv_put(env, b"bic:epoch:diff_bits", next_diff_bits.to_string().as_bytes());
+    let _ = kv_put(env, format!("bic:epoch:diff_bits:{}", epoch_next).as_bytes(), next_diff_bits.to_string().as_bytes());
+    let _ = kv_put(env, format!("bic:epoch:total_sols:{}", epoch_cur).as_bytes(), total_sols.to_string().as_bytes());
+}
+
+fn clear_epoch_data(env: &mut ApplyEnv) {
+    let mut cursor: Vec<u8> = Vec::new();
+
+    let prefix = b"bic:epoch:solbloom:";
+    while let Some((next_key_wo_prefix, _val)) = kv_get_next(env, prefix, &cursor) {
+        let mut key = Vec::with_capacity(prefix.len() + next_key_wo_prefix.len());
+        key.extend_from_slice(prefix);
+        key.extend_from_slice(&next_key_wo_prefix);
+
+        kv_delete(env, &key);
+        cursor = next_key_wo_prefix;
+    }
+
+    let prefix = b"bic:epoch:solutions_count:";
+    while let Some((next_key_wo_prefix, _val)) = kv_get_next(env, prefix, &cursor) {
+        let mut key = Vec::with_capacity(prefix.len() + next_key_wo_prefix.len());
+        key.extend_from_slice(prefix);
+        key.extend_from_slice(&next_key_wo_prefix);
+
+        kv_delete(env, &key);
+        cursor = next_key_wo_prefix;
+    }
 }
diff --git a/ex/native/rdb/src/consensus/bic/exsss.rs b/ex/native/rdb/src/consensus/bic/exsss.rs
new file mode 100644
index 0000000..76b636a
--- /dev/null
+++ b/ex/native/rdb/src/consensus/bic/exsss.rs
@@ -0,0 +1,296 @@
+/// Erlang :exsss (Xorshift116**) PRNG implementation
+///
+/// This provides exact compatibility with Erlang's :rand.seed(:exsss, seed) for
+/// deterministic shuffling in consensus-critical code.
+///
+/// Algorithm: Xorshift116** - a scrambled linear generator with:
+/// - 58 bits precision
+/// - Period of 2^116-1
+/// - Two 64-bit state values (s0, s1)
+/// - Output scrambling via (S*5 rotl 7)*9
+
+/// Xorshift116** state (matches Erlang :exsss)
+#[derive(Debug, Clone, Copy)]
+pub struct Exsss {
+    s0: u64,
+    s1: u64,
+}
+
+impl Exsss {
+    /// Create new generator from 256-bit seed (little-endian)
+    /// Matches Erlang: :rand.seed(:exsss, seed) where seed is <<...::256-little>>
+    pub fn from_seed(seed_bytes: &[u8; 32]) -> Self {
+        // extract integer seed from first bytes (matches Erlang <<seed::256-little>>)
+        let seed = u128::from_le_bytes(seed_bytes[0..16].try_into().unwrap());
+
+        Self::from_seed_u128(seed)
+    }
+
+    /// Create from integer seed (matches Erlang :rand.seed(:exsss, integer))
+    pub fn from_seed_u128(seed: u128) -> Self {
+        // Erlang's seed58(2, X) implementation
+        let (s0, x1) = seed58(seed as u64);
+        let (s1, _x2) = seed58(x1);
+
+        Self { s0, s1 }
+    }
+
+    /// Generate next random u64 value (internal, 58-bit precision)
+    /// Matches Erlang :rand.exsss_next
+    fn next_u64(&mut self) -> u64 {
+        const MASK_58: u64 = (1u64 << 58) - 1;
+
+        // Erlang state format: [S1|S0] (improper list: head=S1, tail=S0)
+        // Our struct stores (s0, s1) matching the seed58 output order
+        // exsss_next([S1|S0]) parameter: S1=head, S0=tail
+        // So when calling with our state: S1=self.s0 (first seed), S0=self.s1 (second seed)
+        let s1 = self.s0;
+        let s0 = self.s1;
+
+        // S0_1 = S0 & MASK_58
+        let s0_1 = s0 & MASK_58;
+
+        // exs_next(S0_1, S1, S1_b):
+        // S1_b = (S1 & MASK_58) ^ ((S1 << 24) & MASK_58)
+        // NewS1 = S1_b ^ S0_1 ^ (S1_b >> 11) ^ (S0_1 >> 41)
+        let s1_masked = s1 & MASK_58;
+        let s1_b = s1_masked ^ ((s1_masked << 24) & MASK_58);
+        let new_s1 = s1_b ^ s0_1 ^ (s1_b >> 11) ^ (s0_1 >> 41);
+
+        // scramble_starstar(S0_1, ...):
+        // V_a = S0_1 + (S0_1 << 2) mod 2^58  // S0_1 * 5
+        // V_b = rotl(V_a, 7) in 58-bit space
+        // Output = (V_b + (V_b << 3)) mod 2^58  // V_b * 9
+        let v_a = (s0_1 + ((s0_1 << 2) & MASK_58)) & MASK_58;
+        let v_b = ((v_a << 7) | (v_a >> 51)) & MASK_58;
+        let output = (v_b + ((v_b << 3) & MASK_58)) & MASK_58;
+
+        // Returns state [S0_1|NewS1]
+        // Our struct: s0=S0_1 (new first), s1=NewS1 (new second)
+        self.s0 = s0_1;
+        self.s1 = new_s1 & MASK_58;
+
+        output
+    }
+
+    /// Generate random float in range [0.0, 1.0) (matches Erlang :rand.uniform())
+    pub fn uniform_float(&mut self) -> f64 {
+        // exsss_uniform: (I >> 5) * 2^-53
+        // where I is 58-bit output from next_u64
+        const TWO_POW_MINUS53: f64 = 1.0 / (1u64 << 53) as f64;
+
+        let i = self.next_u64();
+        let shifted = i >> 5; // 58 - 53 = 5
+        (shifted as f64) * TWO_POW_MINUS53
+    }
+
+    /// Generate random integer in range [1, n] (matches Erlang :rand.uniform(n))
+    pub fn uniform(&mut self, range: u64) -> u64 {
+        self.uniform_internal(range, 0)
+    }
+
+    fn uniform_internal(&mut self, range: u64, depth: u32) -> u64 {
+        const BIT_58: u64 = 1u64 << 58;
+
+        if range == 0 {
+            return 0;
+        }
+
+        let v = self.next_u64(); // already 58-bit
+
+        // Erlang checks: if 0 <= MaxMinusRange (i.e., Range <= BIT_58)
+        // For our use case, range is always small (1000), so this is always true
+
+        // fast path: if v < range, return v + 1
+        if v < range {
+            return v + 1;
+        }
+
+        // rejection sampling
+        let i = v % range;
+        let max_minus_range = BIT_58 - range;
+
+        if v - i <= max_minus_range {
+            i + 1
+        } else {
+            // v in truncated top range, retry
+            self.uniform_internal(range, depth + 1)
+        }
+    }
+
+    /// Shuffle a slice in place (matches Elixir Enum.shuffle)
+    /// Uses sort_by with random floats, not Fisher-Yates
+    pub fn shuffle<T: Clone>(&mut self, slice: &mut [T]) {
+        if slice.len() <= 1 {
+            return;
+        }
+
+        // Generate random key for each element with its value
+        let mut keyed: Vec<(f64, T)> = slice.iter().map(|val| (self.uniform_float(), val.clone())).collect();
+
+        // Sort by random keys
+        keyed.sort_by(|a, b| a.0.partial_cmp(&b.0).unwrap());
+
+        // Write sorted values back
+        for (idx, (_key, val)) in keyed.into_iter().enumerate() {
+            slice[idx] = val;
+        }
+    }
+}
+
+/// Splitmix64 next step (matches Erlang splitmix64_next)
+/// Returns (Z, NewX) where Z is the output and NewX is the updated state
+fn splitmix64_next(x0: u64) -> (u64, u64) {
+    let x = x0.wrapping_add(0x9e3779b97f4a7c15);
+    let mut z = x;
+    z = (z ^ (z >> 30)).wrapping_mul(0xbf58476d1ce4e5b9);
+    z = (z ^ (z >> 27)).wrapping_mul(0x94d049bb133111eb);
+    z = z ^ (z >> 31);
+    (z, x)
+}
+
+/// Seed58 (matches Erlang seed58/1)
+/// Returns (Z masked to 58 bits, NewX) skipping zero values
+fn seed58(x0: u64) -> (u64, u64) {
+    const MASK_58: u64 = (1u64 << 58) - 1;
+
+    let (z0, x) = splitmix64_next(x0);
+    let z = z0 & MASK_58;
+
+    if z == 0 {
+        // retry with new x
+        seed58(x)
+    } else {
+        (z, x)
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn test_state_initialization() {
+        // Verify exact state initialization matches Erlang
+        let test_cases = vec![
+            (0u128, 153307352162749871u64, 178066366098138612u64),
+            (42, 132629853624823445, 67522330609774851),
+            (777, 132610673151668814, 220791266393211968),
+            (12345, 149043579997720992, 31205127689074925),
+            (54321, 144632915686665753, 52714770947718356),
+            (99999, 51811462204453670, 95920375662433499),
+            (123456789, 161132163074061945, 185172155811622446),
+        ];
+
+        for (seed, expected_s0, expected_s1) in test_cases {
+            let rng = Exsss::from_seed_u128(seed);
+            assert_eq!(rng.s0, expected_s0, "s0 mismatch for seed {}", seed);
+            assert_eq!(rng.s1, expected_s1, "s1 mismatch for seed {}", seed);
+        }
+    }
+
+    #[test]
+    fn test_seed_test_1() {
+        // Test 1 from Elixir IEx
+        let seed_bytes: [u8; 32] = [
+            1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
+            30, 31, 32,
+        ];
+        let mut rng = Exsss::from_seed(&seed_bytes);
+
+        let r1 = rng.uniform(1000);
+        let r2 = rng.uniform(1000);
+        let r3 = rng.uniform(1000);
+
+        // Expected: 829, 169, 221
+        assert_eq!(r1, 829, "first uniform(1000)");
+        assert_eq!(r2, 169, "second uniform(1000)");
+        assert_eq!(r3, 221, "third uniform(1000)");
+    }
+
+    #[test]
+    fn test_shuffle_simple() {
+        // Test 2 from Elixir IEx
+        let seed_bytes = seed_from_u64(12345);
+        let mut rng = Exsss::from_seed(&seed_bytes);
+
+        let mut list = vec![1, 2, 3, 4, 5];
+        rng.shuffle(&mut list);
+
+        // Expected: [3, 4, 2, 1, 5]
+        assert_eq!(list, vec![3, 4, 2, 1, 5]);
+    }
+
+    #[test]
+    fn test_shuffle_zero_seed() {
+        // Test 3 from Elixir IEx
+        let seed_bytes = seed_from_u64(0);
+        let mut rng = Exsss::from_seed(&seed_bytes);
+
+        let mut list: Vec<u32> = (1..=10).collect();
+        rng.shuffle(&mut list);
+
+        // Expected: [5, 2, 1, 7, 9, 4, 8, 6, 10, 3]
+        assert_eq!(list, vec![5, 2, 1, 7, 9, 4, 8, 6, 10, 3]);
+    }
+
+    #[test]
+    fn test_random_sequence() {
+        // Test 5 from Elixir IEx
+        let seed_bytes = seed_from_u64(42);
+        let mut rng = Exsss::from_seed(&seed_bytes);
+
+        let mut randoms = Vec::new();
+        for _ in 0..20 {
+            randoms.push(rng.uniform(1000));
+        }
+
+        // Expected: [294, 431, 615, 198, 771, 458, 832, 264, 842, 111, 320, 936, 44, 92, 979, 44, 402, 648, 714, 722]
+        assert_eq!(
+            randoms,
+            vec![294, 431, 615, 198, 771, 458, 832, 264, 842, 111, 320, 936, 44, 92, 979, 44, 402, 648, 714, 722]
+        );
+    }
+
+    #[test]
+    fn test_shuffle_large() {
+        // Test 7 from Elixir IEx
+        let seed_bytes = seed_from_u64(54321);
+        let mut rng = Exsss::from_seed(&seed_bytes);
+
+        let mut list: Vec<u32> = (1..=99).collect();
+        rng.shuffle(&mut list);
+
+        // Expected first 50: [74, 86, 38, 82, 89, 10, 84, 26, 98, 85, 34, 91, 87, 51, 93, 45, 41, 30, 17, 96, 28, 6, 27, 78, 23, 25, 92, 18, 32, 39, 48, 22, 49, 1, 61, 9, 20, 95, 72, 79, 70, 33, 50, 42, 77, 73, 81, 24, 60, 88]
+        let expected_first_50 = vec![
+            74, 86, 38, 82, 89, 10, 84, 26, 98, 85, 34, 91, 87, 51, 93, 45, 41, 30, 17, 96, 28, 6, 27, 78, 23, 25, 92,
+            18, 32, 39, 48, 22, 49, 1, 61, 9, 20, 95, 72, 79, 70, 33, 50, 42, 77, 73, 81, 24, 60, 88,
+        ];
+        assert_eq!(list[0..50], expected_first_50[..]);
+    }
+
+    #[test]
+    fn test_determinism() {
+        // Test 8 from Elixir IEx
+        let seed_bytes = seed_from_u64(777);
+
+        let mut rng1 = Exsss::from_seed(&seed_bytes);
+        let mut list1 = vec![1, 2, 3, 4, 5, 6, 7, 8];
+        rng1.shuffle(&mut list1);
+
+        let mut rng2 = Exsss::from_seed(&seed_bytes);
+        let mut list2 = vec![1, 2, 3, 4, 5, 6, 7, 8];
+        rng2.shuffle(&mut list2);
+
+        // Expected: [2, 3, 6, 4, 1, 5, 7, 8]
+        assert_eq!(list1, vec![2, 3, 6, 4, 1, 5, 7, 8]);
+        assert_eq!(list1, list2, "determinism check");
+    }
+
+    /// Helper: create 32-byte seed from u64 (for simple integer seeds)
+    fn seed_from_u64(n: u64) -> [u8; 32] {
+        let mut bytes = [0u8; 32];
+        bytes[0..8].copy_from_slice(&n.to_le_bytes());
+        bytes
+    }
+}
diff --git a/ex/native/rdb/src/consensus/bic/mod.rs b/ex/native/rdb/src/consensus/bic/mod.rs
index 165e1c4..bc413fb 100644
--- a/ex/native/rdb/src/consensus/bic/mod.rs
+++ b/ex/native/rdb/src/consensus/bic/mod.rs
@@ -9,6 +9,7 @@ pub mod sol;
 pub mod sol_bloom;
 pub mod sol_difficulty;
 pub mod sol_freivalds;
+pub mod exsss;
 
 pub fn eetf_list_of_binaries(list_of_binaries: Vec<Vec<u8>>) -> Result<Vec<u8>, eetf::EncodeError> {
     let elements: Vec<eetf::Term> = list_of_binaries
diff --git a/ex/native/rdb/src/consensus/consensus_apply.rs b/ex/native/rdb/src/consensus/consensus_apply.rs
index 67ed2da..0a01cbd 100644
--- a/ex/native/rdb/src/consensus/consensus_apply.rs
+++ b/ex/native/rdb/src/consensus/consensus_apply.rs
@@ -223,7 +223,7 @@ pub fn apply_entry<'db, 'a>(db: &'db TransactionDB<MultiThreaded>, pk: &[u8], sk
         }
     }
 
-    //call_exit(&mut applyenv);
+    call_exit(&mut applyenv);
 
     applyenv.into_parts()
 }
@@ -251,6 +251,14 @@ fn call_txs_pre_upfront_cost<'a>(env: &mut ApplyEnv, txus: &[rustler::Term<'a>])
 }
 
 fn call_exit(env: &mut ApplyEnv) {
+    //seed RNG for random validator selection
+    let vr = env.caller_env.entry_vr.to_vec();
+    let seed_hash = blake3::hash(&vr);
+    env.caller_env.seed = seed_hash.as_bytes().to_vec();
+    // extract f64 from first 8 bytes of seed_hash in little-endian
+    let seedf64 = f64::from_le_bytes(seed_hash.as_bytes()[0..8].try_into().unwrap_or([0u8; 8]));
+    env.caller_env.seedf64 = seedf64;
+
     env.muts = Vec::new();
     env.muts_rev = Vec::new();
 
diff --git a/ex/native/rdb/src/lib.rs b/ex/native/rdb/src/lib.rs
index ca35169..5b81625 100644
--- a/ex/native/rdb/src/lib.rs
+++ b/ex/native/rdb/src/lib.rs
@@ -10,7 +10,7 @@ use rustler::{
 
 pub use rust_rocksdb::{TransactionDB, MultiThreaded, TransactionDBOptions, Options,
     Transaction, TransactionOptions, WriteOptions, CompactOptions, BottommostLevelCompaction,
-    DBRawIteratorWithThreadMode, BoundColumnFamily,
+    DBRawIteratorWithThreadMode, BoundColumnFamily, ReadOptions,
     Cache, LruCacheOptions, BlockBasedOptions, DBCompressionType, BlockBasedIndexType,
     ColumnFamilyDescriptor, AsColumnFamilyRef};
 
@@ -153,7 +153,7 @@ fn open_transaction_db<'a>(env: Env<'a>, path: String, cf_names: Vec<String>) ->
     db_opts.create_missing_column_families(true);
     db_opts.set_max_open_files(30000);
     //more threads
-    db_opts.increase_parallelism(4);
+    db_opts.increase_parallelism(2);
     db_opts.set_max_background_jobs(2);
 
     db_opts.set_max_total_wal_size(2 * 1024 * 1024 * 1024); // 2GB
@@ -174,7 +174,7 @@ fn open_transaction_db<'a>(env: Env<'a>, path: String, cf_names: Vec<String>) ->
     db_opts.set_level_zero_file_num_compaction_trigger(8);
     db_opts.set_level_zero_slowdown_writes_trigger(30);
     db_opts.set_level_zero_stop_writes_trigger(100);
-    db_opts.set_max_subcompactions(2);
+    db_opts.set_max_subcompactions(1);
 
     //db_opts.set_level_compaction_dynamic_level_bytes(false);
 
@@ -231,7 +231,7 @@ fn open_transaction_db<'a>(env: Env<'a>, path: String, cf_names: Vec<String>) ->
     cf_opts.set_level_zero_file_num_compaction_trigger(20);
     cf_opts.set_level_zero_slowdown_writes_trigger(40);
     cf_opts.set_level_zero_stop_writes_trigger(100);
-    cf_opts.set_max_subcompactions(2);
+    cf_opts.set_max_subcompactions(1);
     //cf_opts.set_periodic_compaction_seconds(0);
 
     //cf_opts.set_level_compaction_dynamic_level_bytes(false);
@@ -280,6 +280,14 @@ fn close_db(db: ResourceArc<DbResource>) -> NifResult<Atom> {
     Ok(atoms::ok())
 }
 
+#[rustler::nif(schedule = "DirtyCpu")]
+fn drop_cf<'a>(env: Env<'a>, db: ResourceArc<DbResource>, cf_name: String) -> NifResult<Term<'a>> {
+    match db.db.drop_cf(cf_name.as_str()) {
+        Ok(()) => Ok(atoms::ok().encode(env)),
+        Err(e) => Err(to_nif_rdb_err(e)),
+    }
+}
+
 #[rustler::nif]
 fn property_value<'a>(env: Env<'a>, db: ResourceArc<DbResource>, key: String) -> NifResult<Term<'a>> {
     match db.db.property_value(&key) {
@@ -372,6 +380,28 @@ fn get_cf<'a>(env: Env<'a>, cf: ResourceArc<CfResource>, key: Binary) -> NifResu
     }
 }
 
+#[rustler::nif]
+fn exists<'a>(env: Env<'a>, db: ResourceArc<DbResource>, key: Binary) -> NifResult<Term<'a>> {
+    let mut ro = ReadOptions::default();
+    ro.fill_cache(false);
+    match db.db.get_pinned_opt(key.as_slice(), &ro) {
+        Ok(Some(_)) => Ok((atoms::ok(), true).encode(env)),
+        Ok(None) => Ok((atoms::ok(), false).encode(env)),
+        Err(e) => Err(to_nif_rdb_err(e)),
+    }
+}
+
+#[rustler::nif]
+fn exists_cf<'a>(env: Env<'a>, cf: ResourceArc<CfResource>, key: Binary) -> NifResult<Term<'a>> {
+    let mut ro = ReadOptions::default();
+    ro.fill_cache(false);
+    match cf.db.db.get_pinned_cf_opt(&*cf, key.as_slice(), &ro) {
+        Ok(Some(_)) => Ok((atoms::ok(), true).encode(env)),
+        Ok(None) => Ok((atoms::ok(), false).encode(env)),
+        Err(e) => Err(to_nif_rdb_err(e)),
+    }
+}
+
 #[rustler::nif]
 fn put(db: ResourceArc<DbResource>, key: Binary, value: Binary) -> NifResult<Atom> {
     db.db
@@ -494,6 +524,34 @@ fn transaction_get_cf<'a>(env: Env<'a>, tx: ResourceArc<TxResource>, cf: Resourc
     }
 }
 
+#[rustler::nif]
+fn transaction_exists<'a>(env: Env<'a>, tx: ResourceArc<TxResource>, key: Binary) -> NifResult<Term<'a>> {
+    let guard = tx.tx.lock().unwrap();
+    let txn = guard.as_ref().ok_or_else(|| to_nif_err(atoms::mutex_closed()))?;
+    let mut ro = ReadOptions::default();
+    ro.fill_cache(false);
+    let rustlol = match txn.get_pinned_opt(key.as_slice(), &ro) {
+        Ok(Some(_)) => Ok((atoms::ok(), true).encode(env)),
+        Ok(None) => Ok((atoms::ok(), false).encode(env)),
+        Err(e) => Err(to_nif_rdb_err(e)),
+    };
+    rustlol
+}
+
+#[rustler::nif]
+fn transaction_exists_cf<'a>(env: Env<'a>, tx: ResourceArc<TxResource>, cf: ResourceArc<CfResource>, key: Binary) -> NifResult<Term<'a>> {
+    let guard = tx.tx.lock().unwrap();
+    let txn = guard.as_ref().ok_or_else(|| to_nif_err(atoms::mutex_closed()))?;
+    let mut ro = ReadOptions::default();
+    ro.fill_cache(false);
+    let rustlol = match txn.get_pinned_cf_opt(&*cf, key.as_slice(), &ro) {
+        Ok(Some(_)) => Ok((atoms::ok(), true).encode(env)),
+        Ok(None) => Ok((atoms::ok(), false).encode(env)),
+        Err(e) => Err(to_nif_rdb_err(e)),
+    };
+    rustlol
+}
+
 #[rustler::nif]
 fn transaction_put(tx: ResourceArc<TxResource>, key: Binary, val: Binary) -> NifResult<Atom> {
     let guard = tx.tx.lock().unwrap();
diff --git a/ex/native/rdb/src/model/_vecpak_ex.rs b/ex/native/rdb/src/model/_vecpak_ex.rs
index 475ea37..9450517 100644
--- a/ex/native/rdb/src/model/_vecpak_ex.rs
+++ b/ex/native/rdb/src/model/_vecpak_ex.rs
@@ -211,7 +211,7 @@ pub fn decode_term<'a>(env: Env<'a>, buf: &[u8], i: &mut usize) -> Result<Term<'
         }
         5 => {
             let len = decode_varint_gt_zero(buf, i)?;
-            let bytes = read_exact(buf, i, len as usize)?.to_vec();
+            let bytes = read_exact(buf, i, len as usize)?;
             let mut ob = OwnedBinary::new(len).ok_or(Error::Atom("alloc_failed"))?;
             ob.as_mut_slice().copy_from_slice(&bytes);
             let bin = ob.release(env);
